2016-12-03 00:59:57.273874: step 0, loss = 13.97, accu = 0.27, validation: 0.27 (10.6 examples/sec; 12.031 sec/batch)
2016-12-03 01:00:00.132412: step 10, loss = 13.82, accu = 0.32, validation: 0.36 (596.7 examples/sec; 0.215 sec/batch)
2016-12-03 01:00:02.244326: step 20, loss = 13.67, accu = 0.41, validation: 0.41 (610.3 examples/sec; 0.210 sec/batch)
2016-12-03 01:00:04.287107: step 30, loss = 13.50, accu = 0.46, validation: 0.50 (648.2 examples/sec; 0.197 sec/batch)
2016-12-03 01:00:06.326011: step 40, loss = 13.23, accu = 0.53, validation: 0.48 (594.4 examples/sec; 0.215 sec/batch)
2016-12-03 01:00:08.390313: step 50, loss = 13.24, accu = 0.52, validation: 0.59 (613.4 examples/sec; 0.209 sec/batch)
2016-12-03 01:00:10.624973: step 60, loss = 13.27, accu = 0.43, validation: 0.45 (576.5 examples/sec; 0.222 sec/batch)
2016-12-03 01:00:12.751197: step 70, loss = 13.03, accu = 0.46, validation: 0.57 (624.4 examples/sec; 0.205 sec/batch)
2016-12-03 01:00:14.872609: step 80, loss = 12.90, accu = 0.53, validation: 0.60 (617.4 examples/sec; 0.207 sec/batch)
2016-12-03 01:00:16.985463: step 90, loss = 12.74, accu = 0.57, validation: 0.61 (602.0 examples/sec; 0.213 sec/batch)
2016-12-03 01:00:19.118281: step 100, loss = 12.56, accu = 0.60, validation: 0.63 (601.0 examples/sec; 0.213 sec/batch)
2016-12-03 01:00:21.486412: step 110, loss = 12.42, accu = 0.64, validation: 0.60 (548.8 examples/sec; 0.233 sec/batch)
2016-12-03 01:00:23.618386: step 120, loss = 12.42, accu = 0.59, validation: 0.62 (589.7 examples/sec; 0.217 sec/batch)
2016-12-03 01:00:25.717176: step 130, loss = 12.35, accu = 0.59, validation: 0.66 (629.3 examples/sec; 0.203 sec/batch)
2016-12-03 01:00:27.838965: step 140, loss = 12.01, accu = 0.72, validation: 0.63 (637.8 examples/sec; 0.201 sec/batch)
2016-12-03 01:00:29.967586: step 150, loss = 12.20, accu = 0.59, validation: 0.63 (624.7 examples/sec; 0.205 sec/batch)
2016-12-03 01:00:32.117260: step 160, loss = 12.03, accu = 0.59, validation: 0.70 (613.8 examples/sec; 0.209 sec/batch)
2016-12-03 01:00:34.238034: step 170, loss = 12.00, accu = 0.61, validation: 0.64 (596.2 examples/sec; 0.215 sec/batch)
2016-12-03 01:00:36.383371: step 180, loss = 11.83, accu = 0.65, validation: 0.55 (596.4 examples/sec; 0.215 sec/batch)
2016-12-03 01:00:38.436581: step 190, loss = 11.76, accu = 0.59, validation: 0.59 (628.0 examples/sec; 0.204 sec/batch)
2016-12-03 01:00:40.512835: step 200, loss = 11.67, accu = 0.64, validation: 0.63 (582.7 examples/sec; 0.220 sec/batch)
2016-12-03 01:00:42.790110: step 210, loss = 11.57, accu = 0.62, validation: 0.66 (604.0 examples/sec; 0.212 sec/batch)
2016-12-03 01:00:44.928180: step 220, loss = 11.57, accu = 0.55, validation: 0.63 (631.2 examples/sec; 0.203 sec/batch)
2016-12-03 01:00:47.054107: step 230, loss = 11.37, accu = 0.60, validation: 0.70 (645.7 examples/sec; 0.198 sec/batch)
2016-12-03 01:00:49.171114: step 240, loss = 11.30, accu = 0.63, validation: 0.58 (576.7 examples/sec; 0.222 sec/batch)
2016-12-03 01:00:51.288401: step 250, loss = 11.17, accu = 0.66, validation: 0.66 (632.0 examples/sec; 0.203 sec/batch)
2016-12-03 01:00:53.418513: step 260, loss = 11.15, accu = 0.61, validation: 0.66 (608.5 examples/sec; 0.210 sec/batch)
2016-12-03 01:00:55.578169: step 270, loss = 11.03, accu = 0.68, validation: 0.59 (611.7 examples/sec; 0.209 sec/batch)
2016-12-03 01:00:57.714571: step 280, loss = 10.93, accu = 0.67, validation: 0.64 (611.2 examples/sec; 0.209 sec/batch)
2016-12-03 01:00:59.840937: step 290, loss = 10.91, accu = 0.62, validation: 0.55 (602.7 examples/sec; 0.212 sec/batch)
2016-12-03 01:01:01.992805: step 300, loss = 10.80, accu = 0.61, validation: 0.66 (594.7 examples/sec; 0.215 sec/batch)
2016-12-03 01:01:04.372027: step 310, loss = 10.67, accu = 0.66, validation: 0.61 (630.4 examples/sec; 0.203 sec/batch)
2016-12-03 01:01:06.498845: step 320, loss = 10.60, accu = 0.63, validation: 0.61 (607.3 examples/sec; 0.211 sec/batch)
2016-12-03 01:01:08.609074: step 330, loss = 10.57, accu = 0.59, validation: 0.67 (592.1 examples/sec; 0.216 sec/batch)
2016-12-03 01:01:10.755563: step 340, loss = 10.41, accu = 0.66, validation: 0.69 (569.4 examples/sec; 0.225 sec/batch)
2016-12-03 01:01:12.907976: step 350, loss = 10.46, accu = 0.61, validation: 0.59 (571.8 examples/sec; 0.224 sec/batch)
2016-12-03 01:01:15.000041: step 360, loss = 10.37, accu = 0.62, validation: 0.66 (587.1 examples/sec; 0.218 sec/batch)
2016-12-03 01:01:17.137816: step 370, loss = 10.40, accu = 0.55, validation: 0.64 (596.4 examples/sec; 0.215 sec/batch)
2016-12-03 01:01:19.241820: step 380, loss = 10.24, accu = 0.60, validation: 0.62 (589.0 examples/sec; 0.217 sec/batch)
2016-12-03 01:01:21.339341: step 390, loss = 10.05, accu = 0.62, validation: 0.66 (612.4 examples/sec; 0.209 sec/batch)
2016-12-03 01:01:23.472396: step 400, loss = 9.90, accu = 0.70, validation: 0.69 (600.3 examples/sec; 0.213 sec/batch)
2016-12-03 01:01:25.783067: step 410, loss = 9.94, accu = 0.62, validation: 0.68 (624.5 examples/sec; 0.205 sec/batch)
2016-12-03 01:01:27.923298: step 420, loss = 9.84, accu = 0.67, validation: 0.63 (608.7 examples/sec; 0.210 sec/batch)
2016-12-03 01:01:30.029780: step 430, loss = 9.78, accu = 0.70, validation: 0.62 (617.4 examples/sec; 0.207 sec/batch)
2016-12-03 01:01:32.177158: step 440, loss = 9.81, accu = 0.62, validation: 0.69 (608.5 examples/sec; 0.210 sec/batch)
2016-12-03 01:01:34.317115: step 450, loss = 9.80, accu = 0.62, validation: 0.64 (614.5 examples/sec; 0.208 sec/batch)
2016-12-03 01:01:36.453872: step 460, loss = 9.52, accu = 0.66, validation: 0.68 (617.2 examples/sec; 0.207 sec/batch)
2016-12-03 01:01:38.609784: step 470, loss = 9.57, accu = 0.62, validation: 0.71 (593.9 examples/sec; 0.216 sec/batch)
2016-12-03 01:01:40.712821: step 480, loss = 9.51, accu = 0.64, validation: 0.59 (627.0 examples/sec; 0.204 sec/batch)
2016-12-03 01:01:42.795526: step 490, loss = 9.27, accu = 0.71, validation: 0.62 (607.2 examples/sec; 0.211 sec/batch)
2016-12-03 01:01:44.933593: step 500, loss = 9.37, accu = 0.61, validation: 0.70 (587.1 examples/sec; 0.218 sec/batch)
2016-12-03 01:01:47.174998: step 510, loss = 9.31, accu = 0.60, validation: 0.62 (592.2 examples/sec; 0.216 sec/batch)
2016-12-03 01:01:49.284330: step 520, loss = 9.30, accu = 0.59, validation: 0.66 (608.3 examples/sec; 0.210 sec/batch)
2016-12-03 01:01:51.402446: step 530, loss = 9.19, accu = 0.66, validation: 0.58 (603.6 examples/sec; 0.212 sec/batch)
2016-12-03 01:01:53.491376: step 540, loss = 9.21, accu = 0.59, validation: 0.62 (619.9 examples/sec; 0.206 sec/batch)
2016-12-03 01:01:55.608853: step 550, loss = 9.02, accu = 0.66, validation: 0.65 (608.9 examples/sec; 0.210 sec/batch)
2016-12-03 01:01:57.725641: step 560, loss = 8.98, accu = 0.64, validation: 0.62 (602.3 examples/sec; 0.213 sec/batch)
2016-12-03 01:01:59.838382: step 570, loss = 8.93, accu = 0.61, validation: 0.66 (638.7 examples/sec; 0.200 sec/batch)
2016-12-03 01:02:01.935233: step 580, loss = 8.88, accu = 0.66, validation: 0.63 (585.5 examples/sec; 0.219 sec/batch)
2016-12-03 01:02:04.037060: step 590, loss = 8.73, accu = 0.64, validation: 0.58 (599.4 examples/sec; 0.214 sec/batch)
2016-12-03 01:02:06.162216: step 600, loss = 8.57, accu = 0.70, validation: 0.66 (596.6 examples/sec; 0.215 sec/batch)
2016-12-03 01:02:08.556778: step 610, loss = 8.58, accu = 0.66, validation: 0.68 (594.2 examples/sec; 0.215 sec/batch)
2016-12-03 01:02:10.689356: step 620, loss = 8.46, accu = 0.66, validation: 0.73 (625.9 examples/sec; 0.205 sec/batch)
2016-12-03 01:02:12.804333: step 630, loss = 8.36, accu = 0.70, validation: 0.69 (636.6 examples/sec; 0.201 sec/batch)
2016-12-03 01:02:14.933040: step 640, loss = 8.38, accu = 0.67, validation: 0.56 (596.1 examples/sec; 0.215 sec/batch)
2016-12-03 01:02:17.010876: step 650, loss = 8.46, accu = 0.65, validation: 0.58 (585.3 examples/sec; 0.219 sec/batch)
2016-12-03 01:02:19.112283: step 660, loss = 8.30, accu = 0.63, validation: 0.67 (593.8 examples/sec; 0.216 sec/batch)
2016-12-03 01:02:21.212220: step 670, loss = 8.35, accu = 0.62, validation: 0.68 (634.5 examples/sec; 0.202 sec/batch)
2016-12-03 01:02:23.331132: step 680, loss = 8.07, accu = 0.74, validation: 0.69 (598.0 examples/sec; 0.214 sec/batch)
2016-12-03 01:02:25.427094: step 690, loss = 8.10, accu = 0.67, validation: 0.69 (598.0 examples/sec; 0.214 sec/batch)
2016-12-03 01:02:27.563905: step 700, loss = 8.19, accu = 0.58, validation: 0.63 (596.3 examples/sec; 0.215 sec/batch)
2016-12-03 01:02:29.787544: step 710, loss = 8.09, accu = 0.65, validation: 0.70 (600.8 examples/sec; 0.213 sec/batch)
2016-12-03 01:02:31.925251: step 720, loss = 7.93, accu = 0.70, validation: 0.70 (606.2 examples/sec; 0.211 sec/batch)
2016-12-03 01:02:34.028572: step 730, loss = 7.86, accu = 0.67, validation: 0.66 (602.1 examples/sec; 0.213 sec/batch)
2016-12-03 01:02:36.146207: step 740, loss = 7.82, accu = 0.67, validation: 0.69 (582.3 examples/sec; 0.220 sec/batch)
2016-12-03 01:02:38.240330: step 750, loss = 7.79, accu = 0.61, validation: 0.62 (624.5 examples/sec; 0.205 sec/batch)
2016-12-03 01:02:40.347982: step 760, loss = 7.83, accu = 0.60, validation: 0.66 (582.5 examples/sec; 0.220 sec/batch)
2016-12-03 01:02:42.481161: step 770, loss = 7.68, accu = 0.66, validation: 0.66 (612.2 examples/sec; 0.209 sec/batch)
2016-12-03 01:02:44.591955: step 780, loss = 7.62, accu = 0.65, validation: 0.69 (638.5 examples/sec; 0.200 sec/batch)
2016-12-03 01:02:46.722359: step 790, loss = 7.49, accu = 0.66, validation: 0.62 (602.2 examples/sec; 0.213 sec/batch)
2016-12-03 01:02:48.859381: step 800, loss = 7.48, accu = 0.69, validation: 0.69 (588.9 examples/sec; 0.217 sec/batch)
2016-12-03 01:02:51.147116: step 810, loss = 7.39, accu = 0.66, validation: 0.60 (624.8 examples/sec; 0.205 sec/batch)
2016-12-03 01:02:53.264501: step 820, loss = 7.36, accu = 0.67, validation: 0.69 (589.7 examples/sec; 0.217 sec/batch)
2016-12-03 01:02:55.393625: step 830, loss = 7.27, accu = 0.73, validation: 0.75 (592.7 examples/sec; 0.216 sec/batch)
2016-12-03 01:02:57.526486: step 840, loss = 7.40, accu = 0.63, validation: 0.67 (590.3 examples/sec; 0.217 sec/batch)
2016-12-03 01:02:59.660649: step 850, loss = 7.32, accu = 0.68, validation: 0.65 (590.7 examples/sec; 0.217 sec/batch)
2016-12-03 01:03:01.782105: step 860, loss = 7.17, accu = 0.66, validation: 0.70 (616.0 examples/sec; 0.208 sec/batch)
2016-12-03 01:03:03.935905: step 870, loss = 7.13, accu = 0.70, validation: 0.70 (619.9 examples/sec; 0.206 sec/batch)
2016-12-03 01:03:06.071098: step 880, loss = 7.08, accu = 0.65, validation: 0.68 (596.4 examples/sec; 0.215 sec/batch)
2016-12-03 01:03:08.197764: step 890, loss = 7.30, accu = 0.55, validation: 0.68 (615.2 examples/sec; 0.208 sec/batch)
2016-12-03 01:03:10.325915: step 900, loss = 7.06, accu = 0.62, validation: 0.73 (625.7 examples/sec; 0.205 sec/batch)
2016-12-03 01:03:12.557627: step 910, loss = 6.94, accu = 0.65, validation: 0.70 (583.6 examples/sec; 0.219 sec/batch)
2016-12-03 01:03:14.721343: step 920, loss = 6.88, accu = 0.63, validation: 0.66 (583.5 examples/sec; 0.219 sec/batch)
2016-12-03 01:03:16.843499: step 930, loss = 6.70, accu = 0.70, validation: 0.72 (581.7 examples/sec; 0.220 sec/batch)
2016-12-03 01:03:18.966023: step 940, loss = 6.77, accu = 0.69, validation: 0.66 (578.1 examples/sec; 0.221 sec/batch)
2016-12-03 01:03:21.068186: step 950, loss = 6.78, accu = 0.61, validation: 0.66 (621.5 examples/sec; 0.206 sec/batch)
2016-12-03 01:03:23.204564: step 960, loss = 6.67, accu = 0.65, validation: 0.66 (665.8 examples/sec; 0.192 sec/batch)
2016-12-03 01:03:25.328065: step 970, loss = 6.65, accu = 0.63, validation: 0.72 (598.3 examples/sec; 0.214 sec/batch)
2016-12-03 01:03:27.489471: step 980, loss = 6.60, accu = 0.69, validation: 0.66 (583.9 examples/sec; 0.219 sec/batch)
2016-12-03 01:03:29.602935: step 990, loss = 6.46, accu = 0.74, validation: 0.62 (627.2 examples/sec; 0.204 sec/batch)
2016-12-03 01:03:31.720314: step 1000, loss = 6.56, accu = 0.64, validation: 0.61 (614.7 examples/sec; 0.208 sec/batch)
2016-12-03 01:03:34.577433: step 1010, loss = 6.38, accu = 0.67, validation: 0.74 (605.4 examples/sec; 0.211 sec/batch)
2016-12-03 01:03:36.691761: step 1020, loss = 6.45, accu = 0.66, validation: 0.73 (588.8 examples/sec; 0.217 sec/batch)
2016-12-03 01:03:38.751154: step 1030, loss = 6.26, accu = 0.71, validation: 0.72 (639.0 examples/sec; 0.200 sec/batch)
2016-12-03 01:03:40.924669: step 1040, loss = 6.28, accu = 0.66, validation: 0.66 (590.7 examples/sec; 0.217 sec/batch)
2016-12-03 01:03:43.074375: step 1050, loss = 6.24, accu = 0.71, validation: 0.67 (594.2 examples/sec; 0.215 sec/batch)
2016-12-03 01:03:45.236722: step 1060, loss = 6.17, accu = 0.71, validation: 0.68 (603.2 examples/sec; 0.212 sec/batch)
2016-12-03 01:03:47.386979: step 1070, loss = 6.10, accu = 0.70, validation: 0.64 (612.9 examples/sec; 0.209 sec/batch)
2016-12-03 01:03:49.545930: step 1080, loss = 6.00, accu = 0.72, validation: 0.74 (578.2 examples/sec; 0.221 sec/batch)
2016-12-03 01:03:51.670976: step 1090, loss = 6.13, accu = 0.66, validation: 0.70 (585.4 examples/sec; 0.219 sec/batch)
2016-12-03 01:03:53.819474: step 1100, loss = 6.10, accu = 0.66, validation: 0.60 (633.1 examples/sec; 0.202 sec/batch)
2016-12-03 01:03:56.079738: step 1110, loss = 6.00, accu = 0.70, validation: 0.62 (610.1 examples/sec; 0.210 sec/batch)
2016-12-03 01:03:58.206556: step 1120, loss = 5.98, accu = 0.68, validation: 0.65 (605.6 examples/sec; 0.211 sec/batch)
2016-12-03 01:04:00.373874: step 1130, loss = 5.90, accu = 0.66, validation: 0.69 (587.4 examples/sec; 0.218 sec/batch)
2016-12-03 01:04:02.543303: step 1140, loss = 5.84, accu = 0.68, validation: 0.73 (579.0 examples/sec; 0.221 sec/batch)
2016-12-03 01:04:04.708865: step 1150, loss = 5.87, accu = 0.67, validation: 0.70 (615.5 examples/sec; 0.208 sec/batch)
2016-12-03 01:04:06.854897: step 1160, loss = 5.86, accu = 0.61, validation: 0.62 (584.3 examples/sec; 0.219 sec/batch)
2016-12-03 01:04:09.005323: step 1170, loss = 5.81, accu = 0.62, validation: 0.68 (621.8 examples/sec; 0.206 sec/batch)
2016-12-03 01:04:11.149455: step 1180, loss = 5.65, accu = 0.70, validation: 0.73 (588.6 examples/sec; 0.217 sec/batch)
2016-12-03 01:04:13.269614: step 1190, loss = 5.70, accu = 0.65, validation: 0.66 (605.8 examples/sec; 0.211 sec/batch)
2016-12-03 01:04:15.420971: step 1200, loss = 5.77, accu = 0.61, validation: 0.70 (579.5 examples/sec; 0.221 sec/batch)
2016-12-03 01:04:17.701735: step 1210, loss = 5.53, accu = 0.75, validation: 0.65 (579.3 examples/sec; 0.221 sec/batch)
2016-12-03 01:04:19.834258: step 1220, loss = 5.47, accu = 0.73, validation: 0.69 (598.2 examples/sec; 0.214 sec/batch)
2016-12-03 01:04:22.016656: step 1230, loss = 5.55, accu = 0.68, validation: 0.66 (586.4 examples/sec; 0.218 sec/batch)
2016-12-03 01:04:24.158340: step 1240, loss = 5.65, accu = 0.66, validation: 0.70 (587.8 examples/sec; 0.218 sec/batch)
2016-12-03 01:04:26.301562: step 1250, loss = 5.52, accu = 0.66, validation: 0.67 (597.9 examples/sec; 0.214 sec/batch)
2016-12-03 01:04:28.441940: step 1260, loss = 5.53, accu = 0.63, validation: 0.76 (599.5 examples/sec; 0.214 sec/batch)
2016-12-03 01:04:30.592257: step 1270, loss = 5.60, accu = 0.60, validation: 0.62 (595.1 examples/sec; 0.215 sec/batch)
2016-12-03 01:04:32.726091: step 1280, loss = 5.42, accu = 0.62, validation: 0.71 (605.0 examples/sec; 0.212 sec/batch)
2016-12-03 01:04:34.884462: step 1290, loss = 5.35, accu = 0.65, validation: 0.76 (586.1 examples/sec; 0.218 sec/batch)
2016-12-03 01:04:37.016295: step 1300, loss = 5.27, accu = 0.72, validation: 0.70 (567.5 examples/sec; 0.226 sec/batch)
2016-12-03 01:04:39.310728: step 1310, loss = 5.23, accu = 0.76, validation: 0.63 (563.0 examples/sec; 0.227 sec/batch)
2016-12-03 01:04:41.462853: step 1320, loss = 5.19, accu = 0.65, validation: 0.64 (561.5 examples/sec; 0.228 sec/batch)
2016-12-03 01:04:43.583460: step 1330, loss = 5.13, accu = 0.70, validation: 0.68 (613.1 examples/sec; 0.209 sec/batch)
2016-12-03 01:04:45.718018: step 1340, loss = 5.20, accu = 0.66, validation: 0.66 (635.4 examples/sec; 0.201 sec/batch)
2016-12-03 01:04:47.862226: step 1350, loss = 5.05, accu = 0.71, validation: 0.66 (603.6 examples/sec; 0.212 sec/batch)
2016-12-03 01:04:49.999552: step 1360, loss = 5.11, accu = 0.65, validation: 0.73 (601.6 examples/sec; 0.213 sec/batch)
2016-12-03 01:04:52.153444: step 1370, loss = 5.02, accu = 0.66, validation: 0.75 (586.1 examples/sec; 0.218 sec/batch)
2016-12-03 01:04:54.306762: step 1380, loss = 4.86, accu = 0.75, validation: 0.71 (584.8 examples/sec; 0.219 sec/batch)
2016-12-03 01:04:56.446900: step 1390, loss = 4.88, accu = 0.72, validation: 0.71 (573.8 examples/sec; 0.223 sec/batch)
2016-12-03 01:04:58.616170: step 1400, loss = 4.80, accu = 0.71, validation: 0.73 (578.5 examples/sec; 0.221 sec/batch)
2016-12-03 01:05:00.866033: step 1410, loss = 4.81, accu = 0.77, validation: 0.64 (613.8 examples/sec; 0.209 sec/batch)
2016-12-03 01:05:03.013501: step 1420, loss = 4.84, accu = 0.68, validation: 0.68 (604.3 examples/sec; 0.212 sec/batch)
2016-12-03 01:05:05.153246: step 1430, loss = 4.77, accu = 0.72, validation: 0.73 (593.0 examples/sec; 0.216 sec/batch)
2016-12-03 01:05:07.322255: step 1440, loss = 4.77, accu = 0.68, validation: 0.73 (610.5 examples/sec; 0.210 sec/batch)
2016-12-03 01:05:09.474696: step 1450, loss = 4.66, accu = 0.76, validation: 0.73 (596.8 examples/sec; 0.214 sec/batch)
2016-12-03 01:05:11.619264: step 1460, loss = 4.75, accu = 0.68, validation: 0.63 (594.9 examples/sec; 0.215 sec/batch)
2016-12-03 01:05:13.733246: step 1470, loss = 4.59, accu = 0.73, validation: 0.70 (619.1 examples/sec; 0.207 sec/batch)
2016-12-03 01:05:15.861802: step 1480, loss = 4.67, accu = 0.70, validation: 0.69 (579.2 examples/sec; 0.221 sec/batch)
2016-12-03 01:05:18.030786: step 1490, loss = 4.78, accu = 0.64, validation: 0.73 (581.4 examples/sec; 0.220 sec/batch)
2016-12-03 01:05:20.157976: step 1500, loss = 4.61, accu = 0.69, validation: 0.70 (614.8 examples/sec; 0.208 sec/batch)
2016-12-03 01:05:22.402266: step 1510, loss = 4.59, accu = 0.67, validation: 0.70 (597.0 examples/sec; 0.214 sec/batch)
2016-12-03 01:05:24.525462: step 1520, loss = 4.49, accu = 0.73, validation: 0.70 (620.1 examples/sec; 0.206 sec/batch)
2016-12-03 01:05:26.664132: step 1530, loss = 4.55, accu = 0.66, validation: 0.66 (580.6 examples/sec; 0.220 sec/batch)
2016-12-03 01:05:28.802229: step 1540, loss = 4.46, accu = 0.72, validation: 0.71 (602.6 examples/sec; 0.212 sec/batch)
2016-12-03 01:05:30.922621: step 1550, loss = 4.54, accu = 0.63, validation: 0.66 (645.3 examples/sec; 0.198 sec/batch)
2016-12-03 01:05:33.053460: step 1560, loss = 4.41, accu = 0.70, validation: 0.66 (570.3 examples/sec; 0.224 sec/batch)
2016-12-03 01:05:35.189547: step 1570, loss = 4.31, accu = 0.71, validation: 0.66 (593.7 examples/sec; 0.216 sec/batch)
2016-12-03 01:05:37.303117: step 1580, loss = 4.51, accu = 0.61, validation: 0.70 (589.9 examples/sec; 0.217 sec/batch)
2016-12-03 01:05:39.426849: step 1590, loss = 4.33, accu = 0.70, validation: 0.74 (592.2 examples/sec; 0.216 sec/batch)
2016-12-03 01:05:41.542832: step 1600, loss = 4.18, accu = 0.73, validation: 0.76 (634.5 examples/sec; 0.202 sec/batch)
2016-12-03 01:05:43.932540: step 1610, loss = 4.20, accu = 0.71, validation: 0.73 (592.1 examples/sec; 0.216 sec/batch)
2016-12-03 01:05:46.093854: step 1620, loss = 4.19, accu = 0.71, validation: 0.64 (612.8 examples/sec; 0.209 sec/batch)
2016-12-03 01:05:48.221233: step 1630, loss = 4.22, accu = 0.66, validation: 0.70 (597.7 examples/sec; 0.214 sec/batch)
2016-12-03 01:05:50.341389: step 1640, loss = 4.26, accu = 0.63, validation: 0.66 (597.1 examples/sec; 0.214 sec/batch)
2016-12-03 01:05:52.474983: step 1650, loss = 4.19, accu = 0.72, validation: 0.67 (578.0 examples/sec; 0.221 sec/batch)
2016-12-03 01:05:54.619188: step 1660, loss = 4.12, accu = 0.69, validation: 0.72 (639.1 examples/sec; 0.200 sec/batch)
2016-12-03 01:05:56.753443: step 1670, loss = 4.07, accu = 0.70, validation: 0.67 (600.1 examples/sec; 0.213 sec/batch)
2016-12-03 01:05:58.890787: step 1680, loss = 4.12, accu = 0.69, validation: 0.62 (587.4 examples/sec; 0.218 sec/batch)
2016-12-03 01:06:01.038813: step 1690, loss = 4.18, accu = 0.65, validation: 0.68 (626.6 examples/sec; 0.204 sec/batch)
2016-12-03 01:06:03.177554: step 1700, loss = 4.00, accu = 0.72, validation: 0.73 (563.7 examples/sec; 0.227 sec/batch)
2016-12-03 01:06:05.480881: step 1710, loss = 4.15, accu = 0.62, validation: 0.67 (579.5 examples/sec; 0.221 sec/batch)
2016-12-03 01:06:07.603081: step 1720, loss = 3.88, accu = 0.77, validation: 0.78 (619.2 examples/sec; 0.207 sec/batch)
2016-12-03 01:06:09.749001: step 1730, loss = 3.87, accu = 0.69, validation: 0.66 (567.5 examples/sec; 0.226 sec/batch)
2016-12-03 01:06:11.828154: step 1740, loss = 3.85, accu = 0.72, validation: 0.76 (627.5 examples/sec; 0.204 sec/batch)
2016-12-03 01:06:13.974001: step 1750, loss = 3.99, accu = 0.65, validation: 0.71 (593.8 examples/sec; 0.216 sec/batch)
2016-12-03 01:06:16.086590: step 1760, loss = 3.81, accu = 0.72, validation: 0.74 (591.0 examples/sec; 0.217 sec/batch)
2016-12-03 01:06:18.204012: step 1770, loss = 3.89, accu = 0.67, validation: 0.66 (593.4 examples/sec; 0.216 sec/batch)
2016-12-03 01:06:20.332253: step 1780, loss = 3.84, accu = 0.70, validation: 0.59 (572.5 examples/sec; 0.224 sec/batch)
2016-12-03 01:06:22.460498: step 1790, loss = 3.75, accu = 0.73, validation: 0.70 (609.4 examples/sec; 0.210 sec/batch)
2016-12-03 01:06:24.579305: step 1800, loss = 3.68, accu = 0.77, validation: 0.68 (611.7 examples/sec; 0.209 sec/batch)
2016-12-03 01:06:26.823365: step 1810, loss = 3.73, accu = 0.74, validation: 0.70 (617.6 examples/sec; 0.207 sec/batch)
2016-12-03 01:06:28.956490: step 1820, loss = 3.64, accu = 0.74, validation: 0.70 (588.3 examples/sec; 0.218 sec/batch)
2016-12-03 01:06:31.113330: step 1830, loss = 3.78, accu = 0.62, validation: 0.68 (555.8 examples/sec; 0.230 sec/batch)
2016-12-03 01:06:33.250102: step 1840, loss = 3.60, accu = 0.77, validation: 0.70 (596.5 examples/sec; 0.215 sec/batch)
2016-12-03 01:06:35.378519: step 1850, loss = 3.67, accu = 0.69, validation: 0.70 (585.0 examples/sec; 0.219 sec/batch)
2016-12-03 01:06:37.532125: step 1860, loss = 3.59, accu = 0.70, validation: 0.77 (581.7 examples/sec; 0.220 sec/batch)
2016-12-03 01:06:39.676632: step 1870, loss = 3.51, accu = 0.79, validation: 0.76 (603.6 examples/sec; 0.212 sec/batch)
2016-12-03 01:06:41.810465: step 1880, loss = 3.60, accu = 0.73, validation: 0.68 (613.5 examples/sec; 0.209 sec/batch)
2016-12-03 01:06:43.916107: step 1890, loss = 3.51, accu = 0.73, validation: 0.72 (647.1 examples/sec; 0.198 sec/batch)
2016-12-03 01:06:46.064545: step 1900, loss = 3.68, accu = 0.66, validation: 0.79 (622.6 examples/sec; 0.206 sec/batch)
2016-12-03 01:06:48.493388: step 1910, loss = 3.51, accu = 0.70, validation: 0.73 (564.7 examples/sec; 0.227 sec/batch)
2016-12-03 01:06:50.639082: step 1920, loss = 3.34, accu = 0.83, validation: 0.72 (632.1 examples/sec; 0.203 sec/batch)
2016-12-03 01:06:52.752208: step 1930, loss = 3.36, accu = 0.75, validation: 0.77 (636.2 examples/sec; 0.201 sec/batch)
2016-12-03 01:06:54.883113: step 1940, loss = 3.44, accu = 0.71, validation: 0.76 (630.1 examples/sec; 0.203 sec/batch)
2016-12-03 01:06:57.013879: step 1950, loss = 3.54, accu = 0.68, validation: 0.70 (589.4 examples/sec; 0.217 sec/batch)
2016-12-03 01:06:59.149155: step 1960, loss = 3.45, accu = 0.69, validation: 0.70 (640.5 examples/sec; 0.200 sec/batch)
2016-12-03 01:07:01.263224: step 1970, loss = 3.45, accu = 0.68, validation: 0.62 (617.8 examples/sec; 0.207 sec/batch)
2016-12-03 01:07:03.400072: step 1980, loss = 3.22, accu = 0.81, validation: 0.66 (580.6 examples/sec; 0.220 sec/batch)
2016-12-03 01:07:05.508094: step 1990, loss = 3.32, accu = 0.75, validation: 0.70 (587.2 examples/sec; 0.218 sec/batch)
2016-12-03 01:07:07.645020: step 2000, loss = 3.15, accu = 0.79, validation: 0.80 (613.3 examples/sec; 0.209 sec/batch)
2016-12-03 01:07:10.418359: step 2010, loss = 3.25, accu = 0.72, validation: 0.70 (589.3 examples/sec; 0.217 sec/batch)
2016-12-03 01:07:12.544202: step 2020, loss = 3.35, accu = 0.71, validation: 0.70 (599.9 examples/sec; 0.213 sec/batch)
2016-12-03 01:07:14.593046: step 2030, loss = 3.31, accu = 0.68, validation: 0.63 (610.8 examples/sec; 0.210 sec/batch)
2016-12-03 01:07:16.712811: step 2040, loss = 3.48, accu = 0.62, validation: 0.74 (560.8 examples/sec; 0.228 sec/batch)
2016-12-03 01:07:18.881410: step 2050, loss = 3.18, accu = 0.69, validation: 0.73 (585.3 examples/sec; 0.219 sec/batch)
2016-12-03 01:07:21.012967: step 2060, loss = 3.12, accu = 0.76, validation: 0.75 (605.9 examples/sec; 0.211 sec/batch)
2016-12-03 01:07:23.160283: step 2070, loss = 3.15, accu = 0.74, validation: 0.77 (578.5 examples/sec; 0.221 sec/batch)
2016-12-03 01:07:25.317159: step 2080, loss = 3.10, accu = 0.76, validation: 0.62 (608.5 examples/sec; 0.210 sec/batch)
2016-12-03 01:07:27.492470: step 2090, loss = 3.04, accu = 0.77, validation: 0.67 (572.5 examples/sec; 0.224 sec/batch)
2016-12-03 01:07:29.671533: step 2100, loss = 3.01, accu = 0.77, validation: 0.66 (581.1 examples/sec; 0.220 sec/batch)
2016-12-03 01:07:31.960687: step 2110, loss = 3.16, accu = 0.66, validation: 0.77 (610.0 examples/sec; 0.210 sec/batch)
2016-12-03 01:07:34.142699: step 2120, loss = 3.14, accu = 0.69, validation: 0.70 (639.2 examples/sec; 0.200 sec/batch)
2016-12-03 01:07:36.326904: step 2130, loss = 3.03, accu = 0.74, validation: 0.62 (571.7 examples/sec; 0.224 sec/batch)
2016-12-03 01:07:38.490289: step 2140, loss = 3.08, accu = 0.70, validation: 0.66 (577.9 examples/sec; 0.221 sec/batch)
2016-12-03 01:07:40.676797: step 2150, loss = 2.99, accu = 0.73, validation: 0.73 (567.5 examples/sec; 0.226 sec/batch)
2016-12-03 01:07:42.840175: step 2160, loss = 2.99, accu = 0.72, validation: 0.77 (568.2 examples/sec; 0.225 sec/batch)
2016-12-03 01:07:45.067412: step 2170, loss = 3.06, accu = 0.70, validation: 0.74 (563.4 examples/sec; 0.227 sec/batch)
2016-12-03 01:07:47.302985: step 2180, loss = 3.02, accu = 0.73, validation: 0.71 (581.0 examples/sec; 0.220 sec/batch)
2016-12-03 01:07:49.512750: step 2190, loss = 3.01, accu = 0.70, validation: 0.66 (536.6 examples/sec; 0.239 sec/batch)
2016-12-03 01:07:51.732683: step 2200, loss = 2.92, accu = 0.73, validation: 0.74 (554.7 examples/sec; 0.231 sec/batch)
2016-12-03 01:07:54.247108: step 2210, loss = 2.93, accu = 0.73, validation: 0.74 (529.3 examples/sec; 0.242 sec/batch)
2016-12-03 01:07:56.649039: step 2220, loss = 2.84, accu = 0.76, validation: 0.73 (538.4 examples/sec; 0.238 sec/batch)
2016-12-03 01:07:59.105063: step 2230, loss = 2.92, accu = 0.71, validation: 0.70 (502.7 examples/sec; 0.255 sec/batch)
2016-12-03 01:08:01.759169: step 2240, loss = 2.87, accu = 0.73, validation: 0.68 (476.3 examples/sec; 0.269 sec/batch)
2016-12-03 01:08:04.829814: step 2250, loss = 2.80, accu = 0.70, validation: 0.65 (393.7 examples/sec; 0.325 sec/batch)
2016-12-03 01:08:08.044670: step 2260, loss = 2.80, accu = 0.74, validation: 0.67 (398.6 examples/sec; 0.321 sec/batch)
2016-12-03 01:08:11.268439: step 2270, loss = 2.73, accu = 0.79, validation: 0.73 (397.7 examples/sec; 0.322 sec/batch)
2016-12-03 01:08:14.497126: step 2280, loss = 2.63, accu = 0.78, validation: 0.75 (391.8 examples/sec; 0.327 sec/batch)
2016-12-03 01:08:17.735708: step 2290, loss = 2.81, accu = 0.72, validation: 0.73 (394.0 examples/sec; 0.325 sec/batch)
2016-12-03 01:08:21.344638: step 2300, loss = 2.70, accu = 0.74, validation: 0.71 (301.5 examples/sec; 0.425 sec/batch)
2016-12-03 01:08:25.120868: step 2310, loss = 2.71, accu = 0.74, validation: 0.75 (371.5 examples/sec; 0.345 sec/batch)
2016-12-03 01:08:28.731076: step 2320, loss = 2.74, accu = 0.71, validation: 0.77 (379.2 examples/sec; 0.338 sec/batch)
2016-12-03 01:08:32.340820: step 2330, loss = 2.51, accu = 0.80, validation: 0.72 (354.0 examples/sec; 0.362 sec/batch)
2016-12-03 01:08:35.861533: step 2340, loss = 2.62, accu = 0.73, validation: 0.72 (369.1 examples/sec; 0.347 sec/batch)
2016-12-03 01:08:39.368806: step 2350, loss = 2.61, accu = 0.78, validation: 0.73 (361.9 examples/sec; 0.354 sec/batch)
2016-12-03 01:08:42.883812: step 2360, loss = 2.76, accu = 0.69, validation: 0.70 (365.2 examples/sec; 0.351 sec/batch)
2016-12-03 01:08:46.393501: step 2370, loss = 2.82, accu = 0.60, validation: 0.70 (375.9 examples/sec; 0.341 sec/batch)
2016-12-03 01:08:49.864361: step 2380, loss = 2.85, accu = 0.68, validation: 0.62 (368.6 examples/sec; 0.347 sec/batch)
2016-12-03 01:08:53.432903: step 2390, loss = 2.56, accu = 0.72, validation: 0.70 (368.0 examples/sec; 0.348 sec/batch)
2016-12-03 01:08:56.902741: step 2400, loss = 2.56, accu = 0.73, validation: 0.66 (375.4 examples/sec; 0.341 sec/batch)
2016-12-03 01:09:00.804019: step 2410, loss = 2.53, accu = 0.77, validation: 0.71 (374.6 examples/sec; 0.342 sec/batch)
2016-12-03 01:09:04.421558: step 2420, loss = 2.48, accu = 0.76, validation: 0.70 (378.0 examples/sec; 0.339 sec/batch)
2016-12-03 01:09:07.889109: step 2430, loss = 2.53, accu = 0.76, validation: 0.77 (370.4 examples/sec; 0.346 sec/batch)
2016-12-03 01:09:11.375326: step 2440, loss = 2.54, accu = 0.74, validation: 0.73 (375.5 examples/sec; 0.341 sec/batch)
2016-12-03 01:09:14.909197: step 2450, loss = 2.51, accu = 0.74, validation: 0.73 (370.5 examples/sec; 0.345 sec/batch)
2016-12-03 01:09:18.387044: step 2460, loss = 2.59, accu = 0.70, validation: 0.65 (367.3 examples/sec; 0.348 sec/batch)
2016-12-03 01:09:21.814341: step 2470, loss = 2.63, accu = 0.69, validation: 0.70 (384.0 examples/sec; 0.333 sec/batch)
2016-12-03 01:09:25.403809: step 2480, loss = 2.37, accu = 0.80, validation: 0.74 (371.9 examples/sec; 0.344 sec/batch)
2016-12-03 01:09:28.890965: step 2490, loss = 2.43, accu = 0.74, validation: 0.70 (369.9 examples/sec; 0.346 sec/batch)
2016-12-03 01:09:32.484892: step 2500, loss = 2.43, accu = 0.75, validation: 0.74 (381.4 examples/sec; 0.336 sec/batch)
2016-12-03 01:09:36.386621: step 2510, loss = 2.35, accu = 0.75, validation: 0.71 (361.1 examples/sec; 0.355 sec/batch)
2016-12-03 01:09:39.861478: step 2520, loss = 2.37, accu = 0.73, validation: 0.76 (379.2 examples/sec; 0.338 sec/batch)
2016-12-03 01:09:43.453338: step 2530, loss = 2.53, accu = 0.70, validation: 0.73 (357.5 examples/sec; 0.358 sec/batch)
2016-12-03 01:09:46.897470: step 2540, loss = 2.39, accu = 0.73, validation: 0.69 (374.4 examples/sec; 0.342 sec/batch)
2016-12-03 01:09:50.483194: step 2550, loss = 2.60, accu = 0.62, validation: 0.67 (353.2 examples/sec; 0.362 sec/batch)
2016-12-03 01:09:53.980004: step 2560, loss = 2.22, accu = 0.81, validation: 0.71 (377.6 examples/sec; 0.339 sec/batch)
2016-12-03 01:09:57.601785: step 2570, loss = 2.32, accu = 0.73, validation: 0.73 (373.8 examples/sec; 0.342 sec/batch)
2016-12-03 01:10:01.257990: step 2580, loss = 2.28, accu = 0.77, validation: 0.76 (301.4 examples/sec; 0.425 sec/batch)
2016-12-03 01:10:04.740051: step 2590, loss = 2.28, accu = 0.79, validation: 0.73 (368.3 examples/sec; 0.348 sec/batch)
2016-12-03 01:10:08.337602: step 2600, loss = 2.33, accu = 0.76, validation: 0.66 (372.9 examples/sec; 0.343 sec/batch)
2016-12-03 01:10:12.119553: step 2610, loss = 2.42, accu = 0.70, validation: 0.68 (351.2 examples/sec; 0.364 sec/batch)
2016-12-03 01:10:15.680601: step 2620, loss = 2.23, accu = 0.74, validation: 0.67 (280.3 examples/sec; 0.457 sec/batch)
2016-12-03 01:10:19.208620: step 2630, loss = 2.40, accu = 0.71, validation: 0.73 (363.3 examples/sec; 0.352 sec/batch)
2016-12-03 01:10:22.734788: step 2640, loss = 2.26, accu = 0.77, validation: 0.73 (367.9 examples/sec; 0.348 sec/batch)
2016-12-03 01:10:26.395690: step 2650, loss = 2.25, accu = 0.77, validation: 0.71 (376.5 examples/sec; 0.340 sec/batch)
2016-12-03 01:10:29.879165: step 2660, loss = 2.38, accu = 0.65, validation: 0.70 (365.7 examples/sec; 0.350 sec/batch)
2016-12-03 01:10:33.490059: step 2670, loss = 2.14, accu = 0.80, validation: 0.77 (362.9 examples/sec; 0.353 sec/batch)
2016-12-03 01:10:37.064165: step 2680, loss = 2.18, accu = 0.78, validation: 0.74 (372.4 examples/sec; 0.344 sec/batch)
2016-12-03 01:10:40.645874: step 2690, loss = 2.30, accu = 0.66, validation: 0.75 (363.2 examples/sec; 0.352 sec/batch)
2016-12-03 01:10:44.123366: step 2700, loss = 2.38, accu = 0.63, validation: 0.55 (373.0 examples/sec; 0.343 sec/batch)
2016-12-03 01:10:48.091151: step 2710, loss = 2.17, accu = 0.75, validation: 0.65 (371.4 examples/sec; 0.345 sec/batch)
2016-12-03 01:10:51.695489: step 2720, loss = 2.27, accu = 0.71, validation: 0.70 (371.0 examples/sec; 0.345 sec/batch)
2016-12-03 01:10:55.166469: step 2730, loss = 2.15, accu = 0.73, validation: 0.73 (360.4 examples/sec; 0.355 sec/batch)
2016-12-03 01:10:58.773089: step 2740, loss = 2.28, accu = 0.68, validation: 0.70 (364.5 examples/sec; 0.351 sec/batch)
2016-12-03 01:11:02.363828: step 2750, loss = 1.90, accu = 0.83, validation: 0.77 (380.4 examples/sec; 0.336 sec/batch)
2016-12-03 01:11:05.833169: step 2760, loss = 1.99, accu = 0.80, validation: 0.68 (376.0 examples/sec; 0.340 sec/batch)
2016-12-03 01:11:09.401986: step 2770, loss = 2.12, accu = 0.72, validation: 0.75 (377.3 examples/sec; 0.339 sec/batch)
2016-12-03 01:11:12.877959: step 2780, loss = 2.20, accu = 0.66, validation: 0.66 (373.1 examples/sec; 0.343 sec/batch)
2016-12-03 01:11:16.524213: step 2790, loss = 2.07, accu = 0.77, validation: 0.73 (331.5 examples/sec; 0.386 sec/batch)
2016-12-03 01:11:20.031220: step 2800, loss = 2.00, accu = 0.83, validation: 0.66 (380.1 examples/sec; 0.337 sec/batch)
2016-12-03 01:11:23.889612: step 2810, loss = 2.03, accu = 0.78, validation: 0.63 (357.1 examples/sec; 0.358 sec/batch)
2016-12-03 01:11:27.362110: step 2820, loss = 2.13, accu = 0.71, validation: 0.71 (379.3 examples/sec; 0.337 sec/batch)
2016-12-03 01:11:31.014621: step 2830, loss = 1.91, accu = 0.80, validation: 0.70 (360.1 examples/sec; 0.355 sec/batch)
2016-12-03 01:11:34.586210: step 2840, loss = 1.99, accu = 0.77, validation: 0.74 (355.2 examples/sec; 0.360 sec/batch)
2016-12-03 01:11:38.225210: step 2850, loss = 1.97, accu = 0.74, validation: 0.68 (344.5 examples/sec; 0.372 sec/batch)
2016-12-03 01:11:41.706169: step 2860, loss = 2.19, accu = 0.69, validation: 0.77 (375.3 examples/sec; 0.341 sec/batch)
2016-12-03 01:11:45.234907: step 2870, loss = 1.93, accu = 0.80, validation: 0.73 (358.3 examples/sec; 0.357 sec/batch)
2016-12-03 01:11:48.830101: step 2880, loss = 2.14, accu = 0.66, validation: 0.66 (373.7 examples/sec; 0.343 sec/batch)
2016-12-03 01:11:52.374331: step 2890, loss = 1.99, accu = 0.77, validation: 0.77 (372.7 examples/sec; 0.343 sec/batch)
2016-12-03 01:11:56.012974: step 2900, loss = 1.92, accu = 0.79, validation: 0.66 (351.0 examples/sec; 0.365 sec/batch)
2016-12-03 01:11:59.850620: step 2910, loss = 1.80, accu = 0.82, validation: 0.69 (353.9 examples/sec; 0.362 sec/batch)
2016-12-03 01:12:03.458819: step 2920, loss = 1.88, accu = 0.79, validation: 0.77 (369.6 examples/sec; 0.346 sec/batch)
2016-12-03 01:12:06.978935: step 2930, loss = 1.73, accu = 0.87, validation: 0.70 (340.4 examples/sec; 0.376 sec/batch)
2016-12-03 01:12:10.543935: step 2940, loss = 1.99, accu = 0.74, validation: 0.70 (367.8 examples/sec; 0.348 sec/batch)
2016-12-03 01:12:14.032998: step 2950, loss = 1.91, accu = 0.75, validation: 0.70 (362.9 examples/sec; 0.353 sec/batch)
2016-12-03 01:12:17.647849: step 2960, loss = 1.98, accu = 0.74, validation: 0.71 (354.8 examples/sec; 0.361 sec/batch)
2016-12-03 01:12:21.232992: step 2970, loss = 1.82, accu = 0.80, validation: 0.79 (368.9 examples/sec; 0.347 sec/batch)
2016-12-03 01:12:24.884641: step 2980, loss = 1.84, accu = 0.80, validation: 0.71 (372.5 examples/sec; 0.344 sec/batch)
2016-12-03 01:12:28.442494: step 2990, loss = 1.88, accu = 0.73, validation: 0.69 (370.5 examples/sec; 0.345 sec/batch)
2016-12-03 01:12:31.950383: step 3000, loss = 1.80, accu = 0.77, validation: 0.66 (374.0 examples/sec; 0.342 sec/batch)
2016-12-03 01:12:36.212581: step 3010, loss = 1.78, accu = 0.77, validation: 0.66 (364.7 examples/sec; 0.351 sec/batch)
2016-12-03 01:12:39.763257: step 3020, loss = 1.71, accu = 0.82, validation: 0.68 (397.3 examples/sec; 0.322 sec/batch)
2016-12-03 01:12:43.437427: step 3030, loss = 1.68, accu = 0.83, validation: 0.74 (369.5 examples/sec; 0.346 sec/batch)
2016-12-03 01:12:46.984077: step 3040, loss = 1.86, accu = 0.72, validation: 0.74 (365.9 examples/sec; 0.350 sec/batch)
2016-12-03 01:12:50.634469: step 3050, loss = 1.83, accu = 0.71, validation: 0.62 (364.4 examples/sec; 0.351 sec/batch)
2016-12-03 01:12:54.151853: step 3060, loss = 1.75, accu = 0.77, validation: 0.68 (381.6 examples/sec; 0.335 sec/batch)
2016-12-03 01:12:57.841710: step 3070, loss = 1.79, accu = 0.76, validation: 0.76 (368.7 examples/sec; 0.347 sec/batch)
2016-12-03 01:13:01.348695: step 3080, loss = 1.70, accu = 0.81, validation: 0.75 (372.0 examples/sec; 0.344 sec/batch)
2016-12-03 01:13:05.086894: step 3090, loss = 1.71, accu = 0.78, validation: 0.76 (336.8 examples/sec; 0.380 sec/batch)
2016-12-03 01:13:08.713105: step 3100, loss = 1.76, accu = 0.75, validation: 0.71 (378.7 examples/sec; 0.338 sec/batch)
2016-12-03 01:13:12.562953: step 3110, loss = 1.71, accu = 0.82, validation: 0.69 (375.0 examples/sec; 0.341 sec/batch)
2016-12-03 01:13:16.132989: step 3120, loss = 1.82, accu = 0.72, validation: 0.70 (357.6 examples/sec; 0.358 sec/batch)
2016-12-03 01:13:19.729115: step 3130, loss = 1.73, accu = 0.77, validation: 0.75 (366.1 examples/sec; 0.350 sec/batch)
2016-12-03 01:13:23.310566: step 3140, loss = 1.68, accu = 0.81, validation: 0.75 (379.7 examples/sec; 0.337 sec/batch)
2016-12-03 01:13:26.870467: step 3150, loss = 1.61, accu = 0.83, validation: 0.65 (371.3 examples/sec; 0.345 sec/batch)
2016-12-03 01:13:30.471588: step 3160, loss = 1.65, accu = 0.78, validation: 0.62 (350.6 examples/sec; 0.365 sec/batch)
2016-12-03 01:13:34.150505: step 3170, loss = 1.71, accu = 0.79, validation: 0.67 (370.0 examples/sec; 0.346 sec/batch)
2016-12-03 01:13:37.741730: step 3180, loss = 1.66, accu = 0.81, validation: 0.72 (385.9 examples/sec; 0.332 sec/batch)
2016-12-03 01:13:41.351018: step 3190, loss = 1.69, accu = 0.77, validation: 0.72 (360.7 examples/sec; 0.355 sec/batch)
2016-12-03 01:13:45.002721: step 3200, loss = 1.65, accu = 0.77, validation: 0.72 (301.4 examples/sec; 0.425 sec/batch)
2016-12-03 01:13:48.740614: step 3210, loss = 1.57, accu = 0.84, validation: 0.71 (368.6 examples/sec; 0.347 sec/batch)
2016-12-03 01:13:52.420843: step 3220, loss = 1.66, accu = 0.78, validation: 0.65 (367.0 examples/sec; 0.349 sec/batch)
2016-12-03 01:13:56.036956: step 3230, loss = 1.52, accu = 0.79, validation: 0.71 (360.3 examples/sec; 0.355 sec/batch)
2016-12-03 01:13:59.573432: step 3240, loss = 1.71, accu = 0.77, validation: 0.76 (373.1 examples/sec; 0.343 sec/batch)
2016-12-03 01:14:03.226541: step 3250, loss = 1.60, accu = 0.79, validation: 0.69 (367.4 examples/sec; 0.348 sec/batch)
2016-12-03 01:14:06.880256: step 3260, loss = 1.70, accu = 0.72, validation: 0.73 (371.8 examples/sec; 0.344 sec/batch)
2016-12-03 01:14:10.605366: step 3270, loss = 1.61, accu = 0.77, validation: 0.66 (280.5 examples/sec; 0.456 sec/batch)
2016-12-03 01:14:14.109295: step 3280, loss = 1.52, accu = 0.79, validation: 0.77 (369.3 examples/sec; 0.347 sec/batch)
2016-12-03 01:14:17.698527: step 3290, loss = 1.60, accu = 0.75, validation: 0.70 (367.3 examples/sec; 0.348 sec/batch)
2016-12-03 01:14:21.209741: step 3300, loss = 1.61, accu = 0.75, validation: 0.70 (363.0 examples/sec; 0.353 sec/batch)
2016-12-03 01:14:25.048953: step 3310, loss = 1.55, accu = 0.79, validation: 0.76 (364.4 examples/sec; 0.351 sec/batch)
2016-12-03 01:14:28.646503: step 3320, loss = 1.48, accu = 0.84, validation: 0.72 (370.7 examples/sec; 0.345 sec/batch)
2016-12-03 01:14:32.244344: step 3330, loss = 1.49, accu = 0.84, validation: 0.71 (381.6 examples/sec; 0.335 sec/batch)
2016-12-03 01:14:35.850500: step 3340, loss = 1.52, accu = 0.80, validation: 0.80 (387.3 examples/sec; 0.330 sec/batch)
2016-12-03 01:14:39.503447: step 3350, loss = 1.59, accu = 0.75, validation: 0.79 (377.4 examples/sec; 0.339 sec/batch)
2016-12-03 01:14:43.140120: step 3360, loss = 1.45, accu = 0.83, validation: 0.66 (365.0 examples/sec; 0.351 sec/batch)
2016-12-03 01:14:46.719850: step 3370, loss = 1.37, accu = 0.84, validation: 0.70 (366.3 examples/sec; 0.349 sec/batch)
2016-12-03 01:14:50.275176: step 3380, loss = 1.50, accu = 0.83, validation: 0.70 (367.5 examples/sec; 0.348 sec/batch)
2016-12-03 01:14:53.898401: step 3390, loss = 1.50, accu = 0.80, validation: 0.71 (376.6 examples/sec; 0.340 sec/batch)
2016-12-03 01:14:57.420840: step 3400, loss = 1.49, accu = 0.80, validation: 0.76 (375.5 examples/sec; 0.341 sec/batch)
2016-12-03 01:15:01.231345: step 3410, loss = 1.47, accu = 0.80, validation: 0.67 (360.0 examples/sec; 0.356 sec/batch)
2016-12-03 01:15:04.903744: step 3420, loss = 1.41, accu = 0.84, validation: 0.70 (375.5 examples/sec; 0.341 sec/batch)
2016-12-03 01:15:08.532803: step 3430, loss = 1.40, accu = 0.84, validation: 0.73 (375.6 examples/sec; 0.341 sec/batch)
2016-12-03 01:15:12.123188: step 3440, loss = 1.54, accu = 0.75, validation: 0.70 (367.1 examples/sec; 0.349 sec/batch)
2016-12-03 01:15:15.712358: step 3450, loss = 1.55, accu = 0.77, validation: 0.69 (382.1 examples/sec; 0.335 sec/batch)
2016-12-03 01:15:19.332764: step 3460, loss = 1.40, accu = 0.82, validation: 0.70 (307.9 examples/sec; 0.416 sec/batch)
2016-12-03 01:15:22.900192: step 3470, loss = 1.42, accu = 0.77, validation: 0.64 (372.6 examples/sec; 0.344 sec/batch)
2016-12-03 01:15:26.493004: step 3480, loss = 1.47, accu = 0.81, validation: 0.65 (310.7 examples/sec; 0.412 sec/batch)
2016-12-03 01:15:30.008621: step 3490, loss = 1.36, accu = 0.87, validation: 0.71 (377.2 examples/sec; 0.339 sec/batch)
2016-12-03 01:15:33.605229: step 3500, loss = 1.52, accu = 0.76, validation: 0.67 (377.6 examples/sec; 0.339 sec/batch)
2016-12-03 01:15:37.458866: step 3510, loss = 1.47, accu = 0.81, validation: 0.64 (362.8 examples/sec; 0.353 sec/batch)
2016-12-03 01:15:41.114636: step 3520, loss = 1.58, accu = 0.76, validation: 0.66 (349.4 examples/sec; 0.366 sec/batch)
2016-12-03 01:15:44.665185: step 3530, loss = 1.48, accu = 0.76, validation: 0.65 (362.0 examples/sec; 0.354 sec/batch)
2016-12-03 01:15:48.237111: step 3540, loss = 1.37, accu = 0.84, validation: 0.71 (364.2 examples/sec; 0.351 sec/batch)
2016-12-03 01:15:51.876000: step 3550, loss = 1.71, accu = 0.70, validation: 0.59 (373.4 examples/sec; 0.343 sec/batch)
2016-12-03 01:15:55.556041: step 3560, loss = 1.39, accu = 0.79, validation: 0.72 (320.2 examples/sec; 0.400 sec/batch)
2016-12-03 01:15:59.063250: step 3570, loss = 1.41, accu = 0.77, validation: 0.67 (380.7 examples/sec; 0.336 sec/batch)
2016-12-03 01:16:02.682285: step 3580, loss = 1.26, accu = 0.86, validation: 0.70 (351.7 examples/sec; 0.364 sec/batch)
2016-12-03 01:16:06.200061: step 3590, loss = 1.32, accu = 0.80, validation: 0.73 (376.8 examples/sec; 0.340 sec/batch)
2016-12-03 01:16:09.844796: step 3600, loss = 1.40, accu = 0.81, validation: 0.75 (362.0 examples/sec; 0.354 sec/batch)
2016-12-03 01:16:13.728038: step 3610, loss = 1.46, accu = 0.80, validation: 0.66 (384.8 examples/sec; 0.333 sec/batch)
2016-12-03 01:16:17.298346: step 3620, loss = 1.31, accu = 0.80, validation: 0.67 (370.2 examples/sec; 0.346 sec/batch)
2016-12-03 01:16:20.922424: step 3630, loss = 1.21, accu = 0.86, validation: 0.67 (381.3 examples/sec; 0.336 sec/batch)
2016-12-03 01:16:24.542452: step 3640, loss = 1.34, accu = 0.81, validation: 0.73 (346.1 examples/sec; 0.370 sec/batch)
2016-12-03 01:16:28.144644: step 3650, loss = 1.65, accu = 0.66, validation: 0.72 (355.9 examples/sec; 0.360 sec/batch)
2016-12-03 01:16:31.749976: step 3660, loss = 1.29, accu = 0.83, validation: 0.72 (387.3 examples/sec; 0.330 sec/batch)
2016-12-03 01:16:35.390777: step 3670, loss = 1.39, accu = 0.75, validation: 0.71 (369.4 examples/sec; 0.346 sec/batch)
2016-12-03 01:16:38.909358: step 3680, loss = 1.45, accu = 0.75, validation: 0.63 (323.4 examples/sec; 0.396 sec/batch)
2016-12-03 01:16:42.525656: step 3690, loss = 1.38, accu = 0.79, validation: 0.77 (352.3 examples/sec; 0.363 sec/batch)
2016-12-03 01:16:45.986878: step 3700, loss = 1.26, accu = 0.80, validation: 0.73 (372.1 examples/sec; 0.344 sec/batch)
2016-12-03 01:16:49.953983: step 3710, loss = 1.32, accu = 0.77, validation: 0.66 (360.6 examples/sec; 0.355 sec/batch)
2016-12-03 01:16:53.543959: step 3720, loss = 1.25, accu = 0.83, validation: 0.66 (300.9 examples/sec; 0.425 sec/batch)
2016-12-03 01:16:57.053591: step 3730, loss = 1.22, accu = 0.82, validation: 0.66 (375.2 examples/sec; 0.341 sec/batch)
2016-12-03 01:17:00.721131: step 3740, loss = 1.37, accu = 0.74, validation: 0.69 (341.8 examples/sec; 0.375 sec/batch)
2016-12-03 01:17:04.367400: step 3750, loss = 1.32, accu = 0.72, validation: 0.74 (370.1 examples/sec; 0.346 sec/batch)
2016-12-03 01:17:08.033467: step 3760, loss = 1.17, accu = 0.86, validation: 0.73 (363.7 examples/sec; 0.352 sec/batch)
2016-12-03 01:17:11.549720: step 3770, loss = 1.19, accu = 0.84, validation: 0.73 (370.5 examples/sec; 0.345 sec/batch)
2016-12-03 01:17:15.215956: step 3780, loss = 1.23, accu = 0.86, validation: 0.73 (366.5 examples/sec; 0.349 sec/batch)
2016-12-03 01:17:18.819506: step 3790, loss = 1.33, accu = 0.77, validation: 0.66 (368.4 examples/sec; 0.347 sec/batch)
2016-12-03 01:17:22.442149: step 3800, loss = 1.24, accu = 0.85, validation: 0.77 (379.3 examples/sec; 0.337 sec/batch)
2016-12-03 01:17:26.321659: step 3810, loss = 1.20, accu = 0.87, validation: 0.77 (373.7 examples/sec; 0.342 sec/batch)
2016-12-03 01:17:29.934537: step 3820, loss = 1.18, accu = 0.83, validation: 0.68 (369.5 examples/sec; 0.346 sec/batch)
2016-12-03 01:17:33.533361: step 3830, loss = 1.47, accu = 0.75, validation: 0.69 (368.8 examples/sec; 0.347 sec/batch)
2016-12-03 01:17:37.144088: step 3840, loss = 1.24, accu = 0.84, validation: 0.65 (336.8 examples/sec; 0.380 sec/batch)
2016-12-03 01:17:40.713168: step 3850, loss = 1.34, accu = 0.77, validation: 0.74 (280.5 examples/sec; 0.456 sec/batch)
2016-12-03 01:17:44.379208: step 3860, loss = 1.10, accu = 0.88, validation: 0.69 (357.7 examples/sec; 0.358 sec/batch)
2016-12-03 01:17:47.977691: step 3870, loss = 1.18, accu = 0.84, validation: 0.70 (362.2 examples/sec; 0.353 sec/batch)
2016-12-03 01:17:51.485030: step 3880, loss = 1.27, accu = 0.78, validation: 0.66 (369.6 examples/sec; 0.346 sec/batch)
2016-12-03 01:17:55.172254: step 3890, loss = 1.24, accu = 0.86, validation: 0.69 (373.6 examples/sec; 0.343 sec/batch)
2016-12-03 01:17:58.765395: step 3900, loss = 1.15, accu = 0.82, validation: 0.70 (364.7 examples/sec; 0.351 sec/batch)
2016-12-03 01:18:02.563084: step 3910, loss = 1.13, accu = 0.87, validation: 0.71 (380.2 examples/sec; 0.337 sec/batch)
2016-12-03 01:18:06.182429: step 3920, loss = 1.16, accu = 0.86, validation: 0.68 (372.6 examples/sec; 0.344 sec/batch)
2016-12-03 01:18:09.818394: step 3930, loss = 1.29, accu = 0.79, validation: 0.63 (379.0 examples/sec; 0.338 sec/batch)
2016-12-03 01:18:13.536124: step 3940, loss = 1.16, accu = 0.82, validation: 0.66 (366.0 examples/sec; 0.350 sec/batch)
2016-12-03 01:18:16.985570: step 3950, loss = 1.10, accu = 0.84, validation: 0.73 (379.4 examples/sec; 0.337 sec/batch)
2016-12-03 01:18:20.648821: step 3960, loss = 1.13, accu = 0.85, validation: 0.73 (362.8 examples/sec; 0.353 sec/batch)
2016-12-03 01:18:24.152357: step 3970, loss = 1.28, accu = 0.80, validation: 0.63 (374.0 examples/sec; 0.342 sec/batch)
2016-12-03 01:18:27.725442: step 3980, loss = 1.14, accu = 0.83, validation: 0.62 (369.0 examples/sec; 0.347 sec/batch)
2016-12-03 01:18:31.436932: step 3990, loss = 1.15, accu = 0.86, validation: 0.71 (374.5 examples/sec; 0.342 sec/batch)
2016-12-03 01:18:34.968239: step 4000, loss = 1.29, accu = 0.78, validation: 0.69 (376.7 examples/sec; 0.340 sec/batch)
2016-12-03 01:18:39.326501: step 4010, loss = 1.23, accu = 0.82, validation: 0.77 (378.8 examples/sec; 0.338 sec/batch)
2016-12-03 01:18:42.882060: step 4020, loss = 1.25, accu = 0.76, validation: 0.71 (354.8 examples/sec; 0.361 sec/batch)
2016-12-03 01:18:46.502357: step 4030, loss = 1.07, accu = 0.84, validation: 0.67 (362.3 examples/sec; 0.353 sec/batch)
2016-12-03 01:18:50.178769: step 4040, loss = 1.09, accu = 0.86, validation: 0.63 (368.5 examples/sec; 0.347 sec/batch)
2016-12-03 01:18:53.763099: step 4050, loss = 1.02, accu = 0.89, validation: 0.72 (306.5 examples/sec; 0.418 sec/batch)
2016-12-03 01:18:57.332890: step 4060, loss = 1.15, accu = 0.80, validation: 0.80 (369.3 examples/sec; 0.347 sec/batch)
2016-12-03 01:19:01.013329: step 4070, loss = 1.27, accu = 0.80, validation: 0.64 (367.4 examples/sec; 0.348 sec/batch)
2016-12-03 01:19:04.648367: step 4080, loss = 1.14, accu = 0.84, validation: 0.70 (379.7 examples/sec; 0.337 sec/batch)
2016-12-03 01:19:08.341110: step 4090, loss = 1.11, accu = 0.85, validation: 0.64 (354.8 examples/sec; 0.361 sec/batch)
2016-12-03 01:19:11.961207: step 4100, loss = 1.04, accu = 0.88, validation: 0.69 (366.9 examples/sec; 0.349 sec/batch)
2016-12-03 01:19:15.824409: step 4110, loss = 1.16, accu = 0.82, validation: 0.70 (295.6 examples/sec; 0.433 sec/batch)
2016-12-03 01:19:19.401370: step 4120, loss = 1.05, accu = 0.86, validation: 0.77 (355.7 examples/sec; 0.360 sec/batch)
2016-12-03 01:19:22.938449: step 4130, loss = 1.43, accu = 0.71, validation: 0.75 (365.4 examples/sec; 0.350 sec/batch)
2016-12-03 01:19:26.641916: step 4140, loss = 1.11, accu = 0.86, validation: 0.66 (368.4 examples/sec; 0.347 sec/batch)
2016-12-03 01:19:30.166827: step 4150, loss = 1.02, accu = 0.91, validation: 0.70 (371.5 examples/sec; 0.345 sec/batch)
2016-12-03 01:19:33.817305: step 4160, loss = 1.16, accu = 0.77, validation: 0.68 (370.2 examples/sec; 0.346 sec/batch)
2016-12-03 01:19:37.339277: step 4170, loss = 1.19, accu = 0.77, validation: 0.73 (379.7 examples/sec; 0.337 sec/batch)
2016-12-03 01:19:41.032165: step 4180, loss = 1.17, accu = 0.83, validation: 0.69 (360.1 examples/sec; 0.355 sec/batch)
2016-12-03 01:19:44.576298: step 4190, loss = 1.22, accu = 0.81, validation: 0.62 (350.2 examples/sec; 0.366 sec/batch)
2016-12-03 01:19:48.194384: step 4200, loss = 1.01, accu = 0.88, validation: 0.68 (371.4 examples/sec; 0.345 sec/batch)
2016-12-03 01:19:52.132432: step 4210, loss = 1.14, accu = 0.83, validation: 0.70 (376.1 examples/sec; 0.340 sec/batch)
2016-12-03 01:19:55.884865: step 4220, loss = 1.04, accu = 0.87, validation: 0.73 (365.9 examples/sec; 0.350 sec/batch)
2016-12-03 01:19:59.567617: step 4230, loss = 1.27, accu = 0.76, validation: 0.74 (301.8 examples/sec; 0.424 sec/batch)
2016-12-03 01:20:03.115270: step 4240, loss = 0.98, accu = 0.87, validation: 0.73 (362.5 examples/sec; 0.353 sec/batch)
2016-12-03 01:20:06.790559: step 4250, loss = 1.02, accu = 0.81, validation: 0.66 (368.7 examples/sec; 0.347 sec/batch)
2016-12-03 01:20:10.502687: step 4260, loss = 1.05, accu = 0.83, validation: 0.68 (353.5 examples/sec; 0.362 sec/batch)
2016-12-03 01:20:14.078719: step 4270, loss = 1.13, accu = 0.77, validation: 0.81 (371.1 examples/sec; 0.345 sec/batch)
2016-12-03 01:20:17.691157: step 4280, loss = 1.13, accu = 0.81, validation: 0.62 (278.5 examples/sec; 0.460 sec/batch)
2016-12-03 01:20:21.292383: step 4290, loss = 1.11, accu = 0.81, validation: 0.67 (379.5 examples/sec; 0.337 sec/batch)
2016-12-03 01:20:24.890196: step 4300, loss = 1.03, accu = 0.86, validation: 0.66 (378.0 examples/sec; 0.339 sec/batch)
2016-12-03 01:20:28.617127: step 4310, loss = 1.00, accu = 0.86, validation: 0.67 (358.2 examples/sec; 0.357 sec/batch)
2016-12-03 01:20:32.325184: step 4320, loss = 0.94, accu = 0.89, validation: 0.70 (356.5 examples/sec; 0.359 sec/batch)
2016-12-03 01:20:35.894947: step 4330, loss = 1.09, accu = 0.79, validation: 0.68 (349.6 examples/sec; 0.366 sec/batch)
2016-12-03 01:20:39.412266: step 4340, loss = 1.08, accu = 0.83, validation: 0.70 (364.7 examples/sec; 0.351 sec/batch)
2016-12-03 01:20:43.073995: step 4350, loss = 1.18, accu = 0.77, validation: 0.70 (373.3 examples/sec; 0.343 sec/batch)
2016-12-03 01:20:46.609947: step 4360, loss = 1.06, accu = 0.86, validation: 0.70 (379.7 examples/sec; 0.337 sec/batch)
2016-12-03 01:20:50.144164: step 4370, loss = 0.95, accu = 0.89, validation: 0.73 (388.2 examples/sec; 0.330 sec/batch)
2016-12-03 01:20:53.688836: step 4380, loss = 1.01, accu = 0.86, validation: 0.76 (369.2 examples/sec; 0.347 sec/batch)
2016-12-03 01:20:57.085852: step 4390, loss = 1.04, accu = 0.84, validation: 0.65 (378.1 examples/sec; 0.339 sec/batch)
2016-12-03 01:21:00.744533: step 4400, loss = 1.14, accu = 0.77, validation: 0.65 (275.7 examples/sec; 0.464 sec/batch)
2016-12-03 01:21:04.597956: step 4410, loss = 0.95, accu = 0.88, validation: 0.70 (364.4 examples/sec; 0.351 sec/batch)
2016-12-03 01:21:08.227128: step 4420, loss = 1.03, accu = 0.82, validation: 0.70 (332.7 examples/sec; 0.385 sec/batch)
2016-12-03 01:21:11.801587: step 4430, loss = 1.08, accu = 0.84, validation: 0.69 (374.7 examples/sec; 0.342 sec/batch)
2016-12-03 01:21:15.328688: step 4440, loss = 1.00, accu = 0.87, validation: 0.66 (363.6 examples/sec; 0.352 sec/batch)
2016-12-03 01:21:19.056194: step 4450, loss = 1.14, accu = 0.78, validation: 0.65 (279.4 examples/sec; 0.458 sec/batch)
2016-12-03 01:21:22.591278: step 4460, loss = 1.00, accu = 0.87, validation: 0.66 (365.3 examples/sec; 0.350 sec/batch)
2016-12-03 01:21:26.096752: step 4470, loss = 1.03, accu = 0.85, validation: 0.65 (368.6 examples/sec; 0.347 sec/batch)
2016-12-03 01:21:29.574331: step 4480, loss = 0.99, accu = 0.84, validation: 0.75 (359.0 examples/sec; 0.357 sec/batch)
2016-12-03 01:21:33.275338: step 4490, loss = 1.07, accu = 0.84, validation: 0.67 (369.7 examples/sec; 0.346 sec/batch)
2016-12-03 01:21:36.731150: step 4500, loss = 1.14, accu = 0.79, validation: 0.63 (373.0 examples/sec; 0.343 sec/batch)
2016-12-03 01:21:40.681322: step 4510, loss = 1.05, accu = 0.80, validation: 0.73 (351.2 examples/sec; 0.364 sec/batch)
2016-12-03 01:21:44.237622: step 4520, loss = 1.00, accu = 0.86, validation: 0.76 (355.7 examples/sec; 0.360 sec/batch)
2016-12-03 01:21:47.747458: step 4530, loss = 0.95, accu = 0.88, validation: 0.67 (383.6 examples/sec; 0.334 sec/batch)
2016-12-03 01:21:51.317445: step 4540, loss = 0.97, accu = 0.85, validation: 0.68 (361.2 examples/sec; 0.354 sec/batch)
2016-12-03 01:21:54.864043: step 4550, loss = 0.94, accu = 0.87, validation: 0.69 (372.2 examples/sec; 0.344 sec/batch)
2016-12-03 01:21:58.508009: step 4560, loss = 0.99, accu = 0.87, validation: 0.69 (364.8 examples/sec; 0.351 sec/batch)
2016-12-03 01:22:01.984074: step 4570, loss = 1.10, accu = 0.82, validation: 0.71 (384.9 examples/sec; 0.333 sec/batch)
2016-12-03 01:22:05.696110: step 4580, loss = 0.84, accu = 0.93, validation: 0.68 (356.2 examples/sec; 0.359 sec/batch)
2016-12-03 01:22:09.266498: step 4590, loss = 0.99, accu = 0.85, validation: 0.73 (378.1 examples/sec; 0.339 sec/batch)
2016-12-03 01:22:12.925950: step 4600, loss = 1.05, accu = 0.83, validation: 0.72 (372.2 examples/sec; 0.344 sec/batch)
2016-12-03 01:22:16.808812: step 4610, loss = 0.97, accu = 0.87, validation: 0.70 (370.9 examples/sec; 0.345 sec/batch)
2016-12-03 01:22:20.443233: step 4620, loss = 0.89, accu = 0.89, validation: 0.68 (365.6 examples/sec; 0.350 sec/batch)
2016-12-03 01:22:24.041364: step 4630, loss = 0.90, accu = 0.85, validation: 0.77 (362.5 examples/sec; 0.353 sec/batch)
2016-12-03 01:22:27.656706: step 4640, loss = 0.92, accu = 0.91, validation: 0.69 (374.8 examples/sec; 0.342 sec/batch)
2016-12-03 01:22:31.233839: step 4650, loss = 0.86, accu = 0.90, validation: 0.70 (385.1 examples/sec; 0.332 sec/batch)
2016-12-03 01:22:34.808664: step 4660, loss = 0.87, accu = 0.87, validation: 0.72 (368.3 examples/sec; 0.348 sec/batch)
2016-12-03 01:22:38.371199: step 4670, loss = 0.90, accu = 0.87, validation: 0.69 (360.5 examples/sec; 0.355 sec/batch)
2016-12-03 01:22:41.982440: step 4680, loss = 0.88, accu = 0.91, validation: 0.72 (380.2 examples/sec; 0.337 sec/batch)
2016-12-03 01:22:45.475797: step 4690, loss = 0.81, accu = 0.92, validation: 0.78 (378.2 examples/sec; 0.338 sec/batch)
2016-12-03 01:22:49.088173: step 4700, loss = 0.87, accu = 0.88, validation: 0.77 (366.1 examples/sec; 0.350 sec/batch)
2016-12-03 01:22:52.954859: step 4710, loss = 0.86, accu = 0.90, validation: 0.70 (370.8 examples/sec; 0.345 sec/batch)
2016-12-03 01:22:56.700190: step 4720, loss = 0.87, accu = 0.90, validation: 0.71 (350.0 examples/sec; 0.366 sec/batch)
2016-12-03 01:23:00.279976: step 4730, loss = 0.90, accu = 0.89, validation: 0.76 (359.6 examples/sec; 0.356 sec/batch)
2016-12-03 01:23:03.925715: step 4740, loss = 0.93, accu = 0.89, validation: 0.70 (359.5 examples/sec; 0.356 sec/batch)
2016-12-03 01:23:07.443391: step 4750, loss = 0.84, accu = 0.91, validation: 0.69 (373.5 examples/sec; 0.343 sec/batch)
2016-12-03 01:23:11.046945: step 4760, loss = 0.97, accu = 0.85, validation: 0.68 (372.5 examples/sec; 0.344 sec/batch)
2016-12-03 01:23:14.741632: step 4770, loss = 0.91, accu = 0.87, validation: 0.70 (365.6 examples/sec; 0.350 sec/batch)
2016-12-03 01:23:18.240172: step 4780, loss = 0.77, accu = 0.95, validation: 0.72 (362.1 examples/sec; 0.354 sec/batch)
2016-12-03 01:23:21.865639: step 4790, loss = 0.86, accu = 0.90, validation: 0.73 (375.4 examples/sec; 0.341 sec/batch)
2016-12-03 01:23:25.353704: step 4800, loss = 0.87, accu = 0.91, validation: 0.73 (357.2 examples/sec; 0.358 sec/batch)
2016-12-03 01:23:29.276528: step 4810, loss = 0.91, accu = 0.89, validation: 0.71 (371.8 examples/sec; 0.344 sec/batch)
2016-12-03 01:23:32.856941: step 4820, loss = 0.83, accu = 0.91, validation: 0.66 (367.8 examples/sec; 0.348 sec/batch)
2016-12-03 01:23:36.385240: step 4830, loss = 0.83, accu = 0.92, validation: 0.69 (371.3 examples/sec; 0.345 sec/batch)
2016-12-03 01:23:39.998487: step 4840, loss = 0.79, accu = 0.91, validation: 0.73 (272.7 examples/sec; 0.469 sec/batch)
2016-12-03 01:23:43.548609: step 4850, loss = 0.80, accu = 0.92, validation: 0.68 (379.2 examples/sec; 0.338 sec/batch)
2016-12-03 01:23:47.159868: step 4860, loss = 0.80, accu = 0.93, validation: 0.66 (374.0 examples/sec; 0.342 sec/batch)
2016-12-03 01:23:50.769209: step 4870, loss = 0.88, accu = 0.88, validation: 0.62 (374.6 examples/sec; 0.342 sec/batch)
2016-12-03 01:23:54.460786: step 4880, loss = 0.82, accu = 0.88, validation: 0.70 (286.5 examples/sec; 0.447 sec/batch)
2016-12-03 01:23:57.956531: step 4890, loss = 0.87, accu = 0.90, validation: 0.69 (368.1 examples/sec; 0.348 sec/batch)
2016-12-03 01:24:01.429129: step 4900, loss = 0.76, accu = 0.92, validation: 0.70 (354.3 examples/sec; 0.361 sec/batch)
2016-12-03 01:24:05.554018: step 4910, loss = 0.76, accu = 0.94, validation: 0.70 (358.0 examples/sec; 0.358 sec/batch)
2016-12-03 01:24:09.114701: step 4920, loss = 0.82, accu = 0.93, validation: 0.74 (380.1 examples/sec; 0.337 sec/batch)
2016-12-03 01:24:12.689365: step 4930, loss = 0.80, accu = 0.93, validation: 0.65 (370.2 examples/sec; 0.346 sec/batch)
2016-12-03 01:24:16.346867: step 4940, loss = 0.83, accu = 0.93, validation: 0.77 (380.2 examples/sec; 0.337 sec/batch)
2016-12-03 01:24:19.924016: step 4950, loss = 0.86, accu = 0.89, validation: 0.72 (380.1 examples/sec; 0.337 sec/batch)
2016-12-03 01:24:23.520867: step 4960, loss = 0.77, accu = 0.95, validation: 0.67 (374.1 examples/sec; 0.342 sec/batch)
2016-12-03 01:24:26.997334: step 4970, loss = 0.84, accu = 0.90, validation: 0.70 (379.8 examples/sec; 0.337 sec/batch)
2016-12-03 01:24:30.662472: step 4980, loss = 0.71, accu = 0.97, validation: 0.73 (367.1 examples/sec; 0.349 sec/batch)
2016-12-03 01:24:34.287253: step 4990, loss = 0.87, accu = 0.85, validation: 0.74 (369.7 examples/sec; 0.346 sec/batch)
2016-12-03 01:24:37.935126: step 5000, loss = 0.76, accu = 0.95, validation: 0.68 (357.6 examples/sec; 0.358 sec/batch)
2016-12-03 01:24:42.122420: step 5010, loss = 0.87, accu = 0.90, validation: 0.61 (363.4 examples/sec; 0.352 sec/batch)
2016-12-03 01:24:45.718224: step 5020, loss = 0.80, accu = 0.92, validation: 0.75 (378.7 examples/sec; 0.338 sec/batch)
2016-12-03 01:24:49.294187: step 5030, loss = 0.72, accu = 0.97, validation: 0.73 (369.9 examples/sec; 0.346 sec/batch)
2016-12-03 01:24:52.912808: step 5040, loss = 0.78, accu = 0.91, validation: 0.74 (365.1 examples/sec; 0.351 sec/batch)
2016-12-03 01:24:56.561888: step 5050, loss = 0.76, accu = 0.95, validation: 0.76 (277.3 examples/sec; 0.462 sec/batch)
2016-12-03 01:25:00.169034: step 5060, loss = 0.82, accu = 0.88, validation: 0.72 (381.0 examples/sec; 0.336 sec/batch)
2016-12-03 01:25:03.829835: step 5070, loss = 0.87, accu = 0.91, validation: 0.66 (375.7 examples/sec; 0.341 sec/batch)
2016-12-03 01:25:07.486892: step 5080, loss = 0.77, accu = 0.95, validation: 0.70 (369.5 examples/sec; 0.346 sec/batch)
2016-12-03 01:25:11.293589: step 5090, loss = 0.79, accu = 0.91, validation: 0.84 (285.5 examples/sec; 0.448 sec/batch)
2016-12-03 01:25:15.011090: step 5100, loss = 0.79, accu = 0.91, validation: 0.68 (338.6 examples/sec; 0.378 sec/batch)
2016-12-03 01:25:18.794767: step 5110, loss = 0.81, accu = 0.93, validation: 0.67 (370.1 examples/sec; 0.346 sec/batch)
2016-12-03 01:25:22.303432: step 5120, loss = 0.83, accu = 0.91, validation: 0.66 (355.1 examples/sec; 0.360 sec/batch)
2016-12-03 01:25:26.077533: step 5130, loss = 0.77, accu = 0.92, validation: 0.71 (359.2 examples/sec; 0.356 sec/batch)
2016-12-03 01:25:29.720751: step 5140, loss = 0.86, accu = 0.92, validation: 0.70 (368.9 examples/sec; 0.347 sec/batch)
2016-12-03 01:25:33.393577: step 5150, loss = 0.77, accu = 0.94, validation: 0.77 (360.5 examples/sec; 0.355 sec/batch)
2016-12-03 01:25:37.002912: step 5160, loss = 0.82, accu = 0.91, validation: 0.75 (373.2 examples/sec; 0.343 sec/batch)
2016-12-03 01:25:40.646301: step 5170, loss = 0.72, accu = 0.95, validation: 0.70 (370.7 examples/sec; 0.345 sec/batch)
2016-12-03 01:25:44.310025: step 5180, loss = 0.71, accu = 0.92, validation: 0.70 (354.8 examples/sec; 0.361 sec/batch)
2016-12-03 01:25:47.936014: step 5190, loss = 0.79, accu = 0.91, validation: 0.69 (360.6 examples/sec; 0.355 sec/batch)
2016-12-03 01:25:51.550380: step 5200, loss = 0.73, accu = 0.95, validation: 0.74 (366.6 examples/sec; 0.349 sec/batch)
2016-12-03 01:25:55.474690: step 5210, loss = 0.70, accu = 0.97, validation: 0.69 (347.8 examples/sec; 0.368 sec/batch)
2016-12-03 01:25:59.110479: step 5220, loss = 0.79, accu = 0.91, validation: 0.63 (362.8 examples/sec; 0.353 sec/batch)
2016-12-03 01:26:02.840012: step 5230, loss = 0.69, accu = 0.97, validation: 0.67 (311.9 examples/sec; 0.410 sec/batch)
2016-12-03 01:26:06.363049: step 5240, loss = 0.78, accu = 0.94, validation: 0.69 (365.2 examples/sec; 0.350 sec/batch)
2016-12-03 01:26:09.978790: step 5250, loss = 0.73, accu = 0.93, validation: 0.70 (361.2 examples/sec; 0.354 sec/batch)
2016-12-03 01:26:13.738087: step 5260, loss = 0.83, accu = 0.91, validation: 0.73 (354.4 examples/sec; 0.361 sec/batch)
2016-12-03 01:26:17.241352: step 5270, loss = 0.73, accu = 0.95, validation: 0.77 (381.6 examples/sec; 0.335 sec/batch)
2016-12-03 01:26:20.869992: step 5280, loss = 0.75, accu = 0.95, validation: 0.71 (376.3 examples/sec; 0.340 sec/batch)
2016-12-03 01:26:24.492065: step 5290, loss = 0.73, accu = 0.93, validation: 0.75 (367.8 examples/sec; 0.348 sec/batch)
2016-12-03 01:26:28.159499: step 5300, loss = 0.80, accu = 0.90, validation: 0.73 (370.3 examples/sec; 0.346 sec/batch)
2016-12-03 01:26:32.044425: step 5310, loss = 0.81, accu = 0.92, validation: 0.69 (369.7 examples/sec; 0.346 sec/batch)
2016-12-03 01:26:35.665607: step 5320, loss = 0.75, accu = 0.94, validation: 0.62 (360.2 examples/sec; 0.355 sec/batch)
2016-12-03 01:26:39.321489: step 5330, loss = 0.84, accu = 0.89, validation: 0.65 (315.7 examples/sec; 0.406 sec/batch)
2016-12-03 01:26:42.953713: step 5340, loss = 0.77, accu = 0.93, validation: 0.69 (366.9 examples/sec; 0.349 sec/batch)
2016-12-03 01:26:46.621079: step 5350, loss = 0.73, accu = 0.92, validation: 0.70 (377.3 examples/sec; 0.339 sec/batch)
2016-12-03 01:26:50.176794: step 5360, loss = 0.78, accu = 0.93, validation: 0.73 (377.5 examples/sec; 0.339 sec/batch)
2016-12-03 01:26:53.744331: step 5370, loss = 0.78, accu = 0.90, validation: 0.74 (359.1 examples/sec; 0.356 sec/batch)
2016-12-03 01:26:57.535438: step 5380, loss = 0.71, accu = 0.96, validation: 0.74 (271.9 examples/sec; 0.471 sec/batch)
2016-12-03 01:27:01.127192: step 5390, loss = 0.81, accu = 0.93, validation: 0.67 (370.7 examples/sec; 0.345 sec/batch)
2016-12-03 01:27:04.732392: step 5400, loss = 0.69, accu = 0.96, validation: 0.70 (367.3 examples/sec; 0.349 sec/batch)
2016-12-03 01:27:08.587059: step 5410, loss = 0.74, accu = 0.95, validation: 0.73 (270.9 examples/sec; 0.473 sec/batch)
2016-12-03 01:27:12.172386: step 5420, loss = 0.77, accu = 0.91, validation: 0.66 (376.5 examples/sec; 0.340 sec/batch)
2016-12-03 01:27:15.805049: step 5430, loss = 0.70, accu = 0.93, validation: 0.66 (382.1 examples/sec; 0.335 sec/batch)
2016-12-03 01:27:19.372337: step 5440, loss = 0.81, accu = 0.91, validation: 0.75 (310.5 examples/sec; 0.412 sec/batch)
2016-12-03 01:27:22.962641: step 5450, loss = 0.75, accu = 0.95, validation: 0.75 (371.4 examples/sec; 0.345 sec/batch)
2016-12-03 01:27:26.606238: step 5460, loss = 0.69, accu = 0.97, validation: 0.73 (371.6 examples/sec; 0.344 sec/batch)
2016-12-03 01:27:30.078555: step 5470, loss = 0.75, accu = 0.93, validation: 0.70 (377.3 examples/sec; 0.339 sec/batch)
2016-12-03 01:27:33.694636: step 5480, loss = 0.79, accu = 0.89, validation: 0.66 (377.0 examples/sec; 0.340 sec/batch)
2016-12-03 01:27:37.298455: step 5490, loss = 0.72, accu = 0.95, validation: 0.73 (393.6 examples/sec; 0.325 sec/batch)
2016-12-03 01:27:40.919313: step 5500, loss = 0.75, accu = 0.95, validation: 0.69 (377.4 examples/sec; 0.339 sec/batch)
2016-12-03 01:27:44.939600: step 5510, loss = 0.69, accu = 0.95, validation: 0.70 (268.3 examples/sec; 0.477 sec/batch)
2016-12-03 01:27:48.592426: step 5520, loss = 0.74, accu = 0.91, validation: 0.66 (370.2 examples/sec; 0.346 sec/batch)
2016-12-03 01:27:52.363989: step 5530, loss = 0.71, accu = 0.94, validation: 0.62 (280.8 examples/sec; 0.456 sec/batch)
2016-12-03 01:27:55.882446: step 5540, loss = 0.76, accu = 0.92, validation: 0.73 (370.7 examples/sec; 0.345 sec/batch)
2016-12-03 01:27:59.505624: step 5550, loss = 0.74, accu = 0.92, validation: 0.77 (285.8 examples/sec; 0.448 sec/batch)
2016-12-03 01:28:03.090789: step 5560, loss = 0.66, accu = 0.97, validation: 0.71 (368.5 examples/sec; 0.347 sec/batch)
2016-12-03 01:28:06.736604: step 5570, loss = 0.72, accu = 0.93, validation: 0.70 (275.4 examples/sec; 0.465 sec/batch)
2016-12-03 01:28:10.228460: step 5580, loss = 0.70, accu = 0.94, validation: 0.66 (373.3 examples/sec; 0.343 sec/batch)
2016-12-03 01:28:13.955727: step 5590, loss = 0.77, accu = 0.91, validation: 0.76 (353.4 examples/sec; 0.362 sec/batch)
2016-12-03 01:28:17.489838: step 5600, loss = 0.76, accu = 0.93, validation: 0.69 (346.4 examples/sec; 0.370 sec/batch)
2016-12-03 01:28:21.361242: step 5610, loss = 0.72, accu = 0.94, validation: 0.75 (368.6 examples/sec; 0.347 sec/batch)
2016-12-03 01:28:24.955947: step 5620, loss = 0.69, accu = 0.95, validation: 0.78 (359.2 examples/sec; 0.356 sec/batch)
2016-12-03 01:28:28.686272: step 5630, loss = 0.73, accu = 0.91, validation: 0.70 (328.8 examples/sec; 0.389 sec/batch)
2016-12-03 01:28:32.172218: step 5640, loss = 0.71, accu = 0.95, validation: 0.67 (374.0 examples/sec; 0.342 sec/batch)
2016-12-03 01:28:35.776235: step 5650, loss = 0.71, accu = 0.96, validation: 0.70 (374.0 examples/sec; 0.342 sec/batch)
2016-12-03 01:28:39.395839: step 5660, loss = 0.71, accu = 0.93, validation: 0.80 (369.5 examples/sec; 0.346 sec/batch)
2016-12-03 01:28:43.004158: step 5670, loss = 0.77, accu = 0.92, validation: 0.70 (382.7 examples/sec; 0.334 sec/batch)
2016-12-03 01:28:46.675825: step 5680, loss = 0.77, accu = 0.92, validation: 0.67 (264.6 examples/sec; 0.484 sec/batch)
2016-12-03 01:28:50.318171: step 5690, loss = 0.71, accu = 0.96, validation: 0.71 (362.7 examples/sec; 0.353 sec/batch)
2016-12-03 01:28:53.816151: step 5700, loss = 0.79, accu = 0.93, validation: 0.72 (358.2 examples/sec; 0.357 sec/batch)
2016-12-03 01:28:57.860569: step 5710, loss = 0.67, accu = 0.97, validation: 0.72 (369.2 examples/sec; 0.347 sec/batch)
2016-12-03 01:29:01.524986: step 5720, loss = 0.69, accu = 0.96, validation: 0.75 (372.6 examples/sec; 0.343 sec/batch)
2016-12-03 01:29:05.213969: step 5730, loss = 0.77, accu = 0.92, validation: 0.72 (300.5 examples/sec; 0.426 sec/batch)
2016-12-03 01:29:08.820199: step 5740, loss = 0.74, accu = 0.91, validation: 0.77 (271.7 examples/sec; 0.471 sec/batch)
2016-12-03 01:29:12.501474: step 5750, loss = 0.69, accu = 0.95, validation: 0.77 (347.8 examples/sec; 0.368 sec/batch)
2016-12-03 01:29:16.156222: step 5760, loss = 0.73, accu = 0.93, validation: 0.71 (366.1 examples/sec; 0.350 sec/batch)
2016-12-03 01:29:19.805353: step 5770, loss = 0.69, accu = 0.95, validation: 0.75 (360.2 examples/sec; 0.355 sec/batch)
2016-12-03 01:29:23.380503: step 5780, loss = 0.71, accu = 0.96, validation: 0.66 (360.9 examples/sec; 0.355 sec/batch)
2016-12-03 01:29:27.083584: step 5790, loss = 0.72, accu = 0.91, validation: 0.66 (331.1 examples/sec; 0.387 sec/batch)
2016-12-03 01:29:30.731918: step 5800, loss = 0.75, accu = 0.94, validation: 0.68 (373.4 examples/sec; 0.343 sec/batch)
2016-12-03 01:29:34.468550: step 5810, loss = 0.69, accu = 0.96, validation: 0.65 (341.2 examples/sec; 0.375 sec/batch)
2016-12-03 01:29:38.139019: step 5820, loss = 0.67, accu = 0.95, validation: 0.74 (349.0 examples/sec; 0.367 sec/batch)
2016-12-03 01:29:41.830584: step 5830, loss = 0.71, accu = 0.95, validation: 0.74 (381.5 examples/sec; 0.336 sec/batch)
2016-12-03 01:29:45.376891: step 5840, loss = 0.70, accu = 0.95, validation: 0.74 (380.9 examples/sec; 0.336 sec/batch)
2016-12-03 01:29:49.028155: step 5850, loss = 0.69, accu = 0.95, validation: 0.71 (368.7 examples/sec; 0.347 sec/batch)
2016-12-03 01:29:52.618308: step 5860, loss = 0.70, accu = 0.94, validation: 0.69 (376.6 examples/sec; 0.340 sec/batch)
2016-12-03 01:29:56.222774: step 5870, loss = 0.70, accu = 0.96, validation: 0.73 (381.1 examples/sec; 0.336 sec/batch)
2016-12-03 01:29:59.795709: step 5880, loss = 0.72, accu = 0.94, validation: 0.64 (377.3 examples/sec; 0.339 sec/batch)
2016-12-03 01:30:03.278536: step 5890, loss = 0.71, accu = 0.95, validation: 0.73 (368.0 examples/sec; 0.348 sec/batch)
2016-12-03 01:30:06.909302: step 5900, loss = 0.61, accu = 0.98, validation: 0.63 (357.8 examples/sec; 0.358 sec/batch)
2016-12-03 01:30:10.837604: step 5910, loss = 0.65, accu = 0.97, validation: 0.73 (358.4 examples/sec; 0.357 sec/batch)
2016-12-03 01:30:14.520666: step 5920, loss = 0.68, accu = 0.95, validation: 0.71 (378.0 examples/sec; 0.339 sec/batch)
2016-12-03 01:30:17.996112: step 5930, loss = 0.66, accu = 0.98, validation: 0.70 (386.1 examples/sec; 0.332 sec/batch)
2016-12-03 01:30:21.732226: step 5940, loss = 0.69, accu = 0.95, validation: 0.65 (276.5 examples/sec; 0.463 sec/batch)
2016-12-03 01:30:25.373701: step 5950, loss = 0.62, accu = 0.99, validation: 0.70 (351.8 examples/sec; 0.364 sec/batch)
2016-12-03 01:30:28.869736: step 5960, loss = 0.70, accu = 0.94, validation: 0.68 (367.4 examples/sec; 0.348 sec/batch)
2016-12-03 01:30:32.530628: step 5970, loss = 0.73, accu = 0.95, validation: 0.75 (370.0 examples/sec; 0.346 sec/batch)
2016-12-03 01:30:36.150604: step 5980, loss = 0.75, accu = 0.92, validation: 0.77 (304.6 examples/sec; 0.420 sec/batch)
2016-12-03 01:30:39.732179: step 5990, loss = 0.67, accu = 0.95, validation: 0.68 (368.4 examples/sec; 0.347 sec/batch)
2016-12-03 01:30:43.326821: step 6000, loss = 0.69, accu = 0.96, validation: 0.70 (360.6 examples/sec; 0.355 sec/batch)
2016-12-03 01:30:47.725992: step 6010, loss = 0.65, accu = 0.97, validation: 0.73 (308.6 examples/sec; 0.415 sec/batch)
2016-12-03 01:30:51.191231: step 6020, loss = 0.74, accu = 0.92, validation: 0.69 (347.6 examples/sec; 0.368 sec/batch)
2016-12-03 01:30:54.925732: step 6030, loss = 0.65, accu = 0.95, validation: 0.62 (360.7 examples/sec; 0.355 sec/batch)
2016-12-03 01:30:58.470890: step 6040, loss = 0.64, accu = 0.96, validation: 0.70 (381.3 examples/sec; 0.336 sec/batch)
2016-12-03 01:31:02.110657: step 6050, loss = 0.70, accu = 0.95, validation: 0.71 (367.1 examples/sec; 0.349 sec/batch)
2016-12-03 01:31:05.834117: step 6060, loss = 0.66, accu = 0.95, validation: 0.70 (357.3 examples/sec; 0.358 sec/batch)
2016-12-03 01:31:09.473349: step 6070, loss = 0.70, accu = 0.94, validation: 0.72 (352.7 examples/sec; 0.363 sec/batch)
2016-12-03 01:31:13.044238: step 6080, loss = 0.67, accu = 0.96, validation: 0.71 (347.1 examples/sec; 0.369 sec/batch)
2016-12-03 01:31:16.734423: step 6090, loss = 0.63, accu = 0.98, validation: 0.70 (364.3 examples/sec; 0.351 sec/batch)
2016-12-03 01:31:20.406680: step 6100, loss = 0.62, accu = 0.98, validation: 0.63 (347.3 examples/sec; 0.369 sec/batch)
2016-12-03 01:31:24.325878: step 6110, loss = 0.67, accu = 0.96, validation: 0.72 (362.2 examples/sec; 0.353 sec/batch)
2016-12-03 01:31:27.985033: step 6120, loss = 0.71, accu = 0.92, validation: 0.77 (353.6 examples/sec; 0.362 sec/batch)
2016-12-03 01:31:31.568498: step 6130, loss = 0.63, accu = 0.98, validation: 0.66 (361.4 examples/sec; 0.354 sec/batch)
2016-12-03 01:31:35.407816: step 6140, loss = 0.73, accu = 0.94, validation: 0.68 (258.7 examples/sec; 0.495 sec/batch)
2016-12-03 01:31:38.990753: step 6150, loss = 0.67, accu = 0.95, validation: 0.69 (360.2 examples/sec; 0.355 sec/batch)
2016-12-03 01:31:42.768323: step 6160, loss = 0.68, accu = 0.94, validation: 0.70 (263.1 examples/sec; 0.487 sec/batch)
2016-12-03 01:31:46.430404: step 6170, loss = 0.67, accu = 0.96, validation: 0.70 (345.6 examples/sec; 0.370 sec/batch)
2016-12-03 01:31:50.087177: step 6180, loss = 0.65, accu = 0.97, validation: 0.75 (271.1 examples/sec; 0.472 sec/batch)
2016-12-03 01:31:53.718641: step 6190, loss = 0.67, accu = 0.97, validation: 0.79 (371.7 examples/sec; 0.344 sec/batch)
2016-12-03 01:31:57.449201: step 6200, loss = 0.66, accu = 0.97, validation: 0.72 (333.3 examples/sec; 0.384 sec/batch)
2016-12-03 01:32:01.183546: step 6210, loss = 0.65, accu = 0.96, validation: 0.69 (382.6 examples/sec; 0.335 sec/batch)
2016-12-03 01:32:04.968818: step 6220, loss = 0.68, accu = 0.95, validation: 0.72 (282.4 examples/sec; 0.453 sec/batch)
2016-12-03 01:32:08.646215: step 6230, loss = 0.65, accu = 0.96, validation: 0.75 (371.5 examples/sec; 0.345 sec/batch)
2016-12-03 01:32:12.319139: step 6240, loss = 0.69, accu = 0.96, validation: 0.71 (362.9 examples/sec; 0.353 sec/batch)
2016-12-03 01:32:15.992152: step 6250, loss = 0.64, accu = 0.95, validation: 0.60 (374.0 examples/sec; 0.342 sec/batch)
2016-12-03 01:32:19.655975: step 6260, loss = 0.73, accu = 0.94, validation: 0.68 (364.3 examples/sec; 0.351 sec/batch)
2016-12-03 01:32:23.325304: step 6270, loss = 0.61, accu = 0.98, validation: 0.73 (384.2 examples/sec; 0.333 sec/batch)
2016-12-03 01:32:27.022597: step 6280, loss = 0.60, accu = 0.99, validation: 0.73 (368.3 examples/sec; 0.348 sec/batch)
2016-12-03 01:32:30.635359: step 6290, loss = 0.65, accu = 0.97, validation: 0.75 (373.7 examples/sec; 0.343 sec/batch)
2016-12-03 01:32:34.232013: step 6300, loss = 0.70, accu = 0.94, validation: 0.73 (375.6 examples/sec; 0.341 sec/batch)
2016-12-03 01:32:38.118014: step 6310, loss = 0.66, accu = 0.94, validation: 0.69 (364.0 examples/sec; 0.352 sec/batch)
2016-12-03 01:32:41.795097: step 6320, loss = 0.63, accu = 0.96, validation: 0.72 (309.9 examples/sec; 0.413 sec/batch)
2016-12-03 01:32:45.346195: step 6330, loss = 0.66, accu = 0.97, validation: 0.73 (377.6 examples/sec; 0.339 sec/batch)
2016-12-03 01:32:48.921286: step 6340, loss = 0.64, accu = 0.95, validation: 0.67 (382.0 examples/sec; 0.335 sec/batch)
2016-12-03 01:32:52.652219: step 6350, loss = 0.70, accu = 0.93, validation: 0.63 (357.9 examples/sec; 0.358 sec/batch)
2016-12-03 01:32:56.348390: step 6360, loss = 0.64, accu = 0.97, validation: 0.66 (322.0 examples/sec; 0.397 sec/batch)
2016-12-03 01:32:59.950800: step 6370, loss = 0.63, accu = 0.97, validation: 0.67 (374.6 examples/sec; 0.342 sec/batch)
2016-12-03 01:33:03.578748: step 6380, loss = 0.65, accu = 0.95, validation: 0.70 (310.2 examples/sec; 0.413 sec/batch)
2016-12-03 01:33:07.241701: step 6390, loss = 0.62, accu = 0.98, validation: 0.70 (352.4 examples/sec; 0.363 sec/batch)
2016-12-03 01:33:10.782035: step 6400, loss = 0.69, accu = 0.94, validation: 0.69 (370.9 examples/sec; 0.345 sec/batch)
2016-12-03 01:33:14.695339: step 6410, loss = 0.61, accu = 0.95, validation: 0.71 (366.9 examples/sec; 0.349 sec/batch)
2016-12-03 01:33:18.314569: step 6420, loss = 0.65, accu = 0.98, validation: 0.66 (366.6 examples/sec; 0.349 sec/batch)
2016-12-03 01:33:21.891294: step 6430, loss = 0.64, accu = 0.98, validation: 0.76 (378.3 examples/sec; 0.338 sec/batch)
2016-12-03 01:33:25.534626: step 6440, loss = 0.62, accu = 0.97, validation: 0.72 (381.0 examples/sec; 0.336 sec/batch)
2016-12-03 01:33:29.115719: step 6450, loss = 0.64, accu = 0.95, validation: 0.65 (362.7 examples/sec; 0.353 sec/batch)
2016-12-03 01:33:32.782246: step 6460, loss = 0.68, accu = 0.96, validation: 0.68 (382.3 examples/sec; 0.335 sec/batch)
2016-12-03 01:33:36.399954: step 6470, loss = 0.73, accu = 0.91, validation: 0.73 (381.4 examples/sec; 0.336 sec/batch)
2016-12-03 01:33:40.018589: step 6480, loss = 0.63, accu = 0.98, validation: 0.74 (368.2 examples/sec; 0.348 sec/batch)
2016-12-03 01:33:43.621632: step 6490, loss = 0.65, accu = 0.95, validation: 0.72 (374.0 examples/sec; 0.342 sec/batch)
2016-12-03 01:33:47.168901: step 6500, loss = 0.61, accu = 0.98, validation: 0.71 (380.8 examples/sec; 0.336 sec/batch)
2016-12-03 01:33:51.181876: step 6510, loss = 0.63, accu = 0.97, validation: 0.72 (366.1 examples/sec; 0.350 sec/batch)
2016-12-03 01:33:54.951264: step 6520, loss = 0.64, accu = 0.95, validation: 0.70 (301.8 examples/sec; 0.424 sec/batch)
2016-12-03 01:33:58.451128: step 6530, loss = 0.64, accu = 0.95, validation: 0.68 (383.0 examples/sec; 0.334 sec/batch)
2016-12-03 01:34:02.034591: step 6540, loss = 0.61, accu = 0.97, validation: 0.73 (360.1 examples/sec; 0.355 sec/batch)
2016-12-03 01:34:05.668125: step 6550, loss = 0.60, accu = 0.97, validation: 0.71 (376.3 examples/sec; 0.340 sec/batch)
2016-12-03 01:34:09.306045: step 6560, loss = 0.61, accu = 0.98, validation: 0.64 (375.6 examples/sec; 0.341 sec/batch)
2016-12-03 01:34:13.027420: step 6570, loss = 0.64, accu = 0.98, validation: 0.68 (369.5 examples/sec; 0.346 sec/batch)
2016-12-03 01:34:16.736657: step 6580, loss = 0.64, accu = 0.97, validation: 0.77 (378.7 examples/sec; 0.338 sec/batch)
2016-12-03 01:34:20.180254: step 6590, loss = 0.65, accu = 0.95, validation: 0.66 (376.6 examples/sec; 0.340 sec/batch)
2016-12-03 01:34:23.835569: step 6600, loss = 0.62, accu = 0.97, validation: 0.76 (359.1 examples/sec; 0.356 sec/batch)
2016-12-03 01:34:27.805249: step 6610, loss = 0.70, accu = 0.95, validation: 0.66 (275.3 examples/sec; 0.465 sec/batch)
2016-12-03 01:34:31.393526: step 6620, loss = 0.60, accu = 0.99, validation: 0.76 (357.0 examples/sec; 0.359 sec/batch)
2016-12-03 01:34:34.987144: step 6630, loss = 0.68, accu = 0.95, validation: 0.76 (284.0 examples/sec; 0.451 sec/batch)
2016-12-03 01:34:38.509972: step 6640, loss = 0.62, accu = 0.95, validation: 0.73 (367.5 examples/sec; 0.348 sec/batch)
2016-12-03 01:34:42.134694: step 6650, loss = 0.65, accu = 0.95, validation: 0.74 (381.5 examples/sec; 0.335 sec/batch)
2016-12-03 01:34:45.944839: step 6660, loss = 0.65, accu = 0.95, validation: 0.64 (320.8 examples/sec; 0.399 sec/batch)
2016-12-03 01:34:49.404689: step 6670, loss = 0.64, accu = 0.98, validation: 0.69 (378.7 examples/sec; 0.338 sec/batch)
2016-12-03 01:34:53.142176: step 6680, loss = 0.67, accu = 0.94, validation: 0.66 (276.9 examples/sec; 0.462 sec/batch)
2016-12-03 01:34:56.810791: step 6690, loss = 0.62, accu = 0.96, validation: 0.76 (371.3 examples/sec; 0.345 sec/batch)
2016-12-03 01:35:00.305878: step 6700, loss = 0.60, accu = 0.98, validation: 0.71 (368.7 examples/sec; 0.347 sec/batch)
2016-12-03 01:35:04.118111: step 6710, loss = 0.66, accu = 0.96, validation: 0.70 (355.5 examples/sec; 0.360 sec/batch)
2016-12-03 01:35:07.779106: step 6720, loss = 0.63, accu = 0.95, validation: 0.68 (372.5 examples/sec; 0.344 sec/batch)
2016-12-03 01:35:11.473036: step 6730, loss = 0.64, accu = 0.94, validation: 0.75 (279.4 examples/sec; 0.458 sec/batch)
2016-12-03 01:35:15.165435: step 6740, loss = 0.60, accu = 0.98, validation: 0.73 (371.1 examples/sec; 0.345 sec/batch)
2016-12-03 01:35:18.736282: step 6750, loss = 0.59, accu = 0.97, validation: 0.76 (364.1 examples/sec; 0.352 sec/batch)
2016-12-03 01:35:22.225604: step 6760, loss = 0.61, accu = 0.97, validation: 0.73 (380.3 examples/sec; 0.337 sec/batch)
2016-12-03 01:35:25.967367: step 6770, loss = 0.58, accu = 0.98, validation: 0.71 (379.1 examples/sec; 0.338 sec/batch)
2016-12-03 01:35:29.516818: step 6780, loss = 0.69, accu = 0.95, validation: 0.68 (365.7 examples/sec; 0.350 sec/batch)
2016-12-03 01:35:33.188157: step 6790, loss = 0.62, accu = 0.96, validation: 0.76 (367.5 examples/sec; 0.348 sec/batch)
2016-12-03 01:35:36.698247: step 6800, loss = 0.62, accu = 0.95, validation: 0.71 (378.5 examples/sec; 0.338 sec/batch)
2016-12-03 01:35:40.762810: step 6810, loss = 0.62, accu = 0.95, validation: 0.62 (368.0 examples/sec; 0.348 sec/batch)
2016-12-03 01:35:44.323381: step 6820, loss = 0.68, accu = 0.95, validation: 0.65 (379.6 examples/sec; 0.337 sec/batch)
2016-12-03 01:35:47.922097: step 6830, loss = 0.64, accu = 0.95, validation: 0.69 (337.2 examples/sec; 0.380 sec/batch)
2016-12-03 01:35:51.666179: step 6840, loss = 0.63, accu = 0.95, validation: 0.66 (354.1 examples/sec; 0.361 sec/batch)
2016-12-03 01:35:55.467221: step 6850, loss = 0.60, accu = 0.97, validation: 0.72 (308.5 examples/sec; 0.415 sec/batch)
2016-12-03 01:35:59.135444: step 6860, loss = 0.64, accu = 0.96, validation: 0.66 (383.8 examples/sec; 0.334 sec/batch)
2016-12-03 01:36:02.776083: step 6870, loss = 0.66, accu = 0.96, validation: 0.73 (359.9 examples/sec; 0.356 sec/batch)
2016-12-03 01:36:06.266042: step 6880, loss = 0.64, accu = 0.95, validation: 0.73 (374.8 examples/sec; 0.342 sec/batch)
2016-12-03 01:36:09.850244: step 6890, loss = 0.57, accu = 0.99, validation: 0.75 (371.7 examples/sec; 0.344 sec/batch)
2016-12-03 01:36:13.589172: step 6900, loss = 0.61, accu = 0.96, validation: 0.71 (290.2 examples/sec; 0.441 sec/batch)
2016-12-03 01:36:17.533501: step 6910, loss = 0.58, accu = 0.98, validation: 0.66 (366.3 examples/sec; 0.349 sec/batch)
2016-12-03 01:36:21.215751: step 6920, loss = 0.61, accu = 0.95, validation: 0.66 (362.5 examples/sec; 0.353 sec/batch)
2016-12-03 01:36:24.832980: step 6930, loss = 0.64, accu = 0.96, validation: 0.68 (365.4 examples/sec; 0.350 sec/batch)
2016-12-03 01:36:28.457878: step 6940, loss = 0.66, accu = 0.95, validation: 0.72 (366.7 examples/sec; 0.349 sec/batch)
2016-12-03 01:36:32.106477: step 6950, loss = 0.59, accu = 0.98, validation: 0.70 (364.6 examples/sec; 0.351 sec/batch)
2016-12-03 01:36:35.682104: step 6960, loss = 0.68, accu = 0.92, validation: 0.71 (385.6 examples/sec; 0.332 sec/batch)
2016-12-03 01:36:39.324155: step 6970, loss = 0.64, accu = 0.94, validation: 0.71 (380.9 examples/sec; 0.336 sec/batch)
2016-12-03 01:36:43.057485: step 6980, loss = 0.64, accu = 0.97, validation: 0.70 (353.8 examples/sec; 0.362 sec/batch)
2016-12-03 01:36:46.506907: step 6990, loss = 0.58, accu = 0.96, validation: 0.69 (371.4 examples/sec; 0.345 sec/batch)
2016-12-03 01:36:50.163263: step 7000, loss = 0.57, accu = 0.99, validation: 0.71 (382.5 examples/sec; 0.335 sec/batch)
2016-12-03 01:36:54.608741: step 7010, loss = 0.61, accu = 0.97, validation: 0.73 (332.1 examples/sec; 0.385 sec/batch)
2016-12-03 01:36:58.056695: step 7020, loss = 0.59, accu = 0.96, validation: 0.62 (372.4 examples/sec; 0.344 sec/batch)
2016-12-03 01:37:01.722706: step 7030, loss = 0.56, accu = 0.98, validation: 0.73 (371.0 examples/sec; 0.345 sec/batch)
2016-12-03 01:37:05.432059: step 7040, loss = 0.60, accu = 0.98, validation: 0.74 (370.9 examples/sec; 0.345 sec/batch)
2016-12-03 01:37:09.130637: step 7050, loss = 0.58, accu = 0.98, validation: 0.68 (361.4 examples/sec; 0.354 sec/batch)
2016-12-03 01:37:12.912008: step 7060, loss = 0.61, accu = 0.95, validation: 0.71 (307.7 examples/sec; 0.416 sec/batch)
2016-12-03 01:37:16.615408: step 7070, loss = 0.59, accu = 0.97, validation: 0.63 (357.0 examples/sec; 0.359 sec/batch)
2016-12-03 01:37:20.330999: step 7080, loss = 0.66, accu = 0.93, validation: 0.72 (373.3 examples/sec; 0.343 sec/batch)
2016-12-03 01:37:23.983044: step 7090, loss = 0.58, accu = 0.98, validation: 0.72 (373.8 examples/sec; 0.342 sec/batch)
2016-12-03 01:37:27.690989: step 7100, loss = 0.70, accu = 0.91, validation: 0.72 (288.0 examples/sec; 0.444 sec/batch)
2016-12-03 01:37:31.628089: step 7110, loss = 0.58, accu = 0.98, validation: 0.77 (326.8 examples/sec; 0.392 sec/batch)
2016-12-03 01:37:35.275071: step 7120, loss = 0.55, accu = 0.99, validation: 0.68 (376.8 examples/sec; 0.340 sec/batch)
2016-12-03 01:37:38.942336: step 7130, loss = 0.60, accu = 0.96, validation: 0.65 (274.2 examples/sec; 0.467 sec/batch)
2016-12-03 01:37:42.665695: step 7140, loss = 0.59, accu = 0.96, validation: 0.76 (373.3 examples/sec; 0.343 sec/batch)
2016-12-03 01:37:46.358935: step 7150, loss = 0.65, accu = 0.95, validation: 0.76 (339.4 examples/sec; 0.377 sec/batch)
2016-12-03 01:37:50.027878: step 7160, loss = 0.63, accu = 0.95, validation: 0.70 (351.5 examples/sec; 0.364 sec/batch)
2016-12-03 01:37:53.695449: step 7170, loss = 0.61, accu = 0.98, validation: 0.73 (346.1 examples/sec; 0.370 sec/batch)
2016-12-03 01:37:57.485374: step 7180, loss = 0.59, accu = 0.97, validation: 0.68 (345.1 examples/sec; 0.371 sec/batch)
2016-12-03 01:38:01.006702: step 7190, loss = 0.60, accu = 0.97, validation: 0.72 (347.4 examples/sec; 0.368 sec/batch)
2016-12-03 01:38:04.701379: step 7200, loss = 0.62, accu = 0.95, validation: 0.73 (276.2 examples/sec; 0.463 sec/batch)
2016-12-03 01:38:08.574212: step 7210, loss = 0.65, accu = 0.95, validation: 0.77 (352.6 examples/sec; 0.363 sec/batch)
2016-12-03 01:38:12.086900: step 7220, loss = 0.59, accu = 0.96, validation: 0.72 (375.1 examples/sec; 0.341 sec/batch)
2016-12-03 01:38:15.776504: step 7230, loss = 0.57, accu = 0.99, validation: 0.70 (317.5 examples/sec; 0.403 sec/batch)
2016-12-03 01:38:19.277565: step 7240, loss = 0.55, accu = 0.98, validation: 0.69 (373.1 examples/sec; 0.343 sec/batch)
2016-12-03 01:38:22.953383: step 7250, loss = 0.62, accu = 0.95, validation: 0.70 (377.9 examples/sec; 0.339 sec/batch)
2016-12-03 01:38:26.465886: step 7260, loss = 0.56, accu = 0.99, validation: 0.76 (369.3 examples/sec; 0.347 sec/batch)
2016-12-03 01:38:30.260437: step 7270, loss = 0.60, accu = 0.94, validation: 0.66 (285.7 examples/sec; 0.448 sec/batch)
2016-12-03 01:38:33.796135: step 7280, loss = 0.57, accu = 0.97, validation: 0.62 (368.1 examples/sec; 0.348 sec/batch)
2016-12-03 01:38:37.409228: step 7290, loss = 0.58, accu = 0.98, validation: 0.69 (377.3 examples/sec; 0.339 sec/batch)
2016-12-03 01:38:41.138258: step 7300, loss = 0.56, accu = 0.98, validation: 0.70 (353.6 examples/sec; 0.362 sec/batch)
2016-12-03 01:38:45.001495: step 7310, loss = 0.59, accu = 0.97, validation: 0.68 (375.3 examples/sec; 0.341 sec/batch)
2016-12-03 01:38:48.676841: step 7320, loss = 0.61, accu = 0.98, validation: 0.77 (355.2 examples/sec; 0.360 sec/batch)
2016-12-03 01:38:52.288745: step 7330, loss = 0.65, accu = 0.93, validation: 0.76 (353.8 examples/sec; 0.362 sec/batch)
2016-12-03 01:38:55.896668: step 7340, loss = 0.59, accu = 0.95, validation: 0.66 (372.8 examples/sec; 0.343 sec/batch)
2016-12-03 01:38:59.471430: step 7350, loss = 0.59, accu = 0.97, validation: 0.73 (378.0 examples/sec; 0.339 sec/batch)
2016-12-03 01:39:03.064378: step 7360, loss = 0.63, accu = 0.95, validation: 0.77 (380.9 examples/sec; 0.336 sec/batch)
2016-12-03 01:39:06.650048: step 7370, loss = 0.56, accu = 0.99, validation: 0.68 (358.8 examples/sec; 0.357 sec/batch)
2016-12-03 01:39:10.236001: step 7380, loss = 0.59, accu = 0.96, validation: 0.66 (379.8 examples/sec; 0.337 sec/batch)
2016-12-03 01:39:13.981451: step 7390, loss = 0.59, accu = 0.98, validation: 0.66 (365.8 examples/sec; 0.350 sec/batch)
2016-12-03 01:39:17.616694: step 7400, loss = 0.58, accu = 0.98, validation: 0.66 (359.3 examples/sec; 0.356 sec/batch)
2016-12-03 01:39:21.462088: step 7410, loss = 0.58, accu = 0.98, validation: 0.73 (340.7 examples/sec; 0.376 sec/batch)
2016-12-03 01:39:25.144414: step 7420, loss = 0.61, accu = 0.95, validation: 0.71 (343.7 examples/sec; 0.372 sec/batch)
2016-12-03 01:39:28.741613: step 7430, loss = 0.55, accu = 0.98, validation: 0.70 (373.6 examples/sec; 0.343 sec/batch)
2016-12-03 01:39:32.397642: step 7440, loss = 0.61, accu = 0.95, validation: 0.77 (370.9 examples/sec; 0.345 sec/batch)
2016-12-03 01:39:36.034025: step 7450, loss = 0.61, accu = 0.95, validation: 0.72 (359.8 examples/sec; 0.356 sec/batch)
2016-12-03 01:39:39.598824: step 7460, loss = 0.55, accu = 0.98, validation: 0.76 (367.4 examples/sec; 0.348 sec/batch)
2016-12-03 01:39:43.262425: step 7470, loss = 0.62, accu = 0.94, validation: 0.75 (370.0 examples/sec; 0.346 sec/batch)
2016-12-03 01:39:46.869465: step 7480, loss = 0.59, accu = 0.97, validation: 0.66 (372.5 examples/sec; 0.344 sec/batch)
2016-12-03 01:39:50.484032: step 7490, loss = 0.58, accu = 0.98, validation: 0.69 (370.2 examples/sec; 0.346 sec/batch)
2016-12-03 01:39:54.135236: step 7500, loss = 0.55, accu = 0.99, validation: 0.73 (360.4 examples/sec; 0.355 sec/batch)
2016-12-03 01:39:58.042747: step 7510, loss = 0.56, accu = 0.99, validation: 0.73 (275.3 examples/sec; 0.465 sec/batch)
2016-12-03 01:40:01.745898: step 7520, loss = 0.58, accu = 0.97, validation: 0.69 (366.2 examples/sec; 0.349 sec/batch)
2016-12-03 01:40:05.421463: step 7530, loss = 0.59, accu = 0.97, validation: 0.70 (364.2 examples/sec; 0.351 sec/batch)
2016-12-03 01:40:08.998419: step 7540, loss = 0.56, accu = 0.98, validation: 0.73 (382.2 examples/sec; 0.335 sec/batch)
2016-12-03 01:40:12.618092: step 7550, loss = 0.53, accu = 0.99, validation: 0.68 (369.9 examples/sec; 0.346 sec/batch)
2016-12-03 01:40:16.242415: step 7560, loss = 0.55, accu = 0.98, validation: 0.69 (380.0 examples/sec; 0.337 sec/batch)
2016-12-03 01:40:19.822253: step 7570, loss = 0.55, accu = 0.98, validation: 0.71 (368.4 examples/sec; 0.347 sec/batch)
2016-12-03 01:40:23.503122: step 7580, loss = 0.56, accu = 0.98, validation: 0.71 (293.4 examples/sec; 0.436 sec/batch)
2016-12-03 01:40:27.088297: step 7590, loss = 0.55, accu = 0.98, validation: 0.62 (364.3 examples/sec; 0.351 sec/batch)
2016-12-03 01:40:30.572146: step 7600, loss = 0.62, accu = 0.95, validation: 0.71 (352.4 examples/sec; 0.363 sec/batch)
2016-12-03 01:40:34.352815: step 7610, loss = 0.60, accu = 0.96, validation: 0.76 (383.4 examples/sec; 0.334 sec/batch)
2016-12-03 01:40:37.992940: step 7620, loss = 0.60, accu = 0.96, validation: 0.69 (361.6 examples/sec; 0.354 sec/batch)
2016-12-03 01:40:41.504487: step 7630, loss = 0.60, accu = 0.96, validation: 0.75 (371.9 examples/sec; 0.344 sec/batch)
2016-12-03 01:40:45.167925: step 7640, loss = 0.60, accu = 0.95, validation: 0.68 (369.1 examples/sec; 0.347 sec/batch)
2016-12-03 01:40:48.837423: step 7650, loss = 0.56, accu = 0.98, validation: 0.76 (371.0 examples/sec; 0.345 sec/batch)
2016-12-03 01:40:52.374222: step 7660, loss = 0.56, accu = 0.98, validation: 0.70 (384.5 examples/sec; 0.333 sec/batch)
2016-12-03 01:40:56.012555: step 7670, loss = 0.55, accu = 0.98, validation: 0.73 (374.7 examples/sec; 0.342 sec/batch)
2016-12-03 01:40:59.726176: step 7680, loss = 0.55, accu = 0.98, validation: 0.77 (375.4 examples/sec; 0.341 sec/batch)
2016-12-03 01:41:03.314501: step 7690, loss = 0.56, accu = 0.98, validation: 0.72 (378.4 examples/sec; 0.338 sec/batch)
2016-12-03 01:41:06.969845: step 7700, loss = 0.55, accu = 0.99, validation: 0.68 (384.0 examples/sec; 0.333 sec/batch)
2016-12-03 01:41:10.818080: step 7710, loss = 0.56, accu = 0.98, validation: 0.68 (377.7 examples/sec; 0.339 sec/batch)
2016-12-03 01:41:14.471903: step 7720, loss = 0.57, accu = 0.98, validation: 0.75 (370.0 examples/sec; 0.346 sec/batch)
2016-12-03 01:41:18.115417: step 7730, loss = 0.56, accu = 0.98, validation: 0.70 (368.4 examples/sec; 0.347 sec/batch)
2016-12-03 01:41:21.692965: step 7740, loss = 0.53, accu = 0.98, validation: 0.62 (371.1 examples/sec; 0.345 sec/batch)
2016-12-03 01:41:25.269526: step 7750, loss = 0.60, accu = 0.95, validation: 0.63 (379.2 examples/sec; 0.338 sec/batch)
2016-12-03 01:41:29.049332: step 7760, loss = 0.54, accu = 0.98, validation: 0.72 (273.6 examples/sec; 0.468 sec/batch)
2016-12-03 01:41:32.677712: step 7770, loss = 0.55, accu = 0.98, validation: 0.62 (360.4 examples/sec; 0.355 sec/batch)
2016-12-03 01:41:36.123165: step 7780, loss = 0.56, accu = 0.97, validation: 0.77 (369.4 examples/sec; 0.346 sec/batch)
2016-12-03 01:41:39.868650: step 7790, loss = 0.55, accu = 0.98, validation: 0.72 (362.1 examples/sec; 0.353 sec/batch)
2016-12-03 01:41:43.485889: step 7800, loss = 0.58, accu = 0.98, validation: 0.68 (314.7 examples/sec; 0.407 sec/batch)
2016-12-03 01:41:47.278387: step 7810, loss = 0.53, accu = 0.99, validation: 0.71 (376.6 examples/sec; 0.340 sec/batch)
2016-12-03 01:41:50.875240: step 7820, loss = 0.53, accu = 0.99, validation: 0.79 (375.2 examples/sec; 0.341 sec/batch)
2016-12-03 01:41:54.520980: step 7830, loss = 0.53, accu = 0.98, validation: 0.69 (379.2 examples/sec; 0.338 sec/batch)
2016-12-03 01:41:58.209396: step 7840, loss = 0.57, accu = 0.97, validation: 0.67 (364.7 examples/sec; 0.351 sec/batch)
2016-12-03 01:42:01.860746: step 7850, loss = 0.54, accu = 0.98, validation: 0.63 (336.3 examples/sec; 0.381 sec/batch)
2016-12-03 01:42:05.513318: step 7860, loss = 0.53, accu = 0.98, validation: 0.71 (297.6 examples/sec; 0.430 sec/batch)
2016-12-03 01:42:09.144092: step 7870, loss = 0.59, accu = 0.95, validation: 0.67 (260.6 examples/sec; 0.491 sec/batch)
2016-12-03 01:42:12.808375: step 7880, loss = 0.54, accu = 0.99, validation: 0.75 (367.5 examples/sec; 0.348 sec/batch)
2016-12-03 01:42:16.331963: step 7890, loss = 0.63, accu = 0.96, validation: 0.70 (382.7 examples/sec; 0.335 sec/batch)
2016-12-03 01:42:19.956333: step 7900, loss = 0.54, accu = 0.99, validation: 0.70 (377.3 examples/sec; 0.339 sec/batch)
2016-12-03 01:42:23.848997: step 7910, loss = 0.58, accu = 0.96, validation: 0.66 (388.2 examples/sec; 0.330 sec/batch)
2016-12-03 01:42:27.495223: step 7920, loss = 0.58, accu = 0.97, validation: 0.73 (356.4 examples/sec; 0.359 sec/batch)
2016-12-03 01:42:31.079071: step 7930, loss = 0.55, accu = 0.98, validation: 0.73 (377.6 examples/sec; 0.339 sec/batch)
2016-12-03 01:42:34.743027: step 7940, loss = 0.57, accu = 0.95, validation: 0.67 (376.4 examples/sec; 0.340 sec/batch)
2016-12-03 01:42:38.274680: step 7950, loss = 0.56, accu = 0.98, validation: 0.77 (380.6 examples/sec; 0.336 sec/batch)
2016-12-03 01:42:41.951290: step 7960, loss = 0.57, accu = 0.97, validation: 0.72 (362.8 examples/sec; 0.353 sec/batch)
2016-12-03 01:42:45.617545: step 7970, loss = 0.56, accu = 0.97, validation: 0.69 (369.7 examples/sec; 0.346 sec/batch)
2016-12-03 01:42:49.241233: step 7980, loss = 0.54, accu = 0.98, validation: 0.68 (376.6 examples/sec; 0.340 sec/batch)
2016-12-03 01:42:52.877745: step 7990, loss = 0.53, accu = 0.99, validation: 0.66 (391.5 examples/sec; 0.327 sec/batch)
2016-12-03 01:42:56.571873: step 8000, loss = 0.53, accu = 0.99, validation: 0.69 (372.7 examples/sec; 0.343 sec/batch)
2016-12-03 01:43:00.867488: step 8010, loss = 0.56, accu = 0.98, validation: 0.69 (371.9 examples/sec; 0.344 sec/batch)
2016-12-03 01:43:04.586852: step 8020, loss = 0.58, accu = 0.97, validation: 0.70 (357.9 examples/sec; 0.358 sec/batch)
2016-12-03 01:43:08.263390: step 8030, loss = 0.63, accu = 0.95, validation: 0.74 (342.8 examples/sec; 0.373 sec/batch)
2016-12-03 01:43:11.936546: step 8040, loss = 0.53, accu = 0.99, validation: 0.73 (362.9 examples/sec; 0.353 sec/batch)
2016-12-03 01:43:15.620791: step 8050, loss = 0.55, accu = 0.96, validation: 0.69 (355.8 examples/sec; 0.360 sec/batch)
2016-12-03 01:43:19.279604: step 8060, loss = 0.56, accu = 0.97, validation: 0.65 (380.6 examples/sec; 0.336 sec/batch)
2016-12-03 01:43:23.004241: step 8070, loss = 0.56, accu = 0.96, validation: 0.73 (315.7 examples/sec; 0.405 sec/batch)
2016-12-03 01:43:26.694210: step 8080, loss = 0.54, accu = 0.97, validation: 0.67 (372.8 examples/sec; 0.343 sec/batch)
2016-12-03 01:43:30.374855: step 8090, loss = 0.57, accu = 0.95, validation: 0.72 (371.0 examples/sec; 0.345 sec/batch)
2016-12-03 01:43:34.071139: step 8100, loss = 0.60, accu = 0.95, validation: 0.66 (373.7 examples/sec; 0.342 sec/batch)
2016-12-03 01:43:37.781192: step 8110, loss = 0.53, accu = 0.99, validation: 0.69 (385.0 examples/sec; 0.333 sec/batch)
2016-12-03 01:43:41.500231: step 8120, loss = 0.53, accu = 0.98, validation: 0.70 (358.8 examples/sec; 0.357 sec/batch)
2016-12-03 01:43:45.147569: step 8130, loss = 0.54, accu = 0.98, validation: 0.74 (357.9 examples/sec; 0.358 sec/batch)
2016-12-03 01:43:49.018128: step 8140, loss = 0.53, accu = 0.98, validation: 0.75 (361.3 examples/sec; 0.354 sec/batch)
2016-12-03 01:43:52.686316: step 8150, loss = 0.54, accu = 0.97, validation: 0.71 (362.4 examples/sec; 0.353 sec/batch)
2016-12-03 01:43:56.231990: step 8160, loss = 0.51, accu = 0.99, validation: 0.62 (365.6 examples/sec; 0.350 sec/batch)
2016-12-03 01:44:00.034287: step 8170, loss = 0.52, accu = 0.98, validation: 0.73 (309.8 examples/sec; 0.413 sec/batch)
2016-12-03 01:44:03.679366: step 8180, loss = 0.55, accu = 0.98, validation: 0.80 (356.3 examples/sec; 0.359 sec/batch)
2016-12-03 01:44:07.331279: step 8190, loss = 0.55, accu = 0.96, validation: 0.69 (348.6 examples/sec; 0.367 sec/batch)
2016-12-03 01:44:11.023456: step 8200, loss = 0.51, accu = 0.99, validation: 0.70 (368.7 examples/sec; 0.347 sec/batch)
2016-12-03 01:44:14.902502: step 8210, loss = 0.52, accu = 0.99, validation: 0.65 (274.4 examples/sec; 0.466 sec/batch)
2016-12-03 01:44:18.490326: step 8220, loss = 0.60, accu = 0.95, validation: 0.75 (333.8 examples/sec; 0.383 sec/batch)
2016-12-03 01:44:22.162004: step 8230, loss = 0.54, accu = 0.98, validation: 0.69 (385.1 examples/sec; 0.332 sec/batch)
2016-12-03 01:44:25.870685: step 8240, loss = 0.52, accu = 0.97, validation: 0.71 (364.4 examples/sec; 0.351 sec/batch)
2016-12-03 01:44:29.557607: step 8250, loss = 0.54, accu = 0.96, validation: 0.79 (377.0 examples/sec; 0.339 sec/batch)
2016-12-03 01:44:33.243915: step 8260, loss = 0.57, accu = 0.96, validation: 0.67 (376.1 examples/sec; 0.340 sec/batch)
2016-12-03 01:44:36.819270: step 8270, loss = 0.54, accu = 0.98, validation: 0.73 (379.6 examples/sec; 0.337 sec/batch)
2016-12-03 01:44:40.410440: step 8280, loss = 0.53, accu = 0.99, validation: 0.70 (375.7 examples/sec; 0.341 sec/batch)
2016-12-03 01:44:43.937733: step 8290, loss = 0.49, accu = 1.00, validation: 0.73 (380.5 examples/sec; 0.336 sec/batch)
2016-12-03 01:44:47.549210: step 8300, loss = 0.54, accu = 0.98, validation: 0.69 (369.1 examples/sec; 0.347 sec/batch)
2016-12-03 01:44:51.489954: step 8310, loss = 0.50, accu = 1.00, validation: 0.63 (370.2 examples/sec; 0.346 sec/batch)
2016-12-03 01:44:55.157055: step 8320, loss = 0.53, accu = 0.96, validation: 0.65 (369.9 examples/sec; 0.346 sec/batch)
2016-12-03 01:44:58.718293: step 8330, loss = 0.54, accu = 0.95, validation: 0.69 (367.7 examples/sec; 0.348 sec/batch)
2016-12-03 01:45:02.304636: step 8340, loss = 0.56, accu = 0.97, validation: 0.69 (370.3 examples/sec; 0.346 sec/batch)
2016-12-03 01:45:05.966120: step 8350, loss = 0.52, accu = 0.98, validation: 0.73 (372.0 examples/sec; 0.344 sec/batch)
2016-12-03 01:45:09.540122: step 8360, loss = 0.53, accu = 0.98, validation: 0.77 (379.0 examples/sec; 0.338 sec/batch)
2016-12-03 01:45:13.150661: step 8370, loss = 0.53, accu = 0.98, validation: 0.69 (280.6 examples/sec; 0.456 sec/batch)
2016-12-03 01:45:16.839118: step 8380, loss = 0.56, accu = 0.97, validation: 0.74 (366.6 examples/sec; 0.349 sec/batch)
2016-12-03 01:45:20.406620: step 8390, loss = 0.52, accu = 0.98, validation: 0.73 (370.9 examples/sec; 0.345 sec/batch)
2016-12-03 01:45:24.021586: step 8400, loss = 0.52, accu = 0.97, validation: 0.66 (370.3 examples/sec; 0.346 sec/batch)
2016-12-03 01:45:28.032548: step 8410, loss = 0.58, accu = 0.96, validation: 0.67 (373.5 examples/sec; 0.343 sec/batch)
2016-12-03 01:45:31.632381: step 8420, loss = 0.54, accu = 0.98, validation: 0.64 (353.8 examples/sec; 0.362 sec/batch)
2016-12-03 01:45:35.231998: step 8430, loss = 0.51, accu = 0.99, validation: 0.67 (367.3 examples/sec; 0.348 sec/batch)
2016-12-03 01:45:38.844632: step 8440, loss = 0.51, accu = 0.98, validation: 0.74 (377.7 examples/sec; 0.339 sec/batch)
2016-12-03 01:45:42.576030: step 8450, loss = 0.52, accu = 0.98, validation: 0.70 (278.3 examples/sec; 0.460 sec/batch)
2016-12-03 01:45:46.079140: step 8460, loss = 0.56, accu = 0.97, validation: 0.70 (368.7 examples/sec; 0.347 sec/batch)
2016-12-03 01:45:49.733839: step 8470, loss = 0.52, accu = 0.98, validation: 0.74 (366.0 examples/sec; 0.350 sec/batch)
2016-12-03 01:45:53.389884: step 8480, loss = 0.57, accu = 0.97, validation: 0.67 (364.8 examples/sec; 0.351 sec/batch)
2016-12-03 01:45:57.012512: step 8490, loss = 0.50, accu = 0.99, validation: 0.78 (378.0 examples/sec; 0.339 sec/batch)
2016-12-03 01:46:00.660890: step 8500, loss = 0.52, accu = 0.98, validation: 0.75 (361.6 examples/sec; 0.354 sec/batch)
2016-12-03 01:46:04.657081: step 8510, loss = 0.51, accu = 0.99, validation: 0.65 (363.7 examples/sec; 0.352 sec/batch)
2016-12-03 01:46:08.211887: step 8520, loss = 0.53, accu = 0.97, validation: 0.65 (354.8 examples/sec; 0.361 sec/batch)
2016-12-03 01:46:11.825265: step 8530, loss = 0.57, accu = 0.95, validation: 0.74 (334.3 examples/sec; 0.383 sec/batch)
2016-12-03 01:46:15.461684: step 8540, loss = 0.51, accu = 0.98, validation: 0.70 (365.5 examples/sec; 0.350 sec/batch)
2016-12-03 01:46:19.146469: step 8550, loss = 0.50, accu = 0.98, validation: 0.70 (349.4 examples/sec; 0.366 sec/batch)
2016-12-03 01:46:22.878826: step 8560, loss = 0.53, accu = 0.98, validation: 0.67 (333.2 examples/sec; 0.384 sec/batch)
2016-12-03 01:46:26.395198: step 8570, loss = 0.53, accu = 0.97, validation: 0.70 (363.1 examples/sec; 0.353 sec/batch)
2016-12-03 01:46:30.017320: step 8580, loss = 0.51, accu = 0.98, validation: 0.73 (361.3 examples/sec; 0.354 sec/batch)
2016-12-03 01:46:33.646733: step 8590, loss = 0.54, accu = 0.98, validation: 0.71 (385.0 examples/sec; 0.332 sec/batch)
2016-12-03 01:46:37.217295: step 8600, loss = 0.49, accu = 1.00, validation: 0.76 (373.3 examples/sec; 0.343 sec/batch)
2016-12-03 01:46:41.108259: step 8610, loss = 0.49, accu = 1.00, validation: 0.70 (365.3 examples/sec; 0.350 sec/batch)
2016-12-03 01:46:44.845894: step 8620, loss = 0.55, accu = 0.98, validation: 0.65 (353.9 examples/sec; 0.362 sec/batch)
2016-12-03 01:46:48.352409: step 8630, loss = 0.53, accu = 0.98, validation: 0.73 (373.4 examples/sec; 0.343 sec/batch)
2016-12-03 01:46:52.073608: step 8640, loss = 0.49, accu = 0.98, validation: 0.77 (319.5 examples/sec; 0.401 sec/batch)
2016-12-03 01:46:55.642815: step 8650, loss = 0.51, accu = 0.99, validation: 0.70 (361.1 examples/sec; 0.354 sec/batch)
2016-12-03 01:46:59.249790: step 8660, loss = 0.51, accu = 0.98, validation: 0.69 (327.9 examples/sec; 0.390 sec/batch)
2016-12-03 01:47:02.908087: step 8670, loss = 0.53, accu = 0.98, validation: 0.62 (365.3 examples/sec; 0.350 sec/batch)
2016-12-03 01:47:06.524631: step 8680, loss = 0.50, accu = 0.98, validation: 0.70 (374.1 examples/sec; 0.342 sec/batch)
2016-12-03 01:47:10.125303: step 8690, loss = 0.49, accu = 1.00, validation: 0.70 (377.1 examples/sec; 0.339 sec/batch)
2016-12-03 01:47:13.767292: step 8700, loss = 0.49, accu = 0.99, validation: 0.77 (362.3 examples/sec; 0.353 sec/batch)
2016-12-03 01:47:17.640388: step 8710, loss = 0.54, accu = 0.98, validation: 0.72 (349.0 examples/sec; 0.367 sec/batch)
2016-12-03 01:47:21.153405: step 8720, loss = 0.56, accu = 0.97, validation: 0.66 (381.5 examples/sec; 0.336 sec/batch)
2016-12-03 01:47:24.936781: step 8730, loss = 0.51, accu = 0.98, validation: 0.66 (371.4 examples/sec; 0.345 sec/batch)
2016-12-03 01:47:28.555896: step 8740, loss = 0.48, accu = 1.00, validation: 0.68 (288.0 examples/sec; 0.444 sec/batch)
2016-12-03 01:47:32.160576: step 8750, loss = 0.50, accu = 0.99, validation: 0.77 (380.4 examples/sec; 0.337 sec/batch)
2016-12-03 01:47:35.820711: step 8760, loss = 0.51, accu = 0.98, validation: 0.70 (363.8 examples/sec; 0.352 sec/batch)
2016-12-03 01:47:39.372080: step 8770, loss = 0.49, accu = 0.99, validation: 0.66 (366.3 examples/sec; 0.349 sec/batch)
2016-12-03 01:47:42.958017: step 8780, loss = 0.52, accu = 0.95, validation: 0.66 (372.5 examples/sec; 0.344 sec/batch)
2016-12-03 01:47:46.662583: step 8790, loss = 0.52, accu = 0.98, validation: 0.69 (365.1 examples/sec; 0.351 sec/batch)
2016-12-03 01:47:50.335373: step 8800, loss = 0.52, accu = 0.98, validation: 0.70 (372.7 examples/sec; 0.343 sec/batch)
2016-12-03 01:47:54.294331: step 8810, loss = 0.53, accu = 0.98, validation: 0.79 (366.4 examples/sec; 0.349 sec/batch)
2016-12-03 01:47:57.908129: step 8820, loss = 0.53, accu = 0.98, validation: 0.73 (326.7 examples/sec; 0.392 sec/batch)
2016-12-03 01:48:01.655288: step 8830, loss = 0.52, accu = 0.98, validation: 0.72 (272.1 examples/sec; 0.470 sec/batch)
2016-12-03 01:48:05.273002: step 8840, loss = 0.52, accu = 0.98, validation: 0.74 (344.2 examples/sec; 0.372 sec/batch)
2016-12-03 01:48:08.914804: step 8850, loss = 0.51, accu = 0.98, validation: 0.76 (361.2 examples/sec; 0.354 sec/batch)
2016-12-03 01:48:12.543716: step 8860, loss = 0.49, accu = 0.98, validation: 0.70 (368.0 examples/sec; 0.348 sec/batch)
2016-12-03 01:48:16.292277: step 8870, loss = 0.52, accu = 0.96, validation: 0.65 (288.4 examples/sec; 0.444 sec/batch)
2016-12-03 01:48:19.779384: step 8880, loss = 0.50, accu = 0.98, validation: 0.64 (374.2 examples/sec; 0.342 sec/batch)
2016-12-03 01:48:23.449965: step 8890, loss = 0.50, accu = 0.99, validation: 0.74 (375.8 examples/sec; 0.341 sec/batch)
2016-12-03 01:48:27.037805: step 8900, loss = 0.53, accu = 0.98, validation: 0.73 (363.0 examples/sec; 0.353 sec/batch)
2016-12-03 01:48:30.970676: step 8910, loss = 0.49, accu = 0.99, validation: 0.71 (374.3 examples/sec; 0.342 sec/batch)
2016-12-03 01:48:34.579340: step 8920, loss = 0.49, accu = 0.98, validation: 0.74 (335.9 examples/sec; 0.381 sec/batch)
2016-12-03 01:48:38.169137: step 8930, loss = 0.50, accu = 0.98, validation: 0.74 (378.8 examples/sec; 0.338 sec/batch)
2016-12-03 01:48:41.828140: step 8940, loss = 0.50, accu = 0.99, validation: 0.67 (370.1 examples/sec; 0.346 sec/batch)
2016-12-03 01:48:45.439988: step 8950, loss = 0.50, accu = 0.99, validation: 0.73 (369.6 examples/sec; 0.346 sec/batch)
2016-12-03 01:48:49.076184: step 8960, loss = 0.49, accu = 0.99, validation: 0.74 (358.1 examples/sec; 0.357 sec/batch)
2016-12-03 01:48:52.649959: step 8970, loss = 0.51, accu = 0.98, validation: 0.65 (307.0 examples/sec; 0.417 sec/batch)
2016-12-03 01:48:56.328463: step 8980, loss = 0.54, accu = 0.98, validation: 0.67 (361.4 examples/sec; 0.354 sec/batch)
2016-12-03 01:48:59.986117: step 8990, loss = 0.51, accu = 0.98, validation: 0.69 (378.2 examples/sec; 0.338 sec/batch)
2016-12-03 01:49:03.635872: step 9000, loss = 0.50, accu = 0.98, validation: 0.70 (368.9 examples/sec; 0.347 sec/batch)
2016-12-03 01:49:07.974091: step 9010, loss = 0.53, accu = 0.97, validation: 0.69 (364.8 examples/sec; 0.351 sec/batch)
2016-12-03 01:49:11.594400: step 9020, loss = 0.53, accu = 0.96, validation: 0.71 (369.9 examples/sec; 0.346 sec/batch)
2016-12-03 01:49:15.259738: step 9030, loss = 0.51, accu = 0.98, validation: 0.70 (377.0 examples/sec; 0.340 sec/batch)
2016-12-03 01:49:19.044743: step 9040, loss = 0.51, accu = 0.98, validation: 0.73 (291.0 examples/sec; 0.440 sec/batch)
2016-12-03 01:49:22.701664: step 9050, loss = 0.50, accu = 0.98, validation: 0.67 (355.0 examples/sec; 0.361 sec/batch)
2016-12-03 01:49:26.387535: step 9060, loss = 0.49, accu = 0.98, validation: 0.70 (369.0 examples/sec; 0.347 sec/batch)
2016-12-03 01:49:30.085616: step 9070, loss = 0.52, accu = 0.98, validation: 0.73 (374.2 examples/sec; 0.342 sec/batch)
2016-12-03 01:49:33.624306: step 9080, loss = 0.48, accu = 1.00, validation: 0.66 (369.1 examples/sec; 0.347 sec/batch)
2016-12-03 01:49:37.278358: step 9090, loss = 0.49, accu = 0.98, validation: 0.73 (370.6 examples/sec; 0.345 sec/batch)
2016-12-03 01:49:40.985173: step 9100, loss = 0.49, accu = 0.99, validation: 0.77 (378.5 examples/sec; 0.338 sec/batch)
2016-12-03 01:49:44.992941: step 9110, loss = 0.47, accu = 0.99, validation: 0.74 (371.8 examples/sec; 0.344 sec/batch)
2016-12-03 01:49:48.522512: step 9120, loss = 0.53, accu = 0.96, validation: 0.66 (363.8 examples/sec; 0.352 sec/batch)
2016-12-03 01:49:52.278550: step 9130, loss = 0.48, accu = 0.99, validation: 0.62 (332.3 examples/sec; 0.385 sec/batch)
2016-12-03 01:49:55.946673: step 9140, loss = 0.53, accu = 0.98, validation: 0.72 (302.9 examples/sec; 0.423 sec/batch)
2016-12-03 01:49:59.701734: step 9150, loss = 0.49, accu = 0.98, validation: 0.73 (361.4 examples/sec; 0.354 sec/batch)
2016-12-03 01:50:03.280982: step 9160, loss = 0.49, accu = 0.98, validation: 0.76 (353.4 examples/sec; 0.362 sec/batch)
2016-12-03 01:50:06.872750: step 9170, loss = 0.49, accu = 0.99, validation: 0.74 (373.1 examples/sec; 0.343 sec/batch)
2016-12-03 01:50:11.740525: step 9180, loss = 0.49, accu = 0.98, validation: 0.71 (240.3 examples/sec; 0.533 sec/batch)
2016-12-03 01:50:17.734357: step 9190, loss = 0.48, accu = 0.99, validation: 0.69 (249.4 examples/sec; 0.513 sec/batch)
2016-12-03 01:50:21.777672: step 9200, loss = 0.47, accu = 0.99, validation: 0.67 (366.6 examples/sec; 0.349 sec/batch)
2016-12-03 01:50:25.711835: step 9210, loss = 0.51, accu = 0.97, validation: 0.78 (337.3 examples/sec; 0.380 sec/batch)
2016-12-03 01:50:29.306742: step 9220, loss = 0.49, accu = 0.99, validation: 0.70 (341.8 examples/sec; 0.375 sec/batch)
2016-12-03 01:50:33.087451: step 9230, loss = 0.51, accu = 0.98, validation: 0.66 (308.3 examples/sec; 0.415 sec/batch)
2016-12-03 01:50:36.776013: step 9240, loss = 0.47, accu = 0.99, validation: 0.72 (321.5 examples/sec; 0.398 sec/batch)
2016-12-03 01:50:40.549092: step 9250, loss = 0.51, accu = 0.97, validation: 0.74 (358.6 examples/sec; 0.357 sec/batch)
2016-12-03 01:50:44.129189: step 9260, loss = 0.48, accu = 0.99, validation: 0.74 (280.9 examples/sec; 0.456 sec/batch)
2016-12-03 01:50:47.760927: step 9270, loss = 0.53, accu = 0.97, validation: 0.73 (371.8 examples/sec; 0.344 sec/batch)
2016-12-03 01:50:51.431986: step 9280, loss = 0.46, accu = 1.00, validation: 0.71 (379.2 examples/sec; 0.338 sec/batch)
2016-12-03 01:50:54.907763: step 9290, loss = 0.48, accu = 0.98, validation: 0.75 (364.1 examples/sec; 0.352 sec/batch)
2016-12-03 01:50:58.459186: step 9300, loss = 0.49, accu = 0.98, validation: 0.68 (386.7 examples/sec; 0.331 sec/batch)
2016-12-03 01:51:02.479244: step 9310, loss = 0.47, accu = 0.99, validation: 0.70 (372.4 examples/sec; 0.344 sec/batch)
2016-12-03 01:51:06.065775: step 9320, loss = 0.47, accu = 0.99, validation: 0.66 (291.4 examples/sec; 0.439 sec/batch)
2016-12-03 01:51:09.689960: step 9330, loss = 0.49, accu = 0.98, validation: 0.68 (366.6 examples/sec; 0.349 sec/batch)
2016-12-03 01:51:13.275364: step 9340, loss = 0.48, accu = 0.98, validation: 0.59 (375.2 examples/sec; 0.341 sec/batch)
2016-12-03 01:51:16.732483: step 9350, loss = 0.47, accu = 0.99, validation: 0.70 (386.5 examples/sec; 0.331 sec/batch)
2016-12-03 01:51:20.375758: step 9360, loss = 0.49, accu = 0.98, validation: 0.69 (376.8 examples/sec; 0.340 sec/batch)
2016-12-03 01:51:23.962623: step 9370, loss = 0.48, accu = 0.98, validation: 0.69 (388.7 examples/sec; 0.329 sec/batch)
2016-12-03 01:51:27.550217: step 9380, loss = 0.47, accu = 0.99, validation: 0.70 (350.9 examples/sec; 0.365 sec/batch)
2016-12-03 01:51:31.136323: step 9390, loss = 0.51, accu = 0.98, validation: 0.73 (375.3 examples/sec; 0.341 sec/batch)
2016-12-03 01:51:34.668199: step 9400, loss = 0.49, accu = 0.98, validation: 0.67 (364.6 examples/sec; 0.351 sec/batch)
2016-12-03 01:51:38.603005: step 9410, loss = 0.48, accu = 0.98, validation: 0.77 (368.8 examples/sec; 0.347 sec/batch)
2016-12-03 01:51:42.230895: step 9420, loss = 0.49, accu = 0.98, validation: 0.70 (319.9 examples/sec; 0.400 sec/batch)
2016-12-03 01:51:45.725379: step 9430, loss = 0.52, accu = 0.98, validation: 0.64 (371.3 examples/sec; 0.345 sec/batch)
2016-12-03 01:51:49.374865: step 9440, loss = 0.49, accu = 0.99, validation: 0.66 (351.7 examples/sec; 0.364 sec/batch)
2016-12-03 01:51:52.800348: step 9450, loss = 0.48, accu = 0.99, validation: 0.67 (384.6 examples/sec; 0.333 sec/batch)
2016-12-03 01:51:56.448093: step 9460, loss = 0.54, accu = 0.95, validation: 0.70 (377.3 examples/sec; 0.339 sec/batch)
2016-12-03 01:52:00.022004: step 9470, loss = 0.47, accu = 1.00, validation: 0.70 (371.4 examples/sec; 0.345 sec/batch)
2016-12-03 01:52:03.628803: step 9480, loss = 0.46, accu = 1.00, validation: 0.70 (377.5 examples/sec; 0.339 sec/batch)
2016-12-03 01:52:07.288767: step 9490, loss = 0.49, accu = 0.98, validation: 0.70 (369.5 examples/sec; 0.346 sec/batch)
2016-12-03 01:52:10.928017: step 9500, loss = 0.50, accu = 0.98, validation: 0.72 (342.6 examples/sec; 0.374 sec/batch)
2016-12-03 01:52:14.752989: step 9510, loss = 0.59, accu = 0.94, validation: 0.66 (369.5 examples/sec; 0.346 sec/batch)
2016-12-03 01:52:18.232575: step 9520, loss = 0.51, accu = 0.97, validation: 0.78 (380.6 examples/sec; 0.336 sec/batch)
2016-12-03 01:52:21.854687: step 9530, loss = 0.49, accu = 0.99, validation: 0.77 (287.2 examples/sec; 0.446 sec/batch)
2016-12-03 01:52:25.558686: step 9540, loss = 0.50, accu = 0.98, validation: 0.70 (363.0 examples/sec; 0.353 sec/batch)
2016-12-03 01:52:29.049813: step 9550, loss = 0.53, accu = 0.96, validation: 0.70 (364.9 examples/sec; 0.351 sec/batch)
2016-12-03 01:52:32.810882: step 9560, loss = 0.47, accu = 0.99, validation: 0.76 (308.9 examples/sec; 0.414 sec/batch)
2016-12-03 01:52:36.433708: step 9570, loss = 0.49, accu = 0.98, validation: 0.72 (366.3 examples/sec; 0.349 sec/batch)
2016-12-03 01:52:40.064819: step 9580, loss = 0.49, accu = 0.97, validation: 0.73 (355.1 examples/sec; 0.360 sec/batch)
2016-12-03 01:52:43.709105: step 9590, loss = 0.49, accu = 0.98, validation: 0.66 (358.3 examples/sec; 0.357 sec/batch)
2016-12-03 01:52:47.329580: step 9600, loss = 0.48, accu = 0.98, validation: 0.73 (334.1 examples/sec; 0.383 sec/batch)
2016-12-03 01:52:51.207373: step 9610, loss = 0.49, accu = 0.98, validation: 0.73 (354.2 examples/sec; 0.361 sec/batch)
2016-12-03 01:52:54.785261: step 9620, loss = 0.49, accu = 0.99, validation: 0.70 (369.3 examples/sec; 0.347 sec/batch)
2016-12-03 01:52:58.383344: step 9630, loss = 0.49, accu = 0.98, validation: 0.72 (384.2 examples/sec; 0.333 sec/batch)
2016-12-03 01:53:01.917312: step 9640, loss = 0.50, accu = 0.97, validation: 0.68 (382.3 examples/sec; 0.335 sec/batch)
2016-12-03 01:53:05.580676: step 9650, loss = 0.49, accu = 0.98, validation: 0.68 (367.3 examples/sec; 0.348 sec/batch)
2016-12-03 01:53:09.177395: step 9660, loss = 0.49, accu = 0.98, validation: 0.72 (385.8 examples/sec; 0.332 sec/batch)
2016-12-03 01:53:12.644133: step 9670, loss = 0.49, accu = 0.98, validation: 0.77 (366.2 examples/sec; 0.350 sec/batch)
2016-12-03 01:53:16.232775: step 9680, loss = 0.49, accu = 0.98, validation: 0.70 (380.2 examples/sec; 0.337 sec/batch)
2016-12-03 01:53:19.701095: step 9690, loss = 0.47, accu = 1.00, validation: 0.67 (378.5 examples/sec; 0.338 sec/batch)
2016-12-03 01:53:23.379002: step 9700, loss = 0.50, accu = 0.98, validation: 0.66 (365.5 examples/sec; 0.350 sec/batch)
2016-12-03 01:53:27.306297: step 9710, loss = 0.48, accu = 0.98, validation: 0.68 (351.4 examples/sec; 0.364 sec/batch)
2016-12-03 01:53:30.996471: step 9720, loss = 0.48, accu = 0.99, validation: 0.73 (324.6 examples/sec; 0.394 sec/batch)
2016-12-03 01:53:34.568854: step 9730, loss = 0.47, accu = 0.99, validation: 0.76 (284.3 examples/sec; 0.450 sec/batch)
2016-12-03 01:53:38.154957: step 9740, loss = 0.52, accu = 0.98, validation: 0.75 (373.2 examples/sec; 0.343 sec/batch)
2016-12-03 01:53:41.773059: step 9750, loss = 0.47, accu = 0.99, validation: 0.68 (373.2 examples/sec; 0.343 sec/batch)
2016-12-03 01:53:45.404808: step 9760, loss = 0.50, accu = 0.98, validation: 0.64 (273.5 examples/sec; 0.468 sec/batch)
2016-12-03 01:53:49.035896: step 9770, loss = 0.49, accu = 0.98, validation: 0.72 (335.3 examples/sec; 0.382 sec/batch)
2016-12-03 01:53:52.657779: step 9780, loss = 0.50, accu = 0.97, validation: 0.73 (345.8 examples/sec; 0.370 sec/batch)
2016-12-03 01:53:56.191830: step 9790, loss = 0.47, accu = 0.99, validation: 0.72 (369.4 examples/sec; 0.347 sec/batch)
2016-12-03 01:53:59.848406: step 9800, loss = 0.47, accu = 0.99, validation: 0.66 (364.5 examples/sec; 0.351 sec/batch)
2016-12-03 01:54:03.714224: step 9810, loss = 0.46, accu = 1.00, validation: 0.69 (341.5 examples/sec; 0.375 sec/batch)
2016-12-03 01:54:07.348225: step 9820, loss = 0.54, accu = 0.98, validation: 0.73 (379.9 examples/sec; 0.337 sec/batch)
2016-12-03 01:54:10.924065: step 9830, loss = 0.49, accu = 0.98, validation: 0.72 (380.2 examples/sec; 0.337 sec/batch)
2016-12-03 01:54:14.540361: step 9840, loss = 0.50, accu = 0.98, validation: 0.74 (371.1 examples/sec; 0.345 sec/batch)
2016-12-03 01:54:18.183365: step 9850, loss = 0.49, accu = 0.97, validation: 0.70 (357.0 examples/sec; 0.359 sec/batch)
2016-12-03 01:54:21.738320: step 9860, loss = 0.49, accu = 0.98, validation: 0.67 (326.6 examples/sec; 0.392 sec/batch)
2016-12-03 01:54:25.318222: step 9870, loss = 0.50, accu = 0.98, validation: 0.70 (374.3 examples/sec; 0.342 sec/batch)
2016-12-03 01:54:28.935041: step 9880, loss = 0.48, accu = 1.00, validation: 0.78 (373.0 examples/sec; 0.343 sec/batch)
2016-12-03 01:54:32.606420: step 9890, loss = 0.48, accu = 0.99, validation: 0.67 (359.9 examples/sec; 0.356 sec/batch)
2016-12-03 01:54:36.303388: step 9900, loss = 0.46, accu = 1.00, validation: 0.70 (321.0 examples/sec; 0.399 sec/batch)
2016-12-03 01:54:40.096590: step 9910, loss = 0.50, accu = 0.97, validation: 0.67 (330.8 examples/sec; 0.387 sec/batch)
2016-12-03 01:54:43.750580: step 9920, loss = 0.48, accu = 0.98, validation: 0.71 (365.2 examples/sec; 0.351 sec/batch)
2016-12-03 01:54:47.366990: step 9930, loss = 0.51, accu = 0.98, validation: 0.69 (380.4 examples/sec; 0.336 sec/batch)
2016-12-03 01:54:50.875539: step 9940, loss = 0.47, accu = 0.99, validation: 0.73 (336.7 examples/sec; 0.380 sec/batch)
2016-12-03 01:54:54.420290: step 9950, loss = 0.50, accu = 0.98, validation: 0.71 (294.0 examples/sec; 0.435 sec/batch)
2016-12-03 01:54:58.028054: step 9960, loss = 0.48, accu = 0.98, validation: 0.71 (381.2 examples/sec; 0.336 sec/batch)
2016-12-03 01:55:01.656645: step 9970, loss = 0.53, accu = 0.96, validation: 0.68 (292.0 examples/sec; 0.438 sec/batch)
2016-12-03 01:55:05.166024: step 9980, loss = 0.48, accu = 0.98, validation: 0.73 (363.0 examples/sec; 0.353 sec/batch)
2016-12-03 01:55:08.759346: step 9990, loss = 0.51, accu = 0.98, validation: 0.76 (352.8 examples/sec; 0.363 sec/batch)
2016-12-03 01:55:12.262066: step 10000, loss = 0.46, accu = 0.99, validation: 0.66 (374.1 examples/sec; 0.342 sec/batch)
2016-12-03 01:55:16.795426: step 10010, loss = 0.46, accu = 0.99, validation: 0.68 (303.8 examples/sec; 0.421 sec/batch)
2016-12-03 01:55:20.412715: step 10020, loss = 0.49, accu = 0.98, validation: 0.69 (280.4 examples/sec; 0.456 sec/batch)
2016-12-03 01:55:24.065739: step 10030, loss = 0.49, accu = 0.98, validation: 0.68 (371.4 examples/sec; 0.345 sec/batch)
2016-12-03 01:55:27.775101: step 10040, loss = 0.51, accu = 0.98, validation: 0.72 (357.0 examples/sec; 0.359 sec/batch)
2016-12-03 01:55:31.405043: step 10050, loss = 0.50, accu = 0.98, validation: 0.70 (366.9 examples/sec; 0.349 sec/batch)
2016-12-03 01:55:35.144091: step 10060, loss = 0.49, accu = 0.99, validation: 0.68 (366.2 examples/sec; 0.350 sec/batch)
2016-12-03 01:55:38.782954: step 10070, loss = 0.49, accu = 0.98, validation: 0.73 (356.6 examples/sec; 0.359 sec/batch)
2016-12-03 01:55:42.352408: step 10080, loss = 0.49, accu = 0.99, validation: 0.67 (370.6 examples/sec; 0.345 sec/batch)
2016-12-03 01:55:46.121152: step 10090, loss = 0.49, accu = 0.98, validation: 0.76 (292.2 examples/sec; 0.438 sec/batch)
2016-12-03 01:55:49.806937: step 10100, loss = 0.48, accu = 1.00, validation: 0.68 (365.5 examples/sec; 0.350 sec/batch)
2016-12-03 01:55:53.674104: step 10110, loss = 0.50, accu = 0.97, validation: 0.66 (385.1 examples/sec; 0.332 sec/batch)
2016-12-03 01:55:57.339075: step 10120, loss = 0.47, accu = 0.99, validation: 0.70 (383.0 examples/sec; 0.334 sec/batch)
2016-12-03 01:56:00.886386: step 10130, loss = 0.48, accu = 1.00, validation: 0.74 (367.2 examples/sec; 0.349 sec/batch)
2016-12-03 01:56:04.598639: step 10140, loss = 0.51, accu = 0.97, validation: 0.73 (353.5 examples/sec; 0.362 sec/batch)
2016-12-03 01:56:08.258246: step 10150, loss = 0.48, accu = 0.98, validation: 0.70 (370.3 examples/sec; 0.346 sec/batch)
2016-12-03 01:56:11.918463: step 10160, loss = 0.51, accu = 0.98, validation: 0.71 (366.0 examples/sec; 0.350 sec/batch)
2016-12-03 01:56:15.617929: step 10170, loss = 0.52, accu = 0.96, validation: 0.71 (351.6 examples/sec; 0.364 sec/batch)
2016-12-03 01:56:19.306029: step 10180, loss = 0.49, accu = 0.98, validation: 0.72 (365.9 examples/sec; 0.350 sec/batch)
2016-12-03 01:56:22.977863: step 10190, loss = 0.51, accu = 0.98, validation: 0.70 (264.2 examples/sec; 0.485 sec/batch)
2016-12-03 01:56:26.625777: step 10200, loss = 0.51, accu = 0.98, validation: 0.74 (354.4 examples/sec; 0.361 sec/batch)
2016-12-03 01:56:30.583467: step 10210, loss = 0.49, accu = 0.98, validation: 0.69 (366.7 examples/sec; 0.349 sec/batch)
2016-12-03 01:56:34.267061: step 10220, loss = 0.46, accu = 0.99, validation: 0.71 (355.2 examples/sec; 0.360 sec/batch)
2016-12-03 01:56:37.973194: step 10230, loss = 0.49, accu = 0.99, validation: 0.73 (339.8 examples/sec; 0.377 sec/batch)
2016-12-03 01:56:41.746698: step 10240, loss = 0.49, accu = 0.98, validation: 0.77 (362.8 examples/sec; 0.353 sec/batch)
2016-12-03 01:56:45.422286: step 10250, loss = 0.49, accu = 0.98, validation: 0.71 (368.1 examples/sec; 0.348 sec/batch)
2016-12-03 01:56:49.162447: step 10260, loss = 0.48, accu = 0.99, validation: 0.68 (363.6 examples/sec; 0.352 sec/batch)
2016-12-03 01:56:52.835455: step 10270, loss = 0.47, accu = 1.00, validation: 0.69 (383.4 examples/sec; 0.334 sec/batch)
2016-12-03 01:56:56.399478: step 10280, loss = 0.48, accu = 0.98, validation: 0.73 (376.5 examples/sec; 0.340 sec/batch)
2016-12-03 01:56:59.984903: step 10290, loss = 0.53, accu = 0.97, validation: 0.74 (387.2 examples/sec; 0.331 sec/batch)
2016-12-03 01:57:03.513746: step 10300, loss = 0.48, accu = 0.98, validation: 0.75 (369.6 examples/sec; 0.346 sec/batch)
2016-12-03 01:57:07.395911: step 10310, loss = 0.48, accu = 0.98, validation: 0.73 (366.5 examples/sec; 0.349 sec/batch)
2016-12-03 01:57:10.899443: step 10320, loss = 0.51, accu = 0.98, validation: 0.70 (383.5 examples/sec; 0.334 sec/batch)
2016-12-03 01:57:14.518612: step 10330, loss = 0.52, accu = 0.98, validation: 0.74 (385.4 examples/sec; 0.332 sec/batch)
2016-12-03 01:57:18.156371: step 10340, loss = 0.50, accu = 0.97, validation: 0.71 (381.9 examples/sec; 0.335 sec/batch)
2016-12-03 01:57:21.786928: step 10350, loss = 0.55, accu = 0.95, validation: 0.69 (374.3 examples/sec; 0.342 sec/batch)
2016-12-03 01:57:25.379045: step 10360, loss = 0.47, accu = 0.99, validation: 0.66 (353.8 examples/sec; 0.362 sec/batch)
2016-12-03 01:57:28.989907: step 10370, loss = 0.49, accu = 0.98, validation: 0.59 (371.5 examples/sec; 0.345 sec/batch)
2016-12-03 01:57:32.562240: step 10380, loss = 0.49, accu = 0.99, validation: 0.70 (370.3 examples/sec; 0.346 sec/batch)
2016-12-03 01:57:36.317915: step 10390, loss = 0.47, accu = 0.99, validation: 0.72 (363.4 examples/sec; 0.352 sec/batch)
2016-12-03 01:57:39.807491: step 10400, loss = 0.49, accu = 0.99, validation: 0.68 (367.4 examples/sec; 0.348 sec/batch)
2016-12-03 01:57:43.716189: step 10410, loss = 0.50, accu = 0.98, validation: 0.73 (276.6 examples/sec; 0.463 sec/batch)
2016-12-03 01:57:47.298671: step 10420, loss = 0.48, accu = 0.98, validation: 0.73 (379.5 examples/sec; 0.337 sec/batch)
2016-12-03 01:57:50.859018: step 10430, loss = 0.48, accu = 0.98, validation: 0.68 (376.9 examples/sec; 0.340 sec/batch)
2016-12-03 01:57:54.466481: step 10440, loss = 0.48, accu = 0.98, validation: 0.76 (368.1 examples/sec; 0.348 sec/batch)
2016-12-03 01:57:58.069197: step 10450, loss = 0.48, accu = 1.00, validation: 0.76 (368.3 examples/sec; 0.348 sec/batch)
2016-12-03 01:58:01.663251: step 10460, loss = 0.50, accu = 0.98, validation: 0.64 (368.4 examples/sec; 0.347 sec/batch)
2016-12-03 01:58:05.226223: step 10470, loss = 0.46, accu = 1.00, validation: 0.66 (385.8 examples/sec; 0.332 sec/batch)
2016-12-03 01:58:08.962833: step 10480, loss = 0.49, accu = 0.98, validation: 0.66 (340.5 examples/sec; 0.376 sec/batch)
2016-12-03 01:58:12.588458: step 10490, loss = 0.50, accu = 0.98, validation: 0.70 (350.0 examples/sec; 0.366 sec/batch)
2016-12-03 01:58:16.177977: step 10500, loss = 0.47, accu = 0.98, validation: 0.73 (364.7 examples/sec; 0.351 sec/batch)
2016-12-03 01:58:20.064947: step 10510, loss = 0.47, accu = 0.99, validation: 0.71 (372.0 examples/sec; 0.344 sec/batch)
2016-12-03 01:58:23.630879: step 10520, loss = 0.49, accu = 0.98, validation: 0.69 (375.4 examples/sec; 0.341 sec/batch)
2016-12-03 01:58:27.239441: step 10530, loss = 0.49, accu = 0.98, validation: 0.72 (279.7 examples/sec; 0.458 sec/batch)
2016-12-03 01:58:30.775024: step 10540, loss = 0.49, accu = 0.98, validation: 0.67 (349.0 examples/sec; 0.367 sec/batch)
2016-12-03 01:58:34.379798: step 10550, loss = 0.50, accu = 0.98, validation: 0.75 (373.1 examples/sec; 0.343 sec/batch)
2016-12-03 01:58:38.017089: step 10560, loss = 0.47, accu = 0.99, validation: 0.74 (372.0 examples/sec; 0.344 sec/batch)
2016-12-03 01:58:41.666359: step 10570, loss = 0.51, accu = 0.98, validation: 0.69 (371.7 examples/sec; 0.344 sec/batch)
2016-12-03 01:58:45.244877: step 10580, loss = 0.48, accu = 0.99, validation: 0.68 (376.1 examples/sec; 0.340 sec/batch)
2016-12-03 01:58:48.904832: step 10590, loss = 0.51, accu = 0.98, validation: 0.79 (365.8 examples/sec; 0.350 sec/batch)
2016-12-03 01:58:52.476004: step 10600, loss = 0.48, accu = 0.98, validation: 0.70 (367.9 examples/sec; 0.348 sec/batch)
2016-12-03 01:58:56.303910: step 10610, loss = 0.48, accu = 0.98, validation: 0.70 (372.9 examples/sec; 0.343 sec/batch)
2016-12-03 01:58:59.929067: step 10620, loss = 0.51, accu = 0.98, validation: 0.67 (374.9 examples/sec; 0.341 sec/batch)
2016-12-03 01:59:03.542329: step 10630, loss = 0.47, accu = 0.99, validation: 0.73 (373.7 examples/sec; 0.343 sec/batch)
2016-12-03 01:59:07.156913: step 10640, loss = 0.47, accu = 1.00, validation: 0.73 (358.1 examples/sec; 0.357 sec/batch)
2016-12-03 01:59:10.746677: step 10650, loss = 0.46, accu = 1.00, validation: 0.75 (374.7 examples/sec; 0.342 sec/batch)
2016-12-03 01:59:14.283995: step 10660, loss = 0.47, accu = 0.99, validation: 0.73 (351.5 examples/sec; 0.364 sec/batch)
2016-12-03 01:59:17.959917: step 10670, loss = 0.49, accu = 0.99, validation: 0.66 (372.1 examples/sec; 0.344 sec/batch)
2016-12-03 01:59:21.531514: step 10680, loss = 0.47, accu = 0.98, validation: 0.66 (377.0 examples/sec; 0.339 sec/batch)
2016-12-03 01:59:25.189813: step 10690, loss = 0.48, accu = 0.98, validation: 0.75 (359.9 examples/sec; 0.356 sec/batch)
2016-12-03 01:59:28.825703: step 10700, loss = 0.48, accu = 0.98, validation: 0.80 (367.1 examples/sec; 0.349 sec/batch)
2016-12-03 01:59:32.604307: step 10710, loss = 0.49, accu = 0.99, validation: 0.70 (361.6 examples/sec; 0.354 sec/batch)
2016-12-03 01:59:36.280991: step 10720, loss = 0.48, accu = 0.99, validation: 0.68 (350.7 examples/sec; 0.365 sec/batch)
2016-12-03 01:59:39.875213: step 10730, loss = 0.45, accu = 1.00, validation: 0.66 (371.9 examples/sec; 0.344 sec/batch)
2016-12-03 01:59:43.474533: step 10740, loss = 0.51, accu = 0.97, validation: 0.67 (287.6 examples/sec; 0.445 sec/batch)
2016-12-03 01:59:47.123039: step 10750, loss = 0.49, accu = 0.99, validation: 0.71 (360.1 examples/sec; 0.355 sec/batch)
2016-12-03 01:59:50.717485: step 10760, loss = 0.47, accu = 0.99, validation: 0.77 (373.4 examples/sec; 0.343 sec/batch)
2016-12-03 01:59:54.372878: step 10770, loss = 0.48, accu = 0.98, validation: 0.77 (361.2 examples/sec; 0.354 sec/batch)
2016-12-03 01:59:58.000680: step 10780, loss = 0.50, accu = 0.97, validation: 0.70 (360.8 examples/sec; 0.355 sec/batch)
2016-12-03 02:00:01.456659: step 10790, loss = 0.47, accu = 0.98, validation: 0.70 (374.3 examples/sec; 0.342 sec/batch)
2016-12-03 02:00:05.091405: step 10800, loss = 0.48, accu = 0.99, validation: 0.75 (373.8 examples/sec; 0.342 sec/batch)
2016-12-03 02:00:09.002696: step 10810, loss = 0.47, accu = 0.99, validation: 0.75 (359.7 examples/sec; 0.356 sec/batch)
2016-12-03 02:00:12.622877: step 10820, loss = 0.47, accu = 0.99, validation: 0.76 (377.2 examples/sec; 0.339 sec/batch)
2016-12-03 02:00:16.236632: step 10830, loss = 0.49, accu = 0.98, validation: 0.64 (372.3 examples/sec; 0.344 sec/batch)
2016-12-03 02:00:19.818473: step 10840, loss = 0.47, accu = 0.98, validation: 0.65 (370.0 examples/sec; 0.346 sec/batch)
2016-12-03 02:00:23.432128: step 10850, loss = 0.48, accu = 1.00, validation: 0.73 (376.3 examples/sec; 0.340 sec/batch)
2016-12-03 02:00:26.916129: step 10860, loss = 0.50, accu = 0.96, validation: 0.73 (373.1 examples/sec; 0.343 sec/batch)
2016-12-03 02:00:30.652333: step 10870, loss = 0.53, accu = 0.98, validation: 0.74 (285.6 examples/sec; 0.448 sec/batch)
2016-12-03 02:00:34.336842: step 10880, loss = 0.49, accu = 0.98, validation: 0.71 (275.1 examples/sec; 0.465 sec/batch)
2016-12-03 02:00:38.010236: step 10890, loss = 0.47, accu = 0.98, validation: 0.70 (374.8 examples/sec; 0.342 sec/batch)
2016-12-03 02:00:41.494355: step 10900, loss = 0.49, accu = 0.98, validation: 0.77 (365.5 examples/sec; 0.350 sec/batch)
2016-12-03 02:00:45.514798: step 10910, loss = 0.47, accu = 0.99, validation: 0.77 (280.1 examples/sec; 0.457 sec/batch)
2016-12-03 02:00:49.188386: step 10920, loss = 0.49, accu = 0.98, validation: 0.66 (286.6 examples/sec; 0.447 sec/batch)
2016-12-03 02:00:52.830368: step 10930, loss = 0.51, accu = 0.98, validation: 0.72 (375.1 examples/sec; 0.341 sec/batch)
2016-12-03 02:00:56.280783: step 10940, loss = 0.49, accu = 0.97, validation: 0.69 (387.8 examples/sec; 0.330 sec/batch)
2016-12-03 02:00:59.915248: step 10950, loss = 0.47, accu = 0.99, validation: 0.70 (382.3 examples/sec; 0.335 sec/batch)
2016-12-03 02:01:03.400031: step 10960, loss = 0.49, accu = 0.98, validation: 0.72 (381.4 examples/sec; 0.336 sec/batch)
2016-12-03 02:01:07.003458: step 10970, loss = 0.49, accu = 0.98, validation: 0.68 (366.8 examples/sec; 0.349 sec/batch)
2016-12-03 02:01:10.693009: step 10980, loss = 0.49, accu = 0.98, validation: 0.74 (360.6 examples/sec; 0.355 sec/batch)
2016-12-03 02:01:14.292117: step 10990, loss = 0.48, accu = 0.99, validation: 0.74 (364.2 examples/sec; 0.351 sec/batch)
2016-12-03 02:01:17.905107: step 11000, loss = 0.46, accu = 0.98, validation: 0.67 (276.9 examples/sec; 0.462 sec/batch)
2016-12-03 02:01:22.084289: step 11010, loss = 0.50, accu = 0.97, validation: 0.76 (373.9 examples/sec; 0.342 sec/batch)
2016-12-03 02:01:25.705477: step 11020, loss = 0.48, accu = 0.98, validation: 0.76 (368.2 examples/sec; 0.348 sec/batch)
2016-12-03 02:01:29.388896: step 11030, loss = 0.48, accu = 0.98, validation: 0.68 (373.1 examples/sec; 0.343 sec/batch)
2016-12-03 02:01:33.116657: step 11040, loss = 0.47, accu = 0.99, validation: 0.68 (366.1 examples/sec; 0.350 sec/batch)
2016-12-03 02:01:36.705740: step 11050, loss = 0.51, accu = 0.98, validation: 0.70 (342.0 examples/sec; 0.374 sec/batch)
2016-12-03 02:01:40.386404: step 11060, loss = 0.46, accu = 0.99, validation: 0.70 (363.1 examples/sec; 0.352 sec/batch)
2016-12-03 02:01:44.000196: step 11070, loss = 0.47, accu = 1.00, validation: 0.70 (362.8 examples/sec; 0.353 sec/batch)
2016-12-03 02:01:47.621719: step 11080, loss = 0.46, accu = 0.99, validation: 0.70 (363.6 examples/sec; 0.352 sec/batch)
2016-12-03 02:01:51.368226: step 11090, loss = 0.50, accu = 0.98, validation: 0.72 (364.2 examples/sec; 0.351 sec/batch)
2016-12-03 02:01:55.065810: step 11100, loss = 0.48, accu = 0.98, validation: 0.73 (360.1 examples/sec; 0.356 sec/batch)
2016-12-03 02:01:59.033126: step 11110, loss = 0.52, accu = 0.97, validation: 0.66 (265.4 examples/sec; 0.482 sec/batch)
2016-12-03 02:02:02.675425: step 11120, loss = 0.49, accu = 0.98, validation: 0.74 (378.9 examples/sec; 0.338 sec/batch)
2016-12-03 02:02:06.248278: step 11130, loss = 0.48, accu = 0.99, validation: 0.71 (382.3 examples/sec; 0.335 sec/batch)
2016-12-03 02:02:10.180846: step 11140, loss = 0.47, accu = 0.98, validation: 0.62 (363.9 examples/sec; 0.352 sec/batch)
2016-12-03 02:02:13.881113: step 11150, loss = 0.47, accu = 0.99, validation: 0.70 (351.5 examples/sec; 0.364 sec/batch)
2016-12-03 02:02:17.669957: step 11160, loss = 0.47, accu = 0.99, validation: 0.73 (285.6 examples/sec; 0.448 sec/batch)
2016-12-03 02:02:21.263180: step 11170, loss = 0.47, accu = 1.00, validation: 0.68 (380.8 examples/sec; 0.336 sec/batch)
2016-12-03 02:02:24.923255: step 11180, loss = 0.49, accu = 0.98, validation: 0.69 (366.8 examples/sec; 0.349 sec/batch)
2016-12-03 02:02:28.773658: step 11190, loss = 0.48, accu = 0.99, validation: 0.66 (306.9 examples/sec; 0.417 sec/batch)
2016-12-03 02:02:32.365960: step 11200, loss = 0.46, accu = 1.00, validation: 0.73 (357.8 examples/sec; 0.358 sec/batch)
2016-12-03 02:02:36.260404: step 11210, loss = 0.52, accu = 0.95, validation: 0.70 (358.1 examples/sec; 0.357 sec/batch)
2016-12-03 02:02:40.081128: step 11220, loss = 0.48, accu = 0.99, validation: 0.72 (352.9 examples/sec; 0.363 sec/batch)
2016-12-03 02:02:43.780809: step 11230, loss = 0.47, accu = 0.98, validation: 0.75 (281.1 examples/sec; 0.455 sec/batch)
2016-12-03 02:02:47.389930: step 11240, loss = 0.48, accu = 0.98, validation: 0.67 (360.0 examples/sec; 0.356 sec/batch)
2016-12-03 02:02:51.056204: step 11250, loss = 0.49, accu = 0.98, validation: 0.67 (354.6 examples/sec; 0.361 sec/batch)
2016-12-03 02:02:54.690990: step 11260, loss = 0.46, accu = 1.00, validation: 0.69 (353.9 examples/sec; 0.362 sec/batch)
2016-12-03 02:02:58.365687: step 11270, loss = 0.48, accu = 0.98, validation: 0.75 (370.4 examples/sec; 0.346 sec/batch)
2016-12-03 02:03:01.991503: step 11280, loss = 0.48, accu = 0.98, validation: 0.72 (383.1 examples/sec; 0.334 sec/batch)
2016-12-03 02:03:05.631572: step 11290, loss = 0.48, accu = 0.98, validation: 0.68 (371.9 examples/sec; 0.344 sec/batch)
2016-12-03 02:03:09.102619: step 11300, loss = 0.49, accu = 0.97, validation: 0.66 (379.3 examples/sec; 0.337 sec/batch)
2016-12-03 02:03:13.016139: step 11310, loss = 0.45, accu = 1.00, validation: 0.73 (359.6 examples/sec; 0.356 sec/batch)
2016-12-03 02:03:16.743790: step 11320, loss = 0.49, accu = 0.98, validation: 0.73 (366.3 examples/sec; 0.349 sec/batch)
2016-12-03 02:03:20.375205: step 11330, loss = 0.49, accu = 0.98, validation: 0.73 (362.1 examples/sec; 0.354 sec/batch)
2016-12-03 02:03:23.950677: step 11340, loss = 0.50, accu = 0.98, validation: 0.73 (371.7 examples/sec; 0.344 sec/batch)
2016-12-03 02:03:27.565782: step 11350, loss = 0.49, accu = 0.98, validation: 0.76 (330.7 examples/sec; 0.387 sec/batch)
2016-12-03 02:03:31.121465: step 11360, loss = 0.46, accu = 0.99, validation: 0.71 (316.1 examples/sec; 0.405 sec/batch)
2016-12-03 02:03:34.838148: step 11370, loss = 0.48, accu = 0.99, validation: 0.76 (367.4 examples/sec; 0.348 sec/batch)
2016-12-03 02:03:38.350144: step 11380, loss = 0.49, accu = 0.99, validation: 0.70 (369.3 examples/sec; 0.347 sec/batch)
2016-12-03 02:03:42.024115: step 11390, loss = 0.48, accu = 1.00, validation: 0.67 (372.1 examples/sec; 0.344 sec/batch)
2016-12-03 02:03:45.623493: step 11400, loss = 0.53, accu = 0.97, validation: 0.64 (368.8 examples/sec; 0.347 sec/batch)
2016-12-03 02:03:49.582302: step 11410, loss = 0.47, accu = 0.99, validation: 0.73 (349.7 examples/sec; 0.366 sec/batch)
2016-12-03 02:03:53.320431: step 11420, loss = 0.48, accu = 1.00, validation: 0.69 (376.0 examples/sec; 0.340 sec/batch)
2016-12-03 02:03:56.957416: step 11430, loss = 0.50, accu = 0.98, validation: 0.69 (297.2 examples/sec; 0.431 sec/batch)
2016-12-03 02:04:00.637086: step 11440, loss = 0.49, accu = 0.97, validation: 0.69 (353.8 examples/sec; 0.362 sec/batch)
2016-12-03 02:04:04.094037: step 11450, loss = 0.47, accu = 0.98, validation: 0.75 (371.3 examples/sec; 0.345 sec/batch)
2016-12-03 02:04:07.771569: step 11460, loss = 0.53, accu = 0.98, validation: 0.66 (377.0 examples/sec; 0.340 sec/batch)
2016-12-03 02:04:11.399784: step 11470, loss = 0.47, accu = 0.99, validation: 0.73 (371.0 examples/sec; 0.345 sec/batch)
2016-12-03 02:04:15.029574: step 11480, loss = 0.46, accu = 0.99, validation: 0.75 (365.6 examples/sec; 0.350 sec/batch)
2016-12-03 02:04:18.626936: step 11490, loss = 0.52, accu = 0.97, validation: 0.62 (295.2 examples/sec; 0.434 sec/batch)
2016-12-03 02:04:22.124103: step 11500, loss = 0.50, accu = 0.97, validation: 0.66 (354.8 examples/sec; 0.361 sec/batch)
2016-12-03 02:04:26.145085: step 11510, loss = 0.51, accu = 0.98, validation: 0.73 (275.5 examples/sec; 0.465 sec/batch)
2016-12-03 02:04:29.782509: step 11520, loss = 0.45, accu = 1.00, validation: 0.69 (258.9 examples/sec; 0.494 sec/batch)
2016-12-03 02:04:33.333569: step 11530, loss = 0.48, accu = 0.98, validation: 0.70 (362.0 examples/sec; 0.354 sec/batch)
2016-12-03 02:04:37.113959: step 11540, loss = 0.48, accu = 0.98, validation: 0.67 (353.6 examples/sec; 0.362 sec/batch)
2016-12-03 02:04:40.717953: step 11550, loss = 0.48, accu = 0.98, validation: 0.73 (361.8 examples/sec; 0.354 sec/batch)
2016-12-03 02:04:44.240724: step 11560, loss = 0.48, accu = 0.98, validation: 0.70 (381.9 examples/sec; 0.335 sec/batch)
2016-12-03 02:04:47.836787: step 11570, loss = 0.48, accu = 0.97, validation: 0.70 (355.6 examples/sec; 0.360 sec/batch)
2016-12-03 02:04:51.362607: step 11580, loss = 0.50, accu = 0.96, validation: 0.79 (381.6 examples/sec; 0.335 sec/batch)
2016-12-03 02:04:55.165898: step 11590, loss = 0.47, accu = 0.99, validation: 0.74 (333.1 examples/sec; 0.384 sec/batch)
2016-12-03 02:04:58.674258: step 11600, loss = 0.51, accu = 0.97, validation: 0.68 (374.3 examples/sec; 0.342 sec/batch)
2016-12-03 02:05:02.743499: step 11610, loss = 0.47, accu = 0.99, validation: 0.70 (371.5 examples/sec; 0.345 sec/batch)
2016-12-03 02:05:06.416690: step 11620, loss = 0.47, accu = 0.99, validation: 0.80 (350.3 examples/sec; 0.365 sec/batch)
2016-12-03 02:05:09.988688: step 11630, loss = 0.49, accu = 0.98, validation: 0.73 (336.5 examples/sec; 0.380 sec/batch)
2016-12-03 02:05:13.566285: step 11640, loss = 0.46, accu = 0.99, validation: 0.68 (378.7 examples/sec; 0.338 sec/batch)
2016-12-03 02:05:17.301972: step 11650, loss = 0.49, accu = 0.98, validation: 0.66 (374.7 examples/sec; 0.342 sec/batch)
2016-12-03 02:05:20.849880: step 11660, loss = 0.46, accu = 0.99, validation: 0.75 (374.4 examples/sec; 0.342 sec/batch)
2016-12-03 02:05:24.412037: step 11670, loss = 0.46, accu = 1.00, validation: 0.69 (353.2 examples/sec; 0.362 sec/batch)
2016-12-03 02:05:28.136607: step 11680, loss = 0.49, accu = 0.98, validation: 0.75 (363.5 examples/sec; 0.352 sec/batch)
2016-12-03 02:05:31.625633: step 11690, loss = 0.48, accu = 0.98, validation: 0.75 (351.6 examples/sec; 0.364 sec/batch)
2016-12-03 02:05:35.108155: step 11700, loss = 0.49, accu = 0.98, validation: 0.66 (369.5 examples/sec; 0.346 sec/batch)
2016-12-03 02:05:39.158293: step 11710, loss = 0.48, accu = 0.98, validation: 0.65 (365.1 examples/sec; 0.351 sec/batch)
2016-12-03 02:05:42.604373: step 11720, loss = 0.50, accu = 0.98, validation: 0.71 (376.0 examples/sec; 0.340 sec/batch)
2016-12-03 02:05:46.190221: step 11730, loss = 0.51, accu = 0.98, validation: 0.80 (371.8 examples/sec; 0.344 sec/batch)
2016-12-03 02:05:49.759816: step 11740, loss = 0.48, accu = 0.98, validation: 0.71 (371.1 examples/sec; 0.345 sec/batch)
2016-12-03 02:05:53.294330: step 11750, loss = 0.48, accu = 0.98, validation: 0.68 (364.5 examples/sec; 0.351 sec/batch)
2016-12-03 02:05:56.884997: step 11760, loss = 0.47, accu = 0.98, validation: 0.64 (374.0 examples/sec; 0.342 sec/batch)
2016-12-03 02:06:00.425403: step 11770, loss = 0.47, accu = 0.98, validation: 0.68 (315.2 examples/sec; 0.406 sec/batch)
2016-12-03 02:06:04.150786: step 11780, loss = 0.48, accu = 1.00, validation: 0.72 (297.8 examples/sec; 0.430 sec/batch)
2016-12-03 02:06:07.786076: step 11790, loss = 0.47, accu = 0.99, validation: 0.82 (355.1 examples/sec; 0.360 sec/batch)
2016-12-03 02:06:11.427390: step 11800, loss = 0.48, accu = 0.98, validation: 0.73 (364.3 examples/sec; 0.351 sec/batch)
2016-12-03 02:06:15.328963: step 11810, loss = 0.49, accu = 0.98, validation: 0.65 (361.4 examples/sec; 0.354 sec/batch)
2016-12-03 02:06:19.010071: step 11820, loss = 0.50, accu = 0.97, validation: 0.70 (357.8 examples/sec; 0.358 sec/batch)
2016-12-03 02:06:22.468518: step 11830, loss = 0.54, accu = 0.96, validation: 0.73 (376.3 examples/sec; 0.340 sec/batch)
2016-12-03 02:06:26.076743: step 11840, loss = 0.47, accu = 0.98, validation: 0.72 (350.5 examples/sec; 0.365 sec/batch)
2016-12-03 02:06:29.664633: step 11850, loss = 0.47, accu = 1.00, validation: 0.68 (361.2 examples/sec; 0.354 sec/batch)
2016-12-03 02:06:33.457139: step 11860, loss = 0.54, accu = 0.96, validation: 0.59 (342.5 examples/sec; 0.374 sec/batch)
2016-12-03 02:06:36.952356: step 11870, loss = 0.49, accu = 0.98, validation: 0.66 (377.2 examples/sec; 0.339 sec/batch)
2016-12-03 02:06:40.672545: step 11880, loss = 0.48, accu = 0.98, validation: 0.73 (346.5 examples/sec; 0.369 sec/batch)
2016-12-03 02:06:44.180692: step 11890, loss = 0.48, accu = 0.99, validation: 0.69 (370.1 examples/sec; 0.346 sec/batch)
2016-12-03 02:06:47.911403: step 11900, loss = 0.48, accu = 0.98, validation: 0.76 (364.6 examples/sec; 0.351 sec/batch)
2016-12-03 02:06:51.763560: step 11910, loss = 0.49, accu = 0.96, validation: 0.78 (339.6 examples/sec; 0.377 sec/batch)
2016-12-03 02:06:55.233233: step 11920, loss = 0.49, accu = 0.97, validation: 0.75 (380.4 examples/sec; 0.337 sec/batch)
2016-12-03 02:06:58.914839: step 11930, loss = 0.47, accu = 0.99, validation: 0.76 (364.8 examples/sec; 0.351 sec/batch)
2016-12-03 02:07:02.426603: step 11940, loss = 0.49, accu = 0.98, validation: 0.73 (383.0 examples/sec; 0.334 sec/batch)
2016-12-03 02:07:06.186836: step 11950, loss = 0.50, accu = 0.98, validation: 0.69 (281.3 examples/sec; 0.455 sec/batch)
2016-12-03 02:07:09.666055: step 11960, loss = 0.47, accu = 0.99, validation: 0.69 (380.1 examples/sec; 0.337 sec/batch)
2016-12-03 02:07:13.272235: step 11970, loss = 0.48, accu = 0.99, validation: 0.65 (381.0 examples/sec; 0.336 sec/batch)
2016-12-03 02:07:16.879530: step 11980, loss = 0.51, accu = 0.97, validation: 0.70 (382.3 examples/sec; 0.335 sec/batch)
2016-12-03 02:07:20.418849: step 11990, loss = 0.45, accu = 1.00, validation: 0.73 (350.5 examples/sec; 0.365 sec/batch)
2016-12-03 02:07:24.012285: step 12000, loss = 0.46, accu = 0.99, validation: 0.72 (378.0 examples/sec; 0.339 sec/batch)
2016-12-03 02:07:28.343356: step 12010, loss = 0.49, accu = 0.99, validation: 0.69 (349.7 examples/sec; 0.366 sec/batch)
2016-12-03 02:07:32.088346: step 12020, loss = 0.49, accu = 0.98, validation: 0.71 (369.3 examples/sec; 0.347 sec/batch)
2016-12-03 02:07:35.628440: step 12030, loss = 0.46, accu = 0.99, validation: 0.65 (366.8 examples/sec; 0.349 sec/batch)
2016-12-03 02:07:39.278109: step 12040, loss = 0.48, accu = 0.98, validation: 0.73 (365.1 examples/sec; 0.351 sec/batch)
2016-12-03 02:07:43.058336: step 12050, loss = 0.50, accu = 0.98, validation: 0.76 (354.9 examples/sec; 0.361 sec/batch)
2016-12-03 02:07:46.803959: step 12060, loss = 0.47, accu = 0.99, validation: 0.60 (372.3 examples/sec; 0.344 sec/batch)
2016-12-03 02:07:50.488802: step 12070, loss = 0.50, accu = 0.97, validation: 0.68 (360.7 examples/sec; 0.355 sec/batch)
2016-12-03 02:07:54.017731: step 12080, loss = 0.45, accu = 1.00, validation: 0.73 (366.4 examples/sec; 0.349 sec/batch)
2016-12-03 02:07:57.746437: step 12090, loss = 0.49, accu = 0.98, validation: 0.66 (360.3 examples/sec; 0.355 sec/batch)
2016-12-03 02:08:01.551977: step 12100, loss = 0.47, accu = 0.99, validation: 0.69 (292.9 examples/sec; 0.437 sec/batch)
2016-12-03 02:08:05.462184: step 12110, loss = 0.46, accu = 1.00, validation: 0.66 (352.4 examples/sec; 0.363 sec/batch)
2016-12-03 02:08:09.038296: step 12120, loss = 0.50, accu = 0.98, validation: 0.71 (366.2 examples/sec; 0.350 sec/batch)
2016-12-03 02:08:12.596481: step 12130, loss = 0.47, accu = 0.98, validation: 0.73 (340.6 examples/sec; 0.376 sec/batch)
2016-12-03 02:08:16.375410: step 12140, loss = 0.48, accu = 0.98, validation: 0.72 (356.5 examples/sec; 0.359 sec/batch)
2016-12-03 02:08:20.098859: step 12150, loss = 0.46, accu = 0.99, validation: 0.74 (343.5 examples/sec; 0.373 sec/batch)
2016-12-03 02:08:23.761902: step 12160, loss = 0.51, accu = 0.95, validation: 0.68 (370.9 examples/sec; 0.345 sec/batch)
2016-12-03 02:08:27.476207: step 12170, loss = 0.46, accu = 1.00, validation: 0.66 (363.5 examples/sec; 0.352 sec/batch)
2016-12-03 02:08:31.185493: step 12180, loss = 0.49, accu = 0.97, validation: 0.73 (369.5 examples/sec; 0.346 sec/batch)
2016-12-03 02:08:34.831284: step 12190, loss = 0.47, accu = 1.00, validation: 0.77 (359.8 examples/sec; 0.356 sec/batch)
2016-12-03 02:08:38.455279: step 12200, loss = 0.48, accu = 0.98, validation: 0.69 (372.0 examples/sec; 0.344 sec/batch)
2016-12-03 02:08:42.377716: step 12210, loss = 0.51, accu = 0.98, validation: 0.75 (360.2 examples/sec; 0.355 sec/batch)
2016-12-03 02:08:46.073914: step 12220, loss = 0.48, accu = 0.99, validation: 0.65 (369.1 examples/sec; 0.347 sec/batch)
2016-12-03 02:08:49.751318: step 12230, loss = 0.47, accu = 0.99, validation: 0.69 (366.5 examples/sec; 0.349 sec/batch)
2016-12-03 02:08:53.480534: step 12240, loss = 0.50, accu = 0.98, validation: 0.74 (375.3 examples/sec; 0.341 sec/batch)
2016-12-03 02:08:57.153164: step 12250, loss = 0.48, accu = 0.99, validation: 0.72 (270.2 examples/sec; 0.474 sec/batch)
2016-12-03 02:09:00.782327: step 12260, loss = 0.47, accu = 0.98, validation: 0.76 (368.2 examples/sec; 0.348 sec/batch)
2016-12-03 02:09:04.326664: step 12270, loss = 0.46, accu = 1.00, validation: 0.66 (377.7 examples/sec; 0.339 sec/batch)
2016-12-03 02:09:07.980829: step 12280, loss = 0.46, accu = 0.99, validation: 0.70 (366.0 examples/sec; 0.350 sec/batch)
2016-12-03 02:09:11.629809: step 12290, loss = 0.49, accu = 0.97, validation: 0.67 (367.6 examples/sec; 0.348 sec/batch)
2016-12-03 02:09:15.166554: step 12300, loss = 0.52, accu = 0.97, validation: 0.76 (372.0 examples/sec; 0.344 sec/batch)
2016-12-03 02:09:19.163358: step 12310, loss = 0.49, accu = 0.98, validation: 0.69 (286.8 examples/sec; 0.446 sec/batch)
2016-12-03 02:09:22.808093: step 12320, loss = 0.48, accu = 0.98, validation: 0.70 (379.3 examples/sec; 0.337 sec/batch)
2016-12-03 02:09:26.352639: step 12330, loss = 0.47, accu = 1.00, validation: 0.66 (298.2 examples/sec; 0.429 sec/batch)
2016-12-03 02:09:29.941104: step 12340, loss = 0.47, accu = 0.98, validation: 0.68 (283.6 examples/sec; 0.451 sec/batch)
2016-12-03 02:09:33.561389: step 12350, loss = 0.46, accu = 1.00, validation: 0.73 (370.8 examples/sec; 0.345 sec/batch)
2016-12-03 02:09:37.057993: step 12360, loss = 0.48, accu = 0.98, validation: 0.76 (374.7 examples/sec; 0.342 sec/batch)
2016-12-03 02:09:40.737429: step 12370, loss = 0.45, accu = 1.00, validation: 0.70 (368.0 examples/sec; 0.348 sec/batch)
2016-12-03 02:09:44.283839: step 12380, loss = 0.48, accu = 0.98, validation: 0.71 (373.6 examples/sec; 0.343 sec/batch)
2016-12-03 02:09:48.040111: step 12390, loss = 0.46, accu = 0.98, validation: 0.68 (375.3 examples/sec; 0.341 sec/batch)
2016-12-03 02:09:51.600494: step 12400, loss = 0.47, accu = 0.98, validation: 0.77 (349.7 examples/sec; 0.366 sec/batch)
2016-12-03 02:09:55.388761: step 12410, loss = 0.46, accu = 0.98, validation: 0.70 (350.4 examples/sec; 0.365 sec/batch)
2016-12-03 02:09:59.020871: step 12420, loss = 0.46, accu = 1.00, validation: 0.68 (353.7 examples/sec; 0.362 sec/batch)
2016-12-03 02:10:02.627111: step 12430, loss = 0.47, accu = 1.00, validation: 0.64 (371.6 examples/sec; 0.344 sec/batch)
2016-12-03 02:10:06.186146: step 12440, loss = 0.46, accu = 1.00, validation: 0.70 (373.5 examples/sec; 0.343 sec/batch)
2016-12-03 02:10:09.790391: step 12450, loss = 0.49, accu = 0.98, validation: 0.72 (375.5 examples/sec; 0.341 sec/batch)
2016-12-03 02:10:13.327574: step 12460, loss = 0.47, accu = 0.98, validation: 0.73 (366.9 examples/sec; 0.349 sec/batch)
2016-12-03 02:10:16.996580: step 12470, loss = 0.48, accu = 0.98, validation: 0.72 (373.0 examples/sec; 0.343 sec/batch)
2016-12-03 02:10:20.584568: step 12480, loss = 0.50, accu = 0.98, validation: 0.68 (385.1 examples/sec; 0.332 sec/batch)
2016-12-03 02:10:24.222718: step 12490, loss = 0.47, accu = 0.99, validation: 0.68 (374.7 examples/sec; 0.342 sec/batch)
2016-12-03 02:10:27.822514: step 12500, loss = 0.47, accu = 0.99, validation: 0.77 (352.1 examples/sec; 0.364 sec/batch)
2016-12-03 02:10:31.732402: step 12510, loss = 0.54, accu = 0.96, validation: 0.72 (365.6 examples/sec; 0.350 sec/batch)
2016-12-03 02:10:35.245778: step 12520, loss = 0.50, accu = 0.97, validation: 0.68 (385.9 examples/sec; 0.332 sec/batch)
2016-12-03 02:10:38.887509: step 12530, loss = 0.50, accu = 0.98, validation: 0.66 (349.8 examples/sec; 0.366 sec/batch)
2016-12-03 02:10:42.582526: step 12540, loss = 0.50, accu = 0.98, validation: 0.69 (277.8 examples/sec; 0.461 sec/batch)
2016-12-03 02:10:46.199908: step 12550, loss = 0.54, accu = 0.96, validation: 0.70 (374.0 examples/sec; 0.342 sec/batch)
2016-12-03 02:10:49.789009: step 12560, loss = 0.46, accu = 0.99, validation: 0.74 (373.2 examples/sec; 0.343 sec/batch)
2016-12-03 02:10:53.364520: step 12570, loss = 0.46, accu = 1.00, validation: 0.66 (363.8 examples/sec; 0.352 sec/batch)
2016-12-03 02:10:56.917540: step 12580, loss = 0.48, accu = 0.99, validation: 0.72 (385.6 examples/sec; 0.332 sec/batch)
2016-12-03 02:11:00.538762: step 12590, loss = 0.46, accu = 0.99, validation: 0.70 (346.0 examples/sec; 0.370 sec/batch)
2016-12-03 02:11:04.132881: step 12600, loss = 0.47, accu = 0.99, validation: 0.69 (302.5 examples/sec; 0.423 sec/batch)
2016-12-03 02:11:07.865228: step 12610, loss = 0.46, accu = 1.00, validation: 0.78 (366.7 examples/sec; 0.349 sec/batch)
2016-12-03 02:11:11.527810: step 12620, loss = 0.47, accu = 1.00, validation: 0.67 (371.8 examples/sec; 0.344 sec/batch)
2016-12-03 02:11:15.161251: step 12630, loss = 0.48, accu = 0.99, validation: 0.65 (360.4 examples/sec; 0.355 sec/batch)
2016-12-03 02:11:18.715250: step 12640, loss = 0.45, accu = 1.00, validation: 0.72 (382.5 examples/sec; 0.335 sec/batch)
2016-12-03 02:11:22.326291: step 12650, loss = 0.46, accu = 0.99, validation: 0.77 (378.7 examples/sec; 0.338 sec/batch)
2016-12-03 02:11:26.029671: step 12660, loss = 0.48, accu = 0.98, validation: 0.70 (330.6 examples/sec; 0.387 sec/batch)
2016-12-03 02:11:29.593290: step 12670, loss = 0.46, accu = 1.00, validation: 0.70 (336.9 examples/sec; 0.380 sec/batch)
2016-12-03 02:11:33.151046: step 12680, loss = 0.49, accu = 0.96, validation: 0.70 (374.1 examples/sec; 0.342 sec/batch)
2016-12-03 02:11:36.791477: step 12690, loss = 0.45, accu = 1.00, validation: 0.74 (382.0 examples/sec; 0.335 sec/batch)
2016-12-03 02:11:40.336279: step 12700, loss = 0.50, accu = 0.97, validation: 0.69 (374.6 examples/sec; 0.342 sec/batch)
2016-12-03 02:11:44.237792: step 12710, loss = 0.46, accu = 0.98, validation: 0.74 (359.7 examples/sec; 0.356 sec/batch)
2016-12-03 02:11:47.831290: step 12720, loss = 0.48, accu = 0.99, validation: 0.73 (383.1 examples/sec; 0.334 sec/batch)
2016-12-03 02:11:51.505330: step 12730, loss = 0.47, accu = 1.00, validation: 0.70 (316.7 examples/sec; 0.404 sec/batch)
2016-12-03 02:11:54.953604: step 12740, loss = 0.49, accu = 0.99, validation: 0.67 (386.0 examples/sec; 0.332 sec/batch)
2016-12-03 02:11:58.609573: step 12750, loss = 0.47, accu = 0.99, validation: 0.70 (306.7 examples/sec; 0.417 sec/batch)
2016-12-03 02:12:02.208233: step 12760, loss = 0.48, accu = 0.97, validation: 0.80 (372.5 examples/sec; 0.344 sec/batch)
2016-12-03 02:12:05.825554: step 12770, loss = 0.47, accu = 0.99, validation: 0.71 (368.6 examples/sec; 0.347 sec/batch)
2016-12-03 02:12:09.395916: step 12780, loss = 0.48, accu = 0.98, validation: 0.69 (374.3 examples/sec; 0.342 sec/batch)
2016-12-03 02:12:12.976220: step 12790, loss = 0.46, accu = 1.00, validation: 0.70 (375.7 examples/sec; 0.341 sec/batch)
2016-12-03 02:12:16.556958: step 12800, loss = 0.49, accu = 0.98, validation: 0.71 (373.9 examples/sec; 0.342 sec/batch)
2016-12-03 02:12:20.414989: step 12810, loss = 0.48, accu = 0.98, validation: 0.73 (366.9 examples/sec; 0.349 sec/batch)
2016-12-03 02:12:24.029697: step 12820, loss = 0.48, accu = 0.98, validation: 0.77 (361.4 examples/sec; 0.354 sec/batch)
2016-12-03 02:12:27.666350: step 12830, loss = 0.47, accu = 0.98, validation: 0.74 (372.1 examples/sec; 0.344 sec/batch)
2016-12-03 02:12:31.301171: step 12840, loss = 0.46, accu = 0.98, validation: 0.70 (373.8 examples/sec; 0.342 sec/batch)
2016-12-03 02:12:34.847496: step 12850, loss = 0.45, accu = 1.00, validation: 0.66 (359.2 examples/sec; 0.356 sec/batch)
2016-12-03 02:12:38.374779: step 12860, loss = 0.48, accu = 0.98, validation: 0.75 (367.6 examples/sec; 0.348 sec/batch)
2016-12-03 02:12:42.037078: step 12870, loss = 0.48, accu = 0.98, validation: 0.72 (355.6 examples/sec; 0.360 sec/batch)
2016-12-03 02:12:45.720199: step 12880, loss = 0.50, accu = 0.96, validation: 0.71 (300.7 examples/sec; 0.426 sec/batch)
2016-12-03 02:12:49.292717: step 12890, loss = 0.48, accu = 0.97, validation: 0.62 (382.4 examples/sec; 0.335 sec/batch)
2016-12-03 02:12:52.936861: step 12900, loss = 0.46, accu = 0.99, validation: 0.70 (369.9 examples/sec; 0.346 sec/batch)
2016-12-03 02:12:56.907304: step 12910, loss = 0.47, accu = 0.99, validation: 0.69 (341.8 examples/sec; 0.375 sec/batch)
2016-12-03 02:13:00.500533: step 12920, loss = 0.48, accu = 0.98, validation: 0.71 (365.2 examples/sec; 0.350 sec/batch)
2016-12-03 02:13:04.158608: step 12930, loss = 0.45, accu = 1.00, validation: 0.75 (361.9 examples/sec; 0.354 sec/batch)
2016-12-03 02:13:07.711267: step 12940, loss = 0.47, accu = 0.99, validation: 0.72 (381.7 examples/sec; 0.335 sec/batch)
2016-12-03 02:13:11.255738: step 12950, loss = 0.49, accu = 0.96, validation: 0.73 (384.4 examples/sec; 0.333 sec/batch)
2016-12-03 02:13:14.866884: step 12960, loss = 0.46, accu = 0.98, validation: 0.73 (376.5 examples/sec; 0.340 sec/batch)
2016-12-03 02:13:18.466554: step 12970, loss = 0.44, accu = 1.00, validation: 0.77 (306.2 examples/sec; 0.418 sec/batch)
2016-12-03 02:13:22.112236: step 12980, loss = 0.46, accu = 1.00, validation: 0.66 (306.4 examples/sec; 0.418 sec/batch)
2016-12-03 02:13:25.751339: step 12990, loss = 0.45, accu = 1.00, validation: 0.65 (339.6 examples/sec; 0.377 sec/batch)
2016-12-03 02:13:29.374022: step 13000, loss = 0.46, accu = 0.99, validation: 0.66 (348.6 examples/sec; 0.367 sec/batch)
2016-12-03 02:13:33.734829: step 13010, loss = 0.49, accu = 0.98, validation: 0.69 (367.4 examples/sec; 0.348 sec/batch)
2016-12-03 02:13:37.473873: step 13020, loss = 0.48, accu = 0.98, validation: 0.71 (337.2 examples/sec; 0.380 sec/batch)
2016-12-03 02:13:40.999154: step 13030, loss = 0.46, accu = 1.00, validation: 0.70 (372.5 examples/sec; 0.344 sec/batch)
2016-12-03 02:13:44.720336: step 13040, loss = 0.49, accu = 0.98, validation: 0.70 (370.1 examples/sec; 0.346 sec/batch)
2016-12-03 02:13:48.475516: step 13050, loss = 0.46, accu = 0.99, validation: 0.73 (364.6 examples/sec; 0.351 sec/batch)
2016-12-03 02:13:52.074134: step 13060, loss = 0.47, accu = 0.99, validation: 0.66 (312.2 examples/sec; 0.410 sec/batch)
2016-12-03 02:13:55.822905: step 13070, loss = 0.49, accu = 0.98, validation: 0.74 (317.0 examples/sec; 0.404 sec/batch)
2016-12-03 02:13:59.442148: step 13080, loss = 0.46, accu = 0.99, validation: 0.77 (361.3 examples/sec; 0.354 sec/batch)
2016-12-03 02:14:03.190332: step 13090, loss = 0.49, accu = 0.98, validation: 0.64 (283.0 examples/sec; 0.452 sec/batch)
2016-12-03 02:14:06.792981: step 13100, loss = 0.51, accu = 0.97, validation: 0.68 (365.2 examples/sec; 0.351 sec/batch)
2016-12-03 02:14:10.732984: step 13110, loss = 0.47, accu = 0.99, validation: 0.72 (368.6 examples/sec; 0.347 sec/batch)
2016-12-03 02:14:14.254526: step 13120, loss = 0.48, accu = 0.98, validation: 0.73 (380.5 examples/sec; 0.336 sec/batch)
2016-12-03 02:14:17.985901: step 13130, loss = 0.49, accu = 0.98, validation: 0.70 (363.8 examples/sec; 0.352 sec/batch)
2016-12-03 02:14:21.675954: step 13140, loss = 0.51, accu = 0.96, validation: 0.69 (339.8 examples/sec; 0.377 sec/batch)
2016-12-03 02:14:25.195322: step 13150, loss = 0.48, accu = 0.98, validation: 0.69 (361.3 examples/sec; 0.354 sec/batch)
2016-12-03 02:14:28.878127: step 13160, loss = 0.51, accu = 0.96, validation: 0.77 (370.4 examples/sec; 0.346 sec/batch)
2016-12-03 02:14:32.578465: step 13170, loss = 0.49, accu = 0.98, validation: 0.70 (363.0 examples/sec; 0.353 sec/batch)
2016-12-03 02:14:36.175181: step 13180, loss = 0.50, accu = 0.98, validation: 0.73 (301.7 examples/sec; 0.424 sec/batch)
2016-12-03 02:14:39.870228: step 13190, loss = 0.46, accu = 0.98, validation: 0.67 (356.1 examples/sec; 0.359 sec/batch)
2016-12-03 02:14:43.550938: step 13200, loss = 0.48, accu = 0.98, validation: 0.65 (370.2 examples/sec; 0.346 sec/batch)
2016-12-03 02:14:47.594035: step 13210, loss = 0.46, accu = 0.99, validation: 0.71 (272.5 examples/sec; 0.470 sec/batch)
2016-12-03 02:14:51.149358: step 13220, loss = 0.51, accu = 0.98, validation: 0.77 (382.8 examples/sec; 0.334 sec/batch)
2016-12-03 02:14:55.018704: step 13230, loss = 0.45, accu = 1.00, validation: 0.67 (358.6 examples/sec; 0.357 sec/batch)
2016-12-03 02:14:58.720195: step 13240, loss = 0.47, accu = 0.99, validation: 0.73 (374.9 examples/sec; 0.341 sec/batch)
2016-12-03 02:15:02.320133: step 13250, loss = 0.47, accu = 0.98, validation: 0.65 (358.4 examples/sec; 0.357 sec/batch)
2016-12-03 02:15:06.070823: step 13260, loss = 0.46, accu = 0.99, validation: 0.71 (328.9 examples/sec; 0.389 sec/batch)
2016-12-03 02:15:09.675947: step 13270, loss = 0.52, accu = 0.97, validation: 0.69 (374.2 examples/sec; 0.342 sec/batch)
2016-12-03 02:15:13.452320: step 13280, loss = 0.47, accu = 0.99, validation: 0.80 (360.2 examples/sec; 0.355 sec/batch)
2016-12-03 02:15:16.910241: step 13290, loss = 0.49, accu = 0.98, validation: 0.76 (376.2 examples/sec; 0.340 sec/batch)
2016-12-03 02:15:20.478200: step 13300, loss = 0.45, accu = 0.99, validation: 0.71 (372.7 examples/sec; 0.343 sec/batch)
2016-12-03 02:15:24.526821: step 13310, loss = 0.44, accu = 1.00, validation: 0.67 (329.0 examples/sec; 0.389 sec/batch)
2016-12-03 02:15:28.028779: step 13320, loss = 0.48, accu = 0.99, validation: 0.66 (378.2 examples/sec; 0.338 sec/batch)
2016-12-03 02:15:31.689377: step 13330, loss = 0.49, accu = 0.98, validation: 0.78 (270.4 examples/sec; 0.473 sec/batch)
2016-12-03 02:15:35.264125: step 13340, loss = 0.46, accu = 1.00, validation: 0.72 (368.4 examples/sec; 0.347 sec/batch)
2016-12-03 02:15:38.916274: step 13350, loss = 0.48, accu = 0.98, validation: 0.63 (377.7 examples/sec; 0.339 sec/batch)
2016-12-03 02:15:42.464157: step 13360, loss = 0.45, accu = 0.99, validation: 0.66 (373.1 examples/sec; 0.343 sec/batch)
2016-12-03 02:15:46.052832: step 13370, loss = 0.48, accu = 0.98, validation: 0.71 (294.6 examples/sec; 0.435 sec/batch)
2016-12-03 02:15:49.700891: step 13380, loss = 0.47, accu = 0.99, validation: 0.72 (344.0 examples/sec; 0.372 sec/batch)
2016-12-03 02:15:53.261503: step 13390, loss = 0.45, accu = 1.00, validation: 0.73 (378.9 examples/sec; 0.338 sec/batch)
2016-12-03 02:15:56.903898: step 13400, loss = 0.46, accu = 1.00, validation: 0.72 (383.9 examples/sec; 0.333 sec/batch)
2016-12-03 02:16:00.864046: step 13410, loss = 0.44, accu = 1.00, validation: 0.71 (334.6 examples/sec; 0.382 sec/batch)
2016-12-03 02:16:04.484602: step 13420, loss = 0.49, accu = 0.99, validation: 0.70 (369.9 examples/sec; 0.346 sec/batch)
2016-12-03 02:16:08.166881: step 13430, loss = 0.50, accu = 0.98, validation: 0.77 (359.3 examples/sec; 0.356 sec/batch)
2016-12-03 02:16:11.664699: step 13440, loss = 0.45, accu = 1.00, validation: 0.72 (340.4 examples/sec; 0.376 sec/batch)
2016-12-03 02:16:15.319992: step 13450, loss = 0.44, accu = 1.00, validation: 0.69 (362.0 examples/sec; 0.354 sec/batch)
2016-12-03 02:16:18.970177: step 13460, loss = 0.47, accu = 0.98, validation: 0.66 (363.4 examples/sec; 0.352 sec/batch)
2016-12-03 02:16:22.514868: step 13470, loss = 0.46, accu = 0.99, validation: 0.69 (382.7 examples/sec; 0.334 sec/batch)
2016-12-03 02:16:26.208436: step 13480, loss = 0.46, accu = 0.98, validation: 0.71 (355.4 examples/sec; 0.360 sec/batch)
2016-12-03 02:16:29.832303: step 13490, loss = 0.47, accu = 0.99, validation: 0.73 (355.6 examples/sec; 0.360 sec/batch)
2016-12-03 02:16:33.415813: step 13500, loss = 0.48, accu = 0.98, validation: 0.72 (368.4 examples/sec; 0.347 sec/batch)
2016-12-03 02:16:37.309435: step 13510, loss = 0.46, accu = 1.00, validation: 0.69 (362.3 examples/sec; 0.353 sec/batch)
2016-12-03 02:16:40.928142: step 13520, loss = 0.48, accu = 0.99, validation: 0.67 (269.5 examples/sec; 0.475 sec/batch)
2016-12-03 02:16:44.552648: step 13530, loss = 0.46, accu = 1.00, validation: 0.74 (370.8 examples/sec; 0.345 sec/batch)
2016-12-03 02:16:48.211280: step 13540, loss = 0.48, accu = 0.99, validation: 0.71 (289.3 examples/sec; 0.442 sec/batch)
2016-12-03 02:16:51.698068: step 13550, loss = 0.49, accu = 0.98, validation: 0.63 (383.6 examples/sec; 0.334 sec/batch)
2016-12-03 02:16:55.369873: step 13560, loss = 0.50, accu = 0.96, validation: 0.68 (375.1 examples/sec; 0.341 sec/batch)
2016-12-03 02:16:59.074983: step 13570, loss = 0.46, accu = 0.98, validation: 0.66 (388.3 examples/sec; 0.330 sec/batch)
2016-12-03 02:17:02.621988: step 13580, loss = 0.47, accu = 0.98, validation: 0.70 (367.6 examples/sec; 0.348 sec/batch)
2016-12-03 02:17:06.244850: step 13590, loss = 0.46, accu = 0.99, validation: 0.73 (356.0 examples/sec; 0.360 sec/batch)
2016-12-03 02:17:10.012862: step 13600, loss = 0.44, accu = 0.99, validation: 0.68 (359.6 examples/sec; 0.356 sec/batch)
2016-12-03 02:17:13.943982: step 13610, loss = 0.48, accu = 0.99, validation: 0.70 (371.7 examples/sec; 0.344 sec/batch)
2016-12-03 02:17:17.618678: step 13620, loss = 0.45, accu = 0.98, validation: 0.70 (363.0 examples/sec; 0.353 sec/batch)
2016-12-03 02:17:21.342212: step 13630, loss = 0.46, accu = 0.99, validation: 0.72 (380.3 examples/sec; 0.337 sec/batch)
2016-12-03 02:17:25.094018: step 13640, loss = 0.53, accu = 0.97, validation: 0.73 (371.2 examples/sec; 0.345 sec/batch)
2016-12-03 02:17:28.812331: step 13650, loss = 0.47, accu = 0.98, validation: 0.74 (369.6 examples/sec; 0.346 sec/batch)
2016-12-03 02:17:32.421601: step 13660, loss = 0.47, accu = 0.99, validation: 0.66 (367.3 examples/sec; 0.348 sec/batch)
2016-12-03 02:17:36.060096: step 13670, loss = 0.46, accu = 0.99, validation: 0.72 (372.5 examples/sec; 0.344 sec/batch)
2016-12-03 02:17:39.726838: step 13680, loss = 0.46, accu = 1.00, validation: 0.77 (374.8 examples/sec; 0.341 sec/batch)
2016-12-03 02:17:43.408160: step 13690, loss = 0.45, accu = 1.00, validation: 0.69 (373.2 examples/sec; 0.343 sec/batch)
2016-12-03 02:17:46.883065: step 13700, loss = 0.47, accu = 0.99, validation: 0.70 (375.0 examples/sec; 0.341 sec/batch)
2016-12-03 02:17:50.646764: step 13710, loss = 0.46, accu = 0.99, validation: 0.69 (366.3 examples/sec; 0.349 sec/batch)
2016-12-03 02:17:54.293749: step 13720, loss = 0.51, accu = 0.97, validation: 0.71 (362.9 examples/sec; 0.353 sec/batch)
2016-12-03 02:17:58.108809: step 13730, loss = 0.46, accu = 0.99, validation: 0.73 (346.7 examples/sec; 0.369 sec/batch)
2016-12-03 02:18:01.578423: step 13740, loss = 0.45, accu = 1.00, validation: 0.70 (357.3 examples/sec; 0.358 sec/batch)
2016-12-03 02:18:05.198492: step 13750, loss = 0.46, accu = 1.00, validation: 0.75 (367.7 examples/sec; 0.348 sec/batch)
2016-12-03 02:18:08.851871: step 13760, loss = 0.48, accu = 0.97, validation: 0.72 (370.9 examples/sec; 0.345 sec/batch)
2016-12-03 02:18:12.537908: step 13770, loss = 0.46, accu = 0.99, validation: 0.70 (378.2 examples/sec; 0.338 sec/batch)
2016-12-03 02:18:16.138521: step 13780, loss = 0.48, accu = 0.98, validation: 0.74 (331.7 examples/sec; 0.386 sec/batch)
2016-12-03 02:18:19.752405: step 13790, loss = 0.48, accu = 0.99, validation: 0.77 (369.8 examples/sec; 0.346 sec/batch)
2016-12-03 02:18:23.516140: step 13800, loss = 0.50, accu = 0.96, validation: 0.69 (385.9 examples/sec; 0.332 sec/batch)
2016-12-03 02:18:27.379094: step 13810, loss = 0.45, accu = 1.00, validation: 0.69 (358.4 examples/sec; 0.357 sec/batch)
2016-12-03 02:18:31.157882: step 13820, loss = 0.50, accu = 0.96, validation: 0.66 (333.7 examples/sec; 0.384 sec/batch)
2016-12-03 02:18:34.761664: step 13830, loss = 0.50, accu = 0.97, validation: 0.70 (366.3 examples/sec; 0.349 sec/batch)
2016-12-03 02:18:38.368682: step 13840, loss = 0.46, accu = 0.98, validation: 0.71 (372.2 examples/sec; 0.344 sec/batch)
2016-12-03 02:18:41.909260: step 13850, loss = 0.47, accu = 0.99, validation: 0.71 (370.9 examples/sec; 0.345 sec/batch)
2016-12-03 02:18:45.521853: step 13860, loss = 0.45, accu = 0.99, validation: 0.75 (371.2 examples/sec; 0.345 sec/batch)
2016-12-03 02:18:49.089138: step 13870, loss = 0.48, accu = 0.98, validation: 0.69 (363.5 examples/sec; 0.352 sec/batch)
2016-12-03 02:18:52.766231: step 13880, loss = 0.48, accu = 0.98, validation: 0.69 (366.0 examples/sec; 0.350 sec/batch)
2016-12-03 02:18:56.376503: step 13890, loss = 0.48, accu = 0.98, validation: 0.70 (364.7 examples/sec; 0.351 sec/batch)
2016-12-03 02:19:00.075179: step 13900, loss = 0.44, accu = 1.00, validation: 0.66 (346.2 examples/sec; 0.370 sec/batch)
2016-12-03 02:19:04.018788: step 13910, loss = 0.45, accu = 1.00, validation: 0.64 (332.7 examples/sec; 0.385 sec/batch)
2016-12-03 02:19:07.651078: step 13920, loss = 0.47, accu = 0.98, validation: 0.63 (330.9 examples/sec; 0.387 sec/batch)
2016-12-03 02:19:11.238740: step 13930, loss = 0.47, accu = 0.98, validation: 0.68 (376.9 examples/sec; 0.340 sec/batch)
2016-12-03 02:19:14.820833: step 13940, loss = 0.46, accu = 0.99, validation: 0.70 (371.8 examples/sec; 0.344 sec/batch)
2016-12-03 02:19:18.393835: step 13950, loss = 0.46, accu = 0.99, validation: 0.70 (368.0 examples/sec; 0.348 sec/batch)
2016-12-03 02:19:22.053819: step 13960, loss = 0.48, accu = 0.97, validation: 0.77 (346.5 examples/sec; 0.369 sec/batch)
2016-12-03 02:19:25.704353: step 13970, loss = 0.48, accu = 0.98, validation: 0.76 (318.4 examples/sec; 0.402 sec/batch)
2016-12-03 02:19:29.402782: step 13980, loss = 0.45, accu = 0.98, validation: 0.69 (370.2 examples/sec; 0.346 sec/batch)
2016-12-03 02:19:33.040565: step 13990, loss = 0.47, accu = 0.98, validation: 0.73 (374.6 examples/sec; 0.342 sec/batch)

