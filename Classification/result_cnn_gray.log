2016-12-03 02:25:48.416510: step 0, loss = 13.96, accu = 0.27, validation: 0.30 (10.4 examples/sec; 12.310 sec/batch)
2016-12-03 02:25:51.252811: step 10, loss = 13.81, accu = 0.39, validation: 0.38 (601.3 examples/sec; 0.213 sec/batch)
2016-12-03 02:25:53.341167: step 20, loss = 13.64, accu = 0.48, validation: 0.41 (634.4 examples/sec; 0.202 sec/batch)
2016-12-03 02:25:55.335126: step 30, loss = 13.54, accu = 0.41, validation: 0.46 (611.6 examples/sec; 0.209 sec/batch)
2016-12-03 02:25:57.484776: step 40, loss = 13.41, accu = 0.47, validation: 0.52 (611.2 examples/sec; 0.209 sec/batch)
2016-12-03 02:25:59.589091: step 50, loss = 13.19, accu = 0.51, validation: 0.48 (606.4 examples/sec; 0.211 sec/batch)
2016-12-03 02:26:01.697850: step 60, loss = 13.28, accu = 0.41, validation: 0.45 (602.9 examples/sec; 0.212 sec/batch)
2016-12-03 02:26:03.841038: step 70, loss = 12.92, accu = 0.61, validation: 0.60 (618.0 examples/sec; 0.207 sec/batch)
2016-12-03 02:26:05.971560: step 80, loss = 12.87, accu = 0.52, validation: 0.46 (572.6 examples/sec; 0.224 sec/batch)
2016-12-03 02:26:08.079276: step 90, loss = 12.79, accu = 0.54, validation: 0.59 (601.1 examples/sec; 0.213 sec/batch)
2016-12-03 02:26:10.224770: step 100, loss = 12.75, accu = 0.50, validation: 0.63 (583.5 examples/sec; 0.219 sec/batch)
2016-12-03 02:26:12.437771: step 110, loss = 12.67, accu = 0.45, validation: 0.55 (590.5 examples/sec; 0.217 sec/batch)
2016-12-03 02:26:14.558475: step 120, loss = 12.54, accu = 0.54, validation: 0.49 (631.6 examples/sec; 0.203 sec/batch)
2016-12-03 02:26:16.698095: step 130, loss = 12.39, accu = 0.53, validation: 0.55 (587.0 examples/sec; 0.218 sec/batch)
2016-12-03 02:26:18.838244: step 140, loss = 12.25, accu = 0.60, validation: 0.55 (547.3 examples/sec; 0.234 sec/batch)
2016-12-03 02:26:21.071591: step 150, loss = 12.10, accu = 0.63, validation: 0.59 (593.1 examples/sec; 0.216 sec/batch)
2016-12-03 02:26:23.262948: step 160, loss = 12.11, accu = 0.55, validation: 0.57 (588.0 examples/sec; 0.218 sec/batch)
2016-12-03 02:26:25.424704: step 170, loss = 12.05, accu = 0.55, validation: 0.52 (614.4 examples/sec; 0.208 sec/batch)
2016-12-03 02:26:27.571705: step 180, loss = 11.84, accu = 0.61, validation: 0.60 (617.7 examples/sec; 0.207 sec/batch)
2016-12-03 02:26:29.783811: step 190, loss = 11.91, accu = 0.56, validation: 0.56 (580.7 examples/sec; 0.220 sec/batch)
2016-12-03 02:26:31.861371: step 200, loss = 11.81, accu = 0.52, validation: 0.57 (603.6 examples/sec; 0.212 sec/batch)
2016-12-03 02:26:34.330448: step 210, loss = 11.65, accu = 0.56, validation: 0.60 (591.7 examples/sec; 0.216 sec/batch)
2016-12-03 02:26:36.499579: step 220, loss = 11.51, accu = 0.59, validation: 0.52 (638.0 examples/sec; 0.201 sec/batch)
2016-12-03 02:26:38.648837: step 230, loss = 11.47, accu = 0.56, validation: 0.53 (575.4 examples/sec; 0.222 sec/batch)
2016-12-03 02:26:40.835752: step 240, loss = 11.42, accu = 0.56, validation: 0.55 (563.9 examples/sec; 0.227 sec/batch)
2016-12-03 02:26:43.027366: step 250, loss = 11.28, accu = 0.63, validation: 0.59 (600.2 examples/sec; 0.213 sec/batch)
2016-12-03 02:26:45.212842: step 260, loss = 11.23, accu = 0.58, validation: 0.62 (581.1 examples/sec; 0.220 sec/batch)
2016-12-03 02:26:47.389264: step 270, loss = 11.25, accu = 0.52, validation: 0.52 (564.1 examples/sec; 0.227 sec/batch)
2016-12-03 02:26:49.531694: step 280, loss = 11.08, accu = 0.62, validation: 0.53 (610.9 examples/sec; 0.210 sec/batch)
2016-12-03 02:26:51.680218: step 290, loss = 10.93, accu = 0.59, validation: 0.60 (609.2 examples/sec; 0.210 sec/batch)
2016-12-03 02:26:53.848217: step 300, loss = 10.90, accu = 0.62, validation: 0.59 (590.3 examples/sec; 0.217 sec/batch)
2016-12-03 02:26:56.097430: step 310, loss = 10.87, accu = 0.55, validation: 0.55 (618.0 examples/sec; 0.207 sec/batch)
2016-12-03 02:26:58.280127: step 320, loss = 10.75, accu = 0.60, validation: 0.57 (582.8 examples/sec; 0.220 sec/batch)
2016-12-03 02:27:00.525114: step 330, loss = 10.57, accu = 0.62, validation: 0.55 (615.0 examples/sec; 0.208 sec/batch)
2016-12-03 02:27:02.704107: step 340, loss = 10.75, accu = 0.52, validation: 0.55 (564.9 examples/sec; 0.227 sec/batch)
2016-12-03 02:27:04.878911: step 350, loss = 10.43, accu = 0.68, validation: 0.62 (634.6 examples/sec; 0.202 sec/batch)
2016-12-03 02:27:07.100098: step 360, loss = 10.41, accu = 0.61, validation: 0.57 (581.6 examples/sec; 0.220 sec/batch)
2016-12-03 02:27:09.273729: step 370, loss = 10.22, accu = 0.65, validation: 0.56 (588.9 examples/sec; 0.217 sec/batch)
2016-12-03 02:27:11.452280: step 380, loss = 10.30, accu = 0.57, validation: 0.55 (599.3 examples/sec; 0.214 sec/batch)
2016-12-03 02:27:13.597123: step 390, loss = 10.26, accu = 0.55, validation: 0.55 (565.3 examples/sec; 0.226 sec/batch)
2016-12-03 02:27:15.701113: step 400, loss = 10.14, accu = 0.53, validation: 0.59 (597.3 examples/sec; 0.214 sec/batch)
2016-12-03 02:27:18.026720: step 410, loss = 10.03, accu = 0.71, validation: 0.59 (626.7 examples/sec; 0.204 sec/batch)
2016-12-03 02:27:20.189472: step 420, loss = 10.03, accu = 0.61, validation: 0.59 (568.6 examples/sec; 0.225 sec/batch)
2016-12-03 02:27:22.365628: step 430, loss = 10.08, accu = 0.55, validation: 0.55 (572.5 examples/sec; 0.224 sec/batch)
2016-12-03 02:27:24.530696: step 440, loss = 9.85, accu = 0.59, validation: 0.62 (562.4 examples/sec; 0.228 sec/batch)
2016-12-03 02:27:26.684960: step 450, loss = 9.81, accu = 0.63, validation: 0.59 (616.6 examples/sec; 0.208 sec/batch)
2016-12-03 02:27:28.831858: step 460, loss = 9.80, accu = 0.58, validation: 0.56 (612.4 examples/sec; 0.209 sec/batch)
2016-12-03 02:27:30.980002: step 470, loss = 9.56, accu = 0.66, validation: 0.60 (592.0 examples/sec; 0.216 sec/batch)
2016-12-03 02:27:33.109231: step 480, loss = 9.50, accu = 0.62, validation: 0.59 (619.3 examples/sec; 0.207 sec/batch)
2016-12-03 02:27:35.258072: step 490, loss = 9.50, accu = 0.56, validation: 0.58 (582.3 examples/sec; 0.220 sec/batch)
2016-12-03 02:27:37.387297: step 500, loss = 9.36, accu = 0.59, validation: 0.55 (604.1 examples/sec; 0.212 sec/batch)
2016-12-03 02:27:39.779492: step 510, loss = 9.42, accu = 0.60, validation: 0.57 (606.1 examples/sec; 0.211 sec/batch)
2016-12-03 02:27:41.927044: step 520, loss = 9.25, accu = 0.60, validation: 0.61 (610.5 examples/sec; 0.210 sec/batch)
2016-12-03 02:27:44.078252: step 530, loss = 9.23, accu = 0.59, validation: 0.53 (588.2 examples/sec; 0.218 sec/batch)
2016-12-03 02:27:46.169217: step 540, loss = 9.16, accu = 0.58, validation: 0.53 (641.8 examples/sec; 0.199 sec/batch)
2016-12-03 02:27:48.402829: step 550, loss = 9.32, accu = 0.51, validation: 0.55 (563.7 examples/sec; 0.227 sec/batch)
2016-12-03 02:27:50.531879: step 560, loss = 9.00, accu = 0.59, validation: 0.61 (610.2 examples/sec; 0.210 sec/batch)
2016-12-03 02:27:52.664147: step 570, loss = 8.94, accu = 0.61, validation: 0.63 (629.2 examples/sec; 0.203 sec/batch)
2016-12-03 02:27:54.812995: step 580, loss = 8.91, accu = 0.54, validation: 0.59 (562.8 examples/sec; 0.227 sec/batch)
2016-12-03 02:27:56.930255: step 590, loss = 8.74, accu = 0.65, validation: 0.59 (626.6 examples/sec; 0.204 sec/batch)
2016-12-03 02:27:59.060423: step 600, loss = 8.81, accu = 0.55, validation: 0.62 (609.8 examples/sec; 0.210 sec/batch)
2016-12-03 02:28:01.449878: step 610, loss = 8.82, accu = 0.54, validation: 0.63 (603.1 examples/sec; 0.212 sec/batch)
2016-12-03 02:28:03.605988: step 620, loss = 8.66, accu = 0.61, validation: 0.58 (596.5 examples/sec; 0.215 sec/batch)
2016-12-03 02:28:05.746324: step 630, loss = 8.57, accu = 0.63, validation: 0.61 (605.3 examples/sec; 0.211 sec/batch)
2016-12-03 02:28:07.880450: step 640, loss = 8.55, accu = 0.62, validation: 0.66 (582.0 examples/sec; 0.220 sec/batch)
2016-12-03 02:28:09.996437: step 650, loss = 8.41, accu = 0.63, validation: 0.57 (625.0 examples/sec; 0.205 sec/batch)
2016-12-03 02:28:12.136301: step 660, loss = 8.45, accu = 0.57, validation: 0.58 (598.2 examples/sec; 0.214 sec/batch)
2016-12-03 02:28:14.221823: step 670, loss = 8.34, accu = 0.62, validation: 0.66 (693.7 examples/sec; 0.185 sec/batch)
2016-12-03 02:28:16.344824: step 680, loss = 8.30, accu = 0.61, validation: 0.62 (602.5 examples/sec; 0.212 sec/batch)
2016-12-03 02:28:18.511294: step 690, loss = 8.29, accu = 0.57, validation: 0.52 (587.1 examples/sec; 0.218 sec/batch)
2016-12-03 02:28:20.640263: step 700, loss = 8.20, accu = 0.57, validation: 0.60 (614.3 examples/sec; 0.208 sec/batch)
2016-12-03 02:28:22.965757: step 710, loss = 8.01, accu = 0.65, validation: 0.62 (640.5 examples/sec; 0.200 sec/batch)
2016-12-03 02:28:25.118113: step 720, loss = 8.07, accu = 0.59, validation: 0.68 (586.5 examples/sec; 0.218 sec/batch)
2016-12-03 02:28:27.249747: step 730, loss = 8.01, accu = 0.66, validation: 0.59 (593.4 examples/sec; 0.216 sec/batch)
2016-12-03 02:28:29.364245: step 740, loss = 8.09, accu = 0.55, validation: 0.53 (586.5 examples/sec; 0.218 sec/batch)
2016-12-03 02:28:31.500998: step 750, loss = 7.85, accu = 0.70, validation: 0.66 (587.2 examples/sec; 0.218 sec/batch)
2016-12-03 02:28:33.619926: step 760, loss = 7.77, accu = 0.62, validation: 0.62 (597.7 examples/sec; 0.214 sec/batch)
2016-12-03 02:28:35.744720: step 770, loss = 7.78, accu = 0.58, validation: 0.68 (596.5 examples/sec; 0.215 sec/batch)
2016-12-03 02:28:37.885839: step 780, loss = 7.76, accu = 0.56, validation: 0.64 (616.7 examples/sec; 0.208 sec/batch)
2016-12-03 02:28:40.012538: step 790, loss = 7.75, accu = 0.59, validation: 0.61 (578.7 examples/sec; 0.221 sec/batch)
2016-12-03 02:28:42.151284: step 800, loss = 7.55, accu = 0.66, validation: 0.55 (611.8 examples/sec; 0.209 sec/batch)
2016-12-03 02:28:44.428278: step 810, loss = 7.40, accu = 0.66, validation: 0.69 (585.9 examples/sec; 0.218 sec/batch)
2016-12-03 02:28:46.597856: step 820, loss = 7.51, accu = 0.61, validation: 0.61 (582.3 examples/sec; 0.220 sec/batch)
2016-12-03 02:28:48.760807: step 830, loss = 7.52, accu = 0.59, validation: 0.67 (594.1 examples/sec; 0.215 sec/batch)
2016-12-03 02:28:50.892500: step 840, loss = 7.41, accu = 0.59, validation: 0.60 (586.6 examples/sec; 0.218 sec/batch)
2016-12-03 02:28:53.006872: step 850, loss = 7.38, accu = 0.63, validation: 0.59 (590.1 examples/sec; 0.217 sec/batch)
2016-12-03 02:28:55.128300: step 860, loss = 7.31, accu = 0.61, validation: 0.62 (635.7 examples/sec; 0.201 sec/batch)
2016-12-03 02:28:57.244583: step 870, loss = 7.24, accu = 0.64, validation: 0.59 (588.4 examples/sec; 0.218 sec/batch)
2016-12-03 02:28:59.400005: step 880, loss = 7.24, accu = 0.59, validation: 0.62 (576.9 examples/sec; 0.222 sec/batch)
2016-12-03 02:29:01.522679: step 890, loss = 7.12, accu = 0.61, validation: 0.64 (589.6 examples/sec; 0.217 sec/batch)
2016-12-03 02:29:03.665945: step 900, loss = 7.10, accu = 0.62, validation: 0.62 (579.7 examples/sec; 0.221 sec/batch)
2016-12-03 02:29:05.932701: step 910, loss = 6.98, accu = 0.67, validation: 0.66 (590.3 examples/sec; 0.217 sec/batch)
2016-12-03 02:29:08.058357: step 920, loss = 7.02, accu = 0.59, validation: 0.58 (600.0 examples/sec; 0.213 sec/batch)
2016-12-03 02:29:10.185800: step 930, loss = 6.82, accu = 0.68, validation: 0.65 (574.2 examples/sec; 0.223 sec/batch)
2016-12-03 02:29:12.298997: step 940, loss = 6.85, accu = 0.65, validation: 0.67 (641.4 examples/sec; 0.200 sec/batch)
2016-12-03 02:29:14.408027: step 950, loss = 6.73, accu = 0.70, validation: 0.66 (594.0 examples/sec; 0.215 sec/batch)
2016-12-03 02:29:16.554764: step 960, loss = 6.71, accu = 0.67, validation: 0.59 (567.5 examples/sec; 0.226 sec/batch)
2016-12-03 02:29:18.653716: step 970, loss = 6.75, accu = 0.66, validation: 0.68 (578.8 examples/sec; 0.221 sec/batch)
2016-12-03 02:29:20.787960: step 980, loss = 6.72, accu = 0.59, validation: 0.59 (609.0 examples/sec; 0.210 sec/batch)
2016-12-03 02:29:22.910048: step 990, loss = 6.59, accu = 0.66, validation: 0.64 (624.9 examples/sec; 0.205 sec/batch)
2016-12-03 02:29:25.041995: step 1000, loss = 6.56, accu = 0.66, validation: 0.55 (608.2 examples/sec; 0.210 sec/batch)
2016-12-03 02:29:27.850534: step 1010, loss = 6.39, accu = 0.70, validation: 0.58 (596.9 examples/sec; 0.214 sec/batch)
2016-12-03 02:29:29.974048: step 1020, loss = 6.40, accu = 0.69, validation: 0.67 (631.5 examples/sec; 0.203 sec/batch)
2016-12-03 02:29:32.060488: step 1030, loss = 6.41, accu = 0.69, validation: 0.62 (626.8 examples/sec; 0.204 sec/batch)
2016-12-03 02:29:34.202257: step 1040, loss = 6.41, accu = 0.65, validation: 0.59 (604.4 examples/sec; 0.212 sec/batch)
2016-12-03 02:29:36.321388: step 1050, loss = 6.36, accu = 0.63, validation: 0.62 (626.4 examples/sec; 0.204 sec/batch)
2016-12-03 02:29:38.448137: step 1060, loss = 6.40, accu = 0.58, validation: 0.68 (589.0 examples/sec; 0.217 sec/batch)
2016-12-03 02:29:40.562462: step 1070, loss = 6.29, accu = 0.67, validation: 0.60 (596.1 examples/sec; 0.215 sec/batch)
2016-12-03 02:29:42.705824: step 1080, loss = 6.15, accu = 0.70, validation: 0.61 (612.3 examples/sec; 0.209 sec/batch)
2016-12-03 02:29:44.870779: step 1090, loss = 6.15, accu = 0.64, validation: 0.60 (581.7 examples/sec; 0.220 sec/batch)
2016-12-03 02:29:47.022222: step 1100, loss = 6.19, accu = 0.61, validation: 0.66 (580.8 examples/sec; 0.220 sec/batch)
2016-12-03 02:29:49.313394: step 1110, loss = 6.10, accu = 0.61, validation: 0.55 (561.1 examples/sec; 0.228 sec/batch)
2016-12-03 02:29:51.460085: step 1120, loss = 6.04, accu = 0.63, validation: 0.66 (616.5 examples/sec; 0.208 sec/batch)
2016-12-03 02:29:53.595358: step 1130, loss = 5.99, accu = 0.68, validation: 0.66 (588.5 examples/sec; 0.217 sec/batch)
2016-12-03 02:29:55.738924: step 1140, loss = 5.87, accu = 0.67, validation: 0.65 (592.0 examples/sec; 0.216 sec/batch)
2016-12-03 02:29:57.882417: step 1150, loss = 5.87, accu = 0.66, validation: 0.55 (589.6 examples/sec; 0.217 sec/batch)
2016-12-03 02:30:00.007501: step 1160, loss = 5.97, accu = 0.56, validation: 0.59 (601.3 examples/sec; 0.213 sec/batch)
2016-12-03 02:30:02.138261: step 1170, loss = 5.82, accu = 0.69, validation: 0.62 (609.5 examples/sec; 0.210 sec/batch)
2016-12-03 02:30:04.286774: step 1180, loss = 5.70, accu = 0.74, validation: 0.63 (590.4 examples/sec; 0.217 sec/batch)
2016-12-03 02:30:06.404699: step 1190, loss = 5.81, accu = 0.62, validation: 0.61 (620.8 examples/sec; 0.206 sec/batch)
2016-12-03 02:30:08.529563: step 1200, loss = 5.71, accu = 0.68, validation: 0.60 (628.9 examples/sec; 0.204 sec/batch)
2016-12-03 02:30:10.855600: step 1210, loss = 5.77, accu = 0.59, validation: 0.70 (583.4 examples/sec; 0.219 sec/batch)
2016-12-03 02:30:13.000775: step 1220, loss = 5.64, accu = 0.66, validation: 0.65 (611.0 examples/sec; 0.209 sec/batch)
2016-12-03 02:30:15.129245: step 1230, loss = 5.44, accu = 0.72, validation: 0.62 (617.7 examples/sec; 0.207 sec/batch)
2016-12-03 02:30:17.271602: step 1240, loss = 5.79, accu = 0.56, validation: 0.67 (600.1 examples/sec; 0.213 sec/batch)
2016-12-03 02:30:19.414621: step 1250, loss = 5.53, accu = 0.67, validation: 0.65 (585.9 examples/sec; 0.218 sec/batch)
2016-12-03 02:30:21.552566: step 1260, loss = 5.53, accu = 0.61, validation: 0.62 (584.6 examples/sec; 0.219 sec/batch)
2016-12-03 02:30:23.678694: step 1270, loss = 5.46, accu = 0.63, validation: 0.62 (617.3 examples/sec; 0.207 sec/batch)
2016-12-03 02:30:25.845310: step 1280, loss = 5.39, accu = 0.68, validation: 0.62 (568.6 examples/sec; 0.225 sec/batch)
2016-12-03 02:30:27.996999: step 1290, loss = 5.49, accu = 0.66, validation: 0.65 (588.5 examples/sec; 0.218 sec/batch)
2016-12-03 02:30:30.148138: step 1300, loss = 5.37, accu = 0.65, validation: 0.62 (572.9 examples/sec; 0.223 sec/batch)
2016-12-03 02:30:32.412736: step 1310, loss = 5.26, accu = 0.71, validation: 0.61 (599.2 examples/sec; 0.214 sec/batch)
2016-12-03 02:30:34.604859: step 1320, loss = 5.29, accu = 0.66, validation: 0.68 (591.7 examples/sec; 0.216 sec/batch)
2016-12-03 02:30:36.798036: step 1330, loss = 5.13, accu = 0.72, validation: 0.63 (574.6 examples/sec; 0.223 sec/batch)
2016-12-03 02:30:38.990442: step 1340, loss = 5.17, accu = 0.70, validation: 0.63 (570.3 examples/sec; 0.224 sec/batch)
2016-12-03 02:30:41.194810: step 1350, loss = 5.29, accu = 0.62, validation: 0.66 (619.5 examples/sec; 0.207 sec/batch)
2016-12-03 02:30:43.428670: step 1360, loss = 5.24, accu = 0.59, validation: 0.65 (533.4 examples/sec; 0.240 sec/batch)
2016-12-03 02:30:45.729851: step 1370, loss = 5.25, accu = 0.59, validation: 0.61 (580.8 examples/sec; 0.220 sec/batch)
2016-12-03 02:30:48.016019: step 1380, loss = 5.21, accu = 0.63, validation: 0.62 (567.9 examples/sec; 0.225 sec/batch)
2016-12-03 02:30:50.442313: step 1390, loss = 5.00, accu = 0.67, validation: 0.69 (539.8 examples/sec; 0.237 sec/batch)
2016-12-03 02:30:53.566086: step 1400, loss = 5.06, accu = 0.62, validation: 0.64 (365.7 examples/sec; 0.350 sec/batch)
2016-12-03 02:30:57.309362: step 1410, loss = 4.84, accu = 0.75, validation: 0.62 (296.6 examples/sec; 0.431 sec/batch)
2016-12-03 02:31:00.976282: step 1420, loss = 4.83, accu = 0.73, validation: 0.58 (375.0 examples/sec; 0.341 sec/batch)
2016-12-03 02:31:04.673116: step 1430, loss = 4.81, accu = 0.71, validation: 0.62 (321.6 examples/sec; 0.398 sec/batch)
2016-12-03 02:31:08.170532: step 1440, loss = 5.02, accu = 0.59, validation: 0.59 (347.3 examples/sec; 0.369 sec/batch)
2016-12-03 02:31:11.774128: step 1450, loss = 4.83, accu = 0.66, validation: 0.68 (334.0 examples/sec; 0.383 sec/batch)
2016-12-03 02:31:15.856663: step 1460, loss = 4.78, accu = 0.66, validation: 0.63 (338.1 examples/sec; 0.379 sec/batch)
2016-12-03 02:31:19.612066: step 1470, loss = 4.84, accu = 0.59, validation: 0.70 (324.3 examples/sec; 0.395 sec/batch)
2016-12-03 02:31:23.150118: step 1480, loss = 4.66, accu = 0.73, validation: 0.66 (387.4 examples/sec; 0.330 sec/batch)
2016-12-03 02:31:27.017954: step 1490, loss = 4.82, accu = 0.64, validation: 0.59 (307.0 examples/sec; 0.417 sec/batch)
2016-12-03 02:31:30.737580: step 1500, loss = 4.65, accu = 0.66, validation: 0.69 (326.7 examples/sec; 0.392 sec/batch)
2016-12-03 02:31:34.792923: step 1510, loss = 4.68, accu = 0.62, validation: 0.66 (325.7 examples/sec; 0.393 sec/batch)
2016-12-03 02:31:38.453739: step 1520, loss = 4.63, accu = 0.64, validation: 0.62 (370.9 examples/sec; 0.345 sec/batch)
2016-12-03 02:31:42.180199: step 1530, loss = 4.41, accu = 0.75, validation: 0.62 (337.1 examples/sec; 0.380 sec/batch)
2016-12-03 02:31:46.371522: step 1540, loss = 4.42, accu = 0.73, validation: 0.65 (280.1 examples/sec; 0.457 sec/batch)
2016-12-03 02:31:50.892347: step 1550, loss = 4.61, accu = 0.63, validation: 0.62 (318.8 examples/sec; 0.401 sec/batch)
2016-12-03 02:31:54.967347: step 1560, loss = 4.40, accu = 0.70, validation: 0.59 (274.3 examples/sec; 0.467 sec/batch)
2016-12-03 02:31:58.348310: step 1570, loss = 4.63, accu = 0.58, validation: 0.58 (386.7 examples/sec; 0.331 sec/batch)
2016-12-03 02:32:01.803832: step 1580, loss = 4.49, accu = 0.60, validation: 0.64 (361.5 examples/sec; 0.354 sec/batch)
2016-12-03 02:32:05.595997: step 1590, loss = 4.38, accu = 0.66, validation: 0.70 (378.4 examples/sec; 0.338 sec/batch)
2016-12-03 02:32:09.387753: step 1600, loss = 4.45, accu = 0.60, validation: 0.64 (365.0 examples/sec; 0.351 sec/batch)
2016-12-03 02:32:13.348039: step 1610, loss = 4.35, accu = 0.66, validation: 0.64 (380.1 examples/sec; 0.337 sec/batch)
2016-12-03 02:32:16.854933: step 1620, loss = 4.42, accu = 0.63, validation: 0.63 (390.1 examples/sec; 0.328 sec/batch)
2016-12-03 02:32:20.412592: step 1630, loss = 4.21, accu = 0.65, validation: 0.66 (344.4 examples/sec; 0.372 sec/batch)
2016-12-03 02:32:23.856836: step 1640, loss = 4.42, accu = 0.62, validation: 0.66 (361.3 examples/sec; 0.354 sec/batch)
2016-12-03 02:32:27.195498: step 1650, loss = 4.23, accu = 0.69, validation: 0.59 (390.7 examples/sec; 0.328 sec/batch)
2016-12-03 02:32:30.816856: step 1660, loss = 4.44, accu = 0.60, validation: 0.62 (372.6 examples/sec; 0.344 sec/batch)
2016-12-03 02:32:34.172201: step 1670, loss = 4.08, accu = 0.74, validation: 0.70 (384.1 examples/sec; 0.333 sec/batch)
2016-12-03 02:32:37.746872: step 1680, loss = 4.22, accu = 0.66, validation: 0.65 (370.7 examples/sec; 0.345 sec/batch)
2016-12-03 02:32:41.092180: step 1690, loss = 4.12, accu = 0.67, validation: 0.66 (377.5 examples/sec; 0.339 sec/batch)
2016-12-03 02:32:44.688726: step 1700, loss = 4.15, accu = 0.62, validation: 0.64 (372.1 examples/sec; 0.344 sec/batch)
2016-12-03 02:32:48.381446: step 1710, loss = 3.87, accu = 0.77, validation: 0.65 (377.7 examples/sec; 0.339 sec/batch)
2016-12-03 02:32:51.771994: step 1720, loss = 4.13, accu = 0.58, validation: 0.66 (389.2 examples/sec; 0.329 sec/batch)
2016-12-03 02:32:55.239571: step 1730, loss = 4.03, accu = 0.69, validation: 0.61 (382.6 examples/sec; 0.335 sec/batch)
2016-12-03 02:32:58.681939: step 1740, loss = 3.89, accu = 0.74, validation: 0.59 (395.8 examples/sec; 0.323 sec/batch)
2016-12-03 02:33:02.161084: step 1750, loss = 4.09, accu = 0.59, validation: 0.70 (376.8 examples/sec; 0.340 sec/batch)
2016-12-03 02:33:05.679752: step 1760, loss = 3.91, accu = 0.66, validation: 0.59 (372.6 examples/sec; 0.344 sec/batch)
2016-12-03 02:33:09.203950: step 1770, loss = 4.01, accu = 0.64, validation: 0.60 (375.0 examples/sec; 0.341 sec/batch)
2016-12-03 02:33:12.677971: step 1780, loss = 3.94, accu = 0.62, validation: 0.73 (294.9 examples/sec; 0.434 sec/batch)
2016-12-03 02:33:16.186276: step 1790, loss = 3.95, accu = 0.62, validation: 0.65 (376.9 examples/sec; 0.340 sec/batch)
2016-12-03 02:33:19.664814: step 1800, loss = 3.82, accu = 0.70, validation: 0.70 (391.3 examples/sec; 0.327 sec/batch)
2016-12-03 02:33:23.428923: step 1810, loss = 3.97, accu = 0.61, validation: 0.60 (394.5 examples/sec; 0.324 sec/batch)
2016-12-03 02:33:26.977813: step 1820, loss = 3.61, accu = 0.73, validation: 0.67 (298.7 examples/sec; 0.429 sec/batch)
2016-12-03 02:33:30.424467: step 1830, loss = 3.87, accu = 0.60, validation: 0.58 (357.3 examples/sec; 0.358 sec/batch)
2016-12-03 02:33:33.882920: step 1840, loss = 3.77, accu = 0.66, validation: 0.63 (283.5 examples/sec; 0.452 sec/batch)
2016-12-03 02:33:37.266053: step 1850, loss = 3.74, accu = 0.65, validation: 0.66 (401.0 examples/sec; 0.319 sec/batch)
2016-12-03 02:33:40.744757: step 1860, loss = 3.72, accu = 0.66, validation: 0.66 (391.1 examples/sec; 0.327 sec/batch)
2016-12-03 02:33:44.287378: step 1870, loss = 3.62, accu = 0.69, validation: 0.66 (378.0 examples/sec; 0.339 sec/batch)
2016-12-03 02:33:47.756738: step 1880, loss = 3.61, accu = 0.71, validation: 0.61 (390.5 examples/sec; 0.328 sec/batch)
2016-12-03 02:33:51.143773: step 1890, loss = 3.57, accu = 0.71, validation: 0.62 (400.8 examples/sec; 0.319 sec/batch)
2016-12-03 02:33:54.608574: step 1900, loss = 3.46, accu = 0.73, validation: 0.61 (397.4 examples/sec; 0.322 sec/batch)
2016-12-03 02:33:58.390095: step 1910, loss = 3.60, accu = 0.68, validation: 0.64 (390.2 examples/sec; 0.328 sec/batch)
2016-12-03 02:34:01.753666: step 1920, loss = 3.59, accu = 0.63, validation: 0.66 (365.6 examples/sec; 0.350 sec/batch)
2016-12-03 02:34:05.320811: step 1930, loss = 3.50, accu = 0.70, validation: 0.62 (380.6 examples/sec; 0.336 sec/batch)
2016-12-03 02:34:08.845678: step 1940, loss = 3.61, accu = 0.64, validation: 0.63 (274.5 examples/sec; 0.466 sec/batch)
2016-12-03 02:34:12.309679: step 1950, loss = 3.67, accu = 0.58, validation: 0.61 (381.3 examples/sec; 0.336 sec/batch)
2016-12-03 02:34:15.834311: step 1960, loss = 3.49, accu = 0.67, validation: 0.66 (385.1 examples/sec; 0.332 sec/batch)
2016-12-03 02:34:19.204731: step 1970, loss = 3.58, accu = 0.65, validation: 0.64 (381.9 examples/sec; 0.335 sec/batch)
2016-12-03 02:34:22.805661: step 1980, loss = 3.40, accu = 0.67, validation: 0.61 (383.7 examples/sec; 0.334 sec/batch)
2016-12-03 02:34:26.257303: step 1990, loss = 3.49, accu = 0.68, validation: 0.64 (389.2 examples/sec; 0.329 sec/batch)
2016-12-03 02:34:29.704125: step 2000, loss = 3.42, accu = 0.70, validation: 0.71 (365.0 examples/sec; 0.351 sec/batch)
2016-12-03 02:34:33.817051: step 2010, loss = 3.47, accu = 0.65, validation: 0.65 (393.9 examples/sec; 0.325 sec/batch)
2016-12-03 02:34:37.305202: step 2020, loss = 3.37, accu = 0.72, validation: 0.65 (383.3 examples/sec; 0.334 sec/batch)
2016-12-03 02:34:40.909365: step 2030, loss = 3.27, accu = 0.73, validation: 0.60 (300.7 examples/sec; 0.426 sec/batch)
2016-12-03 02:34:44.457525: step 2040, loss = 3.27, accu = 0.68, validation: 0.70 (345.4 examples/sec; 0.371 sec/batch)
2016-12-03 02:34:47.836567: step 2050, loss = 3.20, accu = 0.72, validation: 0.74 (380.7 examples/sec; 0.336 sec/batch)
2016-12-03 02:34:51.315360: step 2060, loss = 3.28, accu = 0.71, validation: 0.65 (384.2 examples/sec; 0.333 sec/batch)
2016-12-03 02:34:54.864457: step 2070, loss = 3.16, accu = 0.73, validation: 0.67 (385.7 examples/sec; 0.332 sec/batch)
2016-12-03 02:34:58.399089: step 2080, loss = 3.26, accu = 0.69, validation: 0.66 (383.3 examples/sec; 0.334 sec/batch)
2016-12-03 02:35:01.972122: step 2090, loss = 3.20, accu = 0.71, validation: 0.65 (381.2 examples/sec; 0.336 sec/batch)
2016-12-03 02:35:05.457253: step 2100, loss = 3.20, accu = 0.69, validation: 0.65 (390.6 examples/sec; 0.328 sec/batch)
2016-12-03 02:35:09.285710: step 2110, loss = 3.20, accu = 0.64, validation: 0.65 (372.7 examples/sec; 0.343 sec/batch)
2016-12-03 02:35:12.806398: step 2120, loss = 3.06, accu = 0.73, validation: 0.62 (408.8 examples/sec; 0.313 sec/batch)
2016-12-03 02:35:16.473883: step 2130, loss = 3.09, accu = 0.72, validation: 0.70 (375.4 examples/sec; 0.341 sec/batch)
2016-12-03 02:35:19.982326: step 2140, loss = 3.12, accu = 0.66, validation: 0.58 (387.7 examples/sec; 0.330 sec/batch)
2016-12-03 02:35:23.450876: step 2150, loss = 3.12, accu = 0.66, validation: 0.70 (383.0 examples/sec; 0.334 sec/batch)
2016-12-03 02:35:26.951329: step 2160, loss = 3.07, accu = 0.68, validation: 0.70 (366.9 examples/sec; 0.349 sec/batch)
2016-12-03 02:35:30.530560: step 2170, loss = 3.09, accu = 0.64, validation: 0.68 (395.3 examples/sec; 0.324 sec/batch)
2016-12-03 02:35:34.103954: step 2180, loss = 3.06, accu = 0.70, validation: 0.63 (367.7 examples/sec; 0.348 sec/batch)
2016-12-03 02:35:37.663369: step 2190, loss = 2.96, accu = 0.74, validation: 0.62 (367.2 examples/sec; 0.349 sec/batch)
2016-12-03 02:35:41.152481: step 2200, loss = 2.96, accu = 0.75, validation: 0.64 (384.4 examples/sec; 0.333 sec/batch)
2016-12-03 02:35:44.869667: step 2210, loss = 2.96, accu = 0.69, validation: 0.65 (385.3 examples/sec; 0.332 sec/batch)
2016-12-03 02:35:48.285697: step 2220, loss = 2.87, accu = 0.74, validation: 0.66 (378.4 examples/sec; 0.338 sec/batch)
2016-12-03 02:35:52.006513: step 2230, loss = 2.91, accu = 0.70, validation: 0.62 (376.5 examples/sec; 0.340 sec/batch)
2016-12-03 02:35:55.471773: step 2240, loss = 3.01, accu = 0.62, validation: 0.70 (378.7 examples/sec; 0.338 sec/batch)
2016-12-03 02:35:59.049665: step 2250, loss = 2.85, accu = 0.69, validation: 0.70 (388.7 examples/sec; 0.329 sec/batch)
2016-12-03 02:36:02.568349: step 2260, loss = 2.94, accu = 0.70, validation: 0.69 (377.3 examples/sec; 0.339 sec/batch)
2016-12-03 02:36:06.077049: step 2270, loss = 2.99, accu = 0.64, validation: 0.70 (377.8 examples/sec; 0.339 sec/batch)
2016-12-03 02:36:09.613386: step 2280, loss = 2.90, accu = 0.69, validation: 0.69 (375.0 examples/sec; 0.341 sec/batch)
2016-12-03 02:36:13.291165: step 2290, loss = 2.76, accu = 0.73, validation: 0.64 (305.6 examples/sec; 0.419 sec/batch)
2016-12-03 02:36:16.674187: step 2300, loss = 2.74, accu = 0.75, validation: 0.68 (386.1 examples/sec; 0.331 sec/batch)
2016-12-03 02:36:20.455260: step 2310, loss = 2.68, accu = 0.77, validation: 0.64 (393.3 examples/sec; 0.325 sec/batch)
2016-12-03 02:36:24.061474: step 2320, loss = 2.81, accu = 0.70, validation: 0.71 (362.4 examples/sec; 0.353 sec/batch)
2016-12-03 02:36:27.540756: step 2330, loss = 2.82, accu = 0.70, validation: 0.64 (393.8 examples/sec; 0.325 sec/batch)
2016-12-03 02:36:31.078668: step 2340, loss = 2.78, accu = 0.74, validation: 0.65 (386.6 examples/sec; 0.331 sec/batch)
2016-12-03 02:36:34.599038: step 2350, loss = 2.71, accu = 0.74, validation: 0.67 (383.2 examples/sec; 0.334 sec/batch)
2016-12-03 02:36:38.109090: step 2360, loss = 2.79, accu = 0.66, validation: 0.64 (384.7 examples/sec; 0.333 sec/batch)
2016-12-03 02:36:41.609768: step 2370, loss = 2.81, accu = 0.61, validation: 0.66 (386.4 examples/sec; 0.331 sec/batch)
2016-12-03 02:36:45.082469: step 2380, loss = 2.69, accu = 0.70, validation: 0.65 (377.7 examples/sec; 0.339 sec/batch)
2016-12-03 02:36:48.664069: step 2390, loss = 2.68, accu = 0.73, validation: 0.64 (363.6 examples/sec; 0.352 sec/batch)
2016-12-03 02:36:52.104462: step 2400, loss = 2.78, accu = 0.68, validation: 0.63 (391.0 examples/sec; 0.327 sec/batch)
2016-12-03 02:36:55.896409: step 2410, loss = 2.60, accu = 0.71, validation: 0.71 (384.3 examples/sec; 0.333 sec/batch)
2016-12-03 02:36:59.482019: step 2420, loss = 2.58, accu = 0.66, validation: 0.66 (377.4 examples/sec; 0.339 sec/batch)
2016-12-03 02:37:03.008629: step 2430, loss = 2.67, accu = 0.66, validation: 0.66 (368.1 examples/sec; 0.348 sec/batch)
2016-12-03 02:37:06.554703: step 2440, loss = 2.68, accu = 0.69, validation: 0.58 (374.2 examples/sec; 0.342 sec/batch)
2016-12-03 02:37:09.979538: step 2450, loss = 2.61, accu = 0.70, validation: 0.58 (342.3 examples/sec; 0.374 sec/batch)
2016-12-03 02:37:14.136972: step 2460, loss = 2.57, accu = 0.68, validation: 0.64 (324.6 examples/sec; 0.394 sec/batch)
2016-12-03 02:37:17.999513: step 2470, loss = 2.50, accu = 0.75, validation: 0.62 (326.8 examples/sec; 0.392 sec/batch)
2016-12-03 02:37:22.170215: step 2480, loss = 2.66, accu = 0.68, validation: 0.64 (373.6 examples/sec; 0.343 sec/batch)
2016-12-03 02:37:26.237474: step 2490, loss = 2.73, accu = 0.62, validation: 0.64 (370.6 examples/sec; 0.345 sec/batch)
2016-12-03 02:37:29.848368: step 2500, loss = 2.63, accu = 0.65, validation: 0.68 (395.5 examples/sec; 0.324 sec/batch)
2016-12-03 02:37:33.724861: step 2510, loss = 2.54, accu = 0.71, validation: 0.65 (333.6 examples/sec; 0.384 sec/batch)
2016-12-03 02:37:37.553800: step 2520, loss = 2.47, accu = 0.73, validation: 0.66 (371.7 examples/sec; 0.344 sec/batch)
2016-12-03 02:37:41.063710: step 2530, loss = 2.62, accu = 0.66, validation: 0.72 (342.0 examples/sec; 0.374 sec/batch)
2016-12-03 02:37:44.538901: step 2540, loss = 2.49, accu = 0.68, validation: 0.66 (375.0 examples/sec; 0.341 sec/batch)
2016-12-03 02:37:47.921308: step 2550, loss = 2.42, accu = 0.70, validation: 0.65 (380.4 examples/sec; 0.337 sec/batch)
2016-12-03 02:37:51.480848: step 2560, loss = 2.36, accu = 0.75, validation: 0.68 (306.9 examples/sec; 0.417 sec/batch)
2016-12-03 02:37:54.848065: step 2570, loss = 2.40, accu = 0.69, validation: 0.66 (397.6 examples/sec; 0.322 sec/batch)
2016-12-03 02:37:58.324587: step 2580, loss = 2.40, accu = 0.68, validation: 0.63 (388.1 examples/sec; 0.330 sec/batch)
2016-12-03 02:38:01.922960: step 2590, loss = 2.38, accu = 0.73, validation: 0.64 (388.3 examples/sec; 0.330 sec/batch)
2016-12-03 02:38:05.429575: step 2600, loss = 2.38, accu = 0.72, validation: 0.61 (382.9 examples/sec; 0.334 sec/batch)
2016-12-03 02:38:09.234264: step 2610, loss = 2.40, accu = 0.69, validation: 0.71 (377.2 examples/sec; 0.339 sec/batch)
2016-12-03 02:38:12.739372: step 2620, loss = 2.42, accu = 0.70, validation: 0.70 (373.8 examples/sec; 0.342 sec/batch)
2016-12-03 02:38:16.199032: step 2630, loss = 2.32, accu = 0.73, validation: 0.68 (386.3 examples/sec; 0.331 sec/batch)
2016-12-03 02:38:19.698329: step 2640, loss = 2.25, accu = 0.71, validation: 0.65 (388.4 examples/sec; 0.330 sec/batch)
2016-12-03 02:38:23.233872: step 2650, loss = 2.45, accu = 0.62, validation: 0.61 (391.1 examples/sec; 0.327 sec/batch)
2016-12-03 02:38:26.781527: step 2660, loss = 2.25, accu = 0.74, validation: 0.66 (393.6 examples/sec; 0.325 sec/batch)
2016-12-03 02:38:30.255316: step 2670, loss = 2.14, accu = 0.77, validation: 0.70 (383.7 examples/sec; 0.334 sec/batch)
2016-12-03 02:38:33.771952: step 2680, loss = 2.36, accu = 0.70, validation: 0.64 (395.1 examples/sec; 0.324 sec/batch)
2016-12-03 02:38:37.159475: step 2690, loss = 2.21, accu = 0.74, validation: 0.66 (365.9 examples/sec; 0.350 sec/batch)
2016-12-03 02:38:40.742125: step 2700, loss = 2.27, accu = 0.70, validation: 0.70 (397.6 examples/sec; 0.322 sec/batch)
2016-12-03 02:38:44.523202: step 2710, loss = 2.34, accu = 0.69, validation: 0.68 (356.9 examples/sec; 0.359 sec/batch)
2016-12-03 02:38:48.035382: step 2720, loss = 2.28, accu = 0.72, validation: 0.66 (394.0 examples/sec; 0.325 sec/batch)
2016-12-03 02:38:51.595450: step 2730, loss = 2.13, accu = 0.77, validation: 0.70 (388.7 examples/sec; 0.329 sec/batch)
2016-12-03 02:38:55.165685: step 2740, loss = 2.38, accu = 0.64, validation: 0.69 (334.2 examples/sec; 0.383 sec/batch)
2016-12-03 02:38:58.693018: step 2750, loss = 2.19, accu = 0.77, validation: 0.67 (329.5 examples/sec; 0.388 sec/batch)
2016-12-03 02:39:02.239855: step 2760, loss = 2.17, accu = 0.70, validation: 0.65 (374.4 examples/sec; 0.342 sec/batch)
2016-12-03 02:39:05.706920: step 2770, loss = 2.34, accu = 0.64, validation: 0.61 (295.8 examples/sec; 0.433 sec/batch)
2016-12-03 02:39:09.260498: step 2780, loss = 2.15, accu = 0.70, validation: 0.66 (368.8 examples/sec; 0.347 sec/batch)
2016-12-03 02:39:12.728063: step 2790, loss = 2.04, accu = 0.74, validation: 0.65 (380.9 examples/sec; 0.336 sec/batch)
2016-12-03 02:39:16.183262: step 2800, loss = 2.23, accu = 0.73, validation: 0.59 (291.4 examples/sec; 0.439 sec/batch)
2016-12-03 02:39:19.996271: step 2810, loss = 2.10, accu = 0.74, validation: 0.69 (351.9 examples/sec; 0.364 sec/batch)
2016-12-03 02:39:23.385058: step 2820, loss = 2.06, accu = 0.77, validation: 0.66 (379.9 examples/sec; 0.337 sec/batch)
2016-12-03 02:39:26.955303: step 2830, loss = 2.18, accu = 0.67, validation: 0.70 (335.6 examples/sec; 0.381 sec/batch)
2016-12-03 02:39:30.439937: step 2840, loss = 2.05, accu = 0.73, validation: 0.68 (370.6 examples/sec; 0.345 sec/batch)
2016-12-03 02:39:34.005198: step 2850, loss = 2.03, accu = 0.73, validation: 0.68 (320.9 examples/sec; 0.399 sec/batch)
2016-12-03 02:39:37.591495: step 2860, loss = 1.97, accu = 0.76, validation: 0.66 (378.8 examples/sec; 0.338 sec/batch)
2016-12-03 02:39:40.965575: step 2870, loss = 2.09, accu = 0.73, validation: 0.66 (386.5 examples/sec; 0.331 sec/batch)
2016-12-03 02:39:44.532732: step 2880, loss = 2.01, accu = 0.75, validation: 0.66 (385.3 examples/sec; 0.332 sec/batch)
2016-12-03 02:39:48.067273: step 2890, loss = 1.99, accu = 0.76, validation: 0.66 (378.1 examples/sec; 0.338 sec/batch)
2016-12-03 02:39:51.652597: step 2900, loss = 2.02, accu = 0.73, validation: 0.65 (381.8 examples/sec; 0.335 sec/batch)
2016-12-03 02:39:55.383379: step 2910, loss = 2.06, accu = 0.73, validation: 0.62 (378.6 examples/sec; 0.338 sec/batch)
2016-12-03 02:39:58.987318: step 2920, loss = 1.92, accu = 0.73, validation: 0.70 (353.7 examples/sec; 0.362 sec/batch)
2016-12-03 02:40:02.348062: step 2930, loss = 1.91, accu = 0.80, validation: 0.59 (388.6 examples/sec; 0.329 sec/batch)
2016-12-03 02:40:05.783882: step 2940, loss = 1.90, accu = 0.77, validation: 0.66 (396.3 examples/sec; 0.323 sec/batch)
2016-12-03 02:40:09.453485: step 2950, loss = 1.99, accu = 0.75, validation: 0.72 (395.8 examples/sec; 0.323 sec/batch)
2016-12-03 02:40:13.074890: step 2960, loss = 2.03, accu = 0.70, validation: 0.62 (350.5 examples/sec; 0.365 sec/batch)
2016-12-03 02:40:16.476962: step 2970, loss = 2.01, accu = 0.71, validation: 0.66 (391.3 examples/sec; 0.327 sec/batch)
2016-12-03 02:40:19.960680: step 2980, loss = 1.96, accu = 0.73, validation: 0.62 (278.4 examples/sec; 0.460 sec/batch)
2016-12-03 02:40:23.385128: step 2990, loss = 2.08, accu = 0.67, validation: 0.69 (377.0 examples/sec; 0.340 sec/batch)
2016-12-03 02:40:26.917464: step 3000, loss = 1.80, accu = 0.82, validation: 0.66 (375.4 examples/sec; 0.341 sec/batch)
2016-12-03 02:40:31.225049: step 3010, loss = 1.88, accu = 0.75, validation: 0.62 (326.0 examples/sec; 0.393 sec/batch)
2016-12-03 02:40:34.785462: step 3020, loss = 1.88, accu = 0.76, validation: 0.67 (290.3 examples/sec; 0.441 sec/batch)
2016-12-03 02:40:38.250897: step 3030, loss = 1.97, accu = 0.69, validation: 0.67 (375.7 examples/sec; 0.341 sec/batch)
2016-12-03 02:40:41.776004: step 3040, loss = 1.97, accu = 0.70, validation: 0.70 (387.0 examples/sec; 0.331 sec/batch)
2016-12-03 02:40:45.462406: step 3050, loss = 1.79, accu = 0.77, validation: 0.64 (310.5 examples/sec; 0.412 sec/batch)
2016-12-03 02:40:48.996657: step 3060, loss = 1.93, accu = 0.72, validation: 0.59 (387.6 examples/sec; 0.330 sec/batch)
2016-12-03 02:40:52.502706: step 3070, loss = 1.73, accu = 0.82, validation: 0.70 (390.1 examples/sec; 0.328 sec/batch)
2016-12-03 02:40:56.119550: step 3080, loss = 2.07, accu = 0.59, validation: 0.70 (364.3 examples/sec; 0.351 sec/batch)
2016-12-03 02:40:59.648232: step 3090, loss = 1.69, accu = 0.80, validation: 0.72 (381.9 examples/sec; 0.335 sec/batch)
2016-12-03 02:41:03.255049: step 3100, loss = 1.78, accu = 0.75, validation: 0.70 (342.3 examples/sec; 0.374 sec/batch)
2016-12-03 02:41:06.881180: step 3110, loss = 1.80, accu = 0.76, validation: 0.63 (371.9 examples/sec; 0.344 sec/batch)
2016-12-03 02:41:10.540205: step 3120, loss = 1.90, accu = 0.74, validation: 0.62 (349.0 examples/sec; 0.367 sec/batch)
2016-12-03 02:41:14.060225: step 3130, loss = 1.80, accu = 0.75, validation: 0.71 (392.1 examples/sec; 0.326 sec/batch)
2016-12-03 02:41:17.435242: step 3140, loss = 2.03, accu = 0.66, validation: 0.59 (388.1 examples/sec; 0.330 sec/batch)
2016-12-03 02:41:21.018236: step 3150, loss = 1.64, accu = 0.81, validation: 0.62 (381.0 examples/sec; 0.336 sec/batch)
2016-12-03 02:41:24.524665: step 3160, loss = 1.75, accu = 0.74, validation: 0.70 (382.2 examples/sec; 0.335 sec/batch)
2016-12-03 02:41:28.096539: step 3170, loss = 1.81, accu = 0.75, validation: 0.66 (360.6 examples/sec; 0.355 sec/batch)
2016-12-03 02:41:31.614209: step 3180, loss = 1.75, accu = 0.77, validation: 0.69 (361.5 examples/sec; 0.354 sec/batch)
2016-12-03 02:41:35.218277: step 3190, loss = 1.77, accu = 0.76, validation: 0.75 (301.1 examples/sec; 0.425 sec/batch)
2016-12-03 02:41:38.766464: step 3200, loss = 1.88, accu = 0.74, validation: 0.67 (380.6 examples/sec; 0.336 sec/batch)
2016-12-03 02:41:42.502608: step 3210, loss = 1.73, accu = 0.73, validation: 0.66 (385.5 examples/sec; 0.332 sec/batch)
2016-12-03 02:41:46.038302: step 3220, loss = 1.78, accu = 0.74, validation: 0.70 (389.4 examples/sec; 0.329 sec/batch)
2016-12-03 02:41:49.600985: step 3230, loss = 1.59, accu = 0.81, validation: 0.68 (386.5 examples/sec; 0.331 sec/batch)
2016-12-03 02:41:53.154800: step 3240, loss = 1.76, accu = 0.72, validation: 0.67 (388.0 examples/sec; 0.330 sec/batch)
2016-12-03 02:41:56.692973: step 3250, loss = 1.68, accu = 0.77, validation: 0.62 (387.2 examples/sec; 0.331 sec/batch)
2016-12-03 02:42:00.214017: step 3260, loss = 1.66, accu = 0.76, validation: 0.58 (373.0 examples/sec; 0.343 sec/batch)
2016-12-03 02:42:03.763731: step 3270, loss = 1.63, accu = 0.80, validation: 0.70 (377.2 examples/sec; 0.339 sec/batch)
2016-12-03 02:42:07.249565: step 3280, loss = 1.69, accu = 0.74, validation: 0.65 (380.1 examples/sec; 0.337 sec/batch)
2016-12-03 02:42:10.669996: step 3290, loss = 1.66, accu = 0.77, validation: 0.71 (396.0 examples/sec; 0.323 sec/batch)
2016-12-03 02:42:14.144116: step 3300, loss = 1.71, accu = 0.74, validation: 0.69 (382.1 examples/sec; 0.335 sec/batch)
2016-12-03 02:42:18.014546: step 3310, loss = 1.67, accu = 0.77, validation: 0.67 (385.1 examples/sec; 0.332 sec/batch)
2016-12-03 02:42:21.530201: step 3320, loss = 1.74, accu = 0.75, validation: 0.62 (343.3 examples/sec; 0.373 sec/batch)
2016-12-03 02:42:24.982125: step 3330, loss = 1.62, accu = 0.73, validation: 0.69 (370.3 examples/sec; 0.346 sec/batch)
2016-12-03 02:42:28.454625: step 3340, loss = 1.52, accu = 0.81, validation: 0.65 (389.1 examples/sec; 0.329 sec/batch)
2016-12-03 02:42:31.997793: step 3350, loss = 1.76, accu = 0.69, validation: 0.70 (287.0 examples/sec; 0.446 sec/batch)
2016-12-03 02:42:35.682430: step 3360, loss = 1.60, accu = 0.77, validation: 0.60 (335.0 examples/sec; 0.382 sec/batch)
2016-12-03 02:42:39.046785: step 3370, loss = 1.68, accu = 0.70, validation: 0.63 (389.7 examples/sec; 0.328 sec/batch)
2016-12-03 02:42:42.498012: step 3380, loss = 1.50, accu = 0.80, validation: 0.69 (392.9 examples/sec; 0.326 sec/batch)
2016-12-03 02:42:45.968035: step 3390, loss = 1.64, accu = 0.76, validation: 0.66 (384.2 examples/sec; 0.333 sec/batch)
2016-12-03 02:42:49.500163: step 3400, loss = 1.63, accu = 0.72, validation: 0.59 (381.1 examples/sec; 0.336 sec/batch)
2016-12-03 02:42:53.294594: step 3410, loss = 1.66, accu = 0.70, validation: 0.72 (383.2 examples/sec; 0.334 sec/batch)
2016-12-03 02:42:56.829138: step 3420, loss = 1.37, accu = 0.84, validation: 0.66 (374.5 examples/sec; 0.342 sec/batch)
2016-12-03 02:43:00.231324: step 3430, loss = 1.47, accu = 0.77, validation: 0.62 (371.7 examples/sec; 0.344 sec/batch)
2016-12-03 02:43:03.718098: step 3440, loss = 1.56, accu = 0.77, validation: 0.65 (393.1 examples/sec; 0.326 sec/batch)
2016-12-03 02:43:07.245237: step 3450, loss = 1.53, accu = 0.80, validation: 0.71 (377.7 examples/sec; 0.339 sec/batch)
2016-12-03 02:43:10.780104: step 3460, loss = 1.41, accu = 0.80, validation: 0.66 (394.2 examples/sec; 0.325 sec/batch)
2016-12-03 02:43:14.219957: step 3470, loss = 1.58, accu = 0.77, validation: 0.66 (387.7 examples/sec; 0.330 sec/batch)
2016-12-03 02:43:17.858205: step 3480, loss = 1.64, accu = 0.73, validation: 0.68 (380.3 examples/sec; 0.337 sec/batch)
2016-12-03 02:43:21.380361: step 3490, loss = 1.43, accu = 0.84, validation: 0.71 (395.1 examples/sec; 0.324 sec/batch)
2016-12-03 02:43:24.907995: step 3500, loss = 1.47, accu = 0.84, validation: 0.59 (374.9 examples/sec; 0.341 sec/batch)
2016-12-03 02:43:28.687070: step 3510, loss = 1.66, accu = 0.73, validation: 0.66 (368.0 examples/sec; 0.348 sec/batch)
2016-12-03 02:43:32.177712: step 3520, loss = 1.44, accu = 0.78, validation: 0.64 (383.4 examples/sec; 0.334 sec/batch)
2016-12-03 02:43:35.659465: step 3530, loss = 1.43, accu = 0.77, validation: 0.62 (391.7 examples/sec; 0.327 sec/batch)
2016-12-03 02:43:39.169435: step 3540, loss = 1.49, accu = 0.80, validation: 0.70 (371.0 examples/sec; 0.345 sec/batch)
2016-12-03 02:43:42.797614: step 3550, loss = 1.47, accu = 0.73, validation: 0.67 (279.6 examples/sec; 0.458 sec/batch)
2016-12-03 02:43:46.327335: step 3560, loss = 1.46, accu = 0.76, validation: 0.70 (377.5 examples/sec; 0.339 sec/batch)
2016-12-03 02:43:49.888238: step 3570, loss = 1.48, accu = 0.80, validation: 0.61 (373.6 examples/sec; 0.343 sec/batch)
2016-12-03 02:43:53.443353: step 3580, loss = 1.49, accu = 0.74, validation: 0.63 (335.4 examples/sec; 0.382 sec/batch)
2016-12-03 02:43:56.856520: step 3590, loss = 1.36, accu = 0.85, validation: 0.65 (370.7 examples/sec; 0.345 sec/batch)
2016-12-03 02:44:00.389701: step 3600, loss = 1.35, accu = 0.80, validation: 0.61 (364.2 examples/sec; 0.351 sec/batch)
2016-12-03 02:44:04.184491: step 3610, loss = 1.38, accu = 0.84, validation: 0.59 (388.9 examples/sec; 0.329 sec/batch)
2016-12-03 02:44:07.741376: step 3620, loss = 1.39, accu = 0.80, validation: 0.71 (391.0 examples/sec; 0.327 sec/batch)
2016-12-03 02:44:11.341478: step 3630, loss = 1.39, accu = 0.77, validation: 0.59 (392.4 examples/sec; 0.326 sec/batch)
2016-12-03 02:44:14.821873: step 3640, loss = 1.40, accu = 0.74, validation: 0.66 (389.3 examples/sec; 0.329 sec/batch)
2016-12-03 02:44:18.459377: step 3650, loss = 1.29, accu = 0.82, validation: 0.74 (272.9 examples/sec; 0.469 sec/batch)
2016-12-03 02:44:21.900843: step 3660, loss = 1.36, accu = 0.82, validation: 0.70 (393.8 examples/sec; 0.325 sec/batch)
2016-12-03 02:44:25.345803: step 3670, loss = 1.61, accu = 0.73, validation: 0.63 (389.1 examples/sec; 0.329 sec/batch)
2016-12-03 02:44:28.900593: step 3680, loss = 1.31, accu = 0.83, validation: 0.67 (383.7 examples/sec; 0.334 sec/batch)
2016-12-03 02:44:32.410233: step 3690, loss = 1.53, accu = 0.71, validation: 0.61 (290.3 examples/sec; 0.441 sec/batch)
2016-12-03 02:44:35.962383: step 3700, loss = 1.56, accu = 0.70, validation: 0.66 (285.5 examples/sec; 0.448 sec/batch)
2016-12-03 02:44:39.662094: step 3710, loss = 1.37, accu = 0.77, validation: 0.67 (337.3 examples/sec; 0.380 sec/batch)
2016-12-03 02:44:43.025074: step 3720, loss = 1.30, accu = 0.83, validation: 0.66 (374.1 examples/sec; 0.342 sec/batch)
2016-12-03 02:44:46.614515: step 3730, loss = 1.47, accu = 0.77, validation: 0.70 (385.2 examples/sec; 0.332 sec/batch)
2016-12-03 02:44:50.150459: step 3740, loss = 1.41, accu = 0.75, validation: 0.64 (375.1 examples/sec; 0.341 sec/batch)
2016-12-03 02:44:53.532194: step 3750, loss = 1.40, accu = 0.73, validation: 0.64 (362.8 examples/sec; 0.353 sec/batch)
2016-12-03 02:44:57.164286: step 3760, loss = 1.37, accu = 0.77, validation: 0.70 (272.0 examples/sec; 0.471 sec/batch)
2016-12-03 02:45:00.653735: step 3770, loss = 1.39, accu = 0.79, validation: 0.70 (367.0 examples/sec; 0.349 sec/batch)
2016-12-03 02:45:04.150474: step 3780, loss = 1.26, accu = 0.85, validation: 0.62 (385.5 examples/sec; 0.332 sec/batch)
2016-12-03 02:45:07.508105: step 3790, loss = 1.30, accu = 0.80, validation: 0.62 (389.5 examples/sec; 0.329 sec/batch)
2016-12-03 02:45:11.156088: step 3800, loss = 1.32, accu = 0.84, validation: 0.65 (368.8 examples/sec; 0.347 sec/batch)
2016-12-03 02:45:14.952789: step 3810, loss = 1.38, accu = 0.72, validation: 0.69 (375.2 examples/sec; 0.341 sec/batch)
2016-12-03 02:45:18.448453: step 3820, loss = 1.26, accu = 0.80, validation: 0.61 (378.7 examples/sec; 0.338 sec/batch)
2016-12-03 02:45:21.963286: step 3830, loss = 1.22, accu = 0.82, validation: 0.61 (390.5 examples/sec; 0.328 sec/batch)
2016-12-03 02:45:25.553456: step 3840, loss = 1.28, accu = 0.84, validation: 0.69 (299.2 examples/sec; 0.428 sec/batch)
2016-12-03 02:45:29.027592: step 3850, loss = 1.22, accu = 0.86, validation: 0.64 (385.0 examples/sec; 0.332 sec/batch)
2016-12-03 02:45:32.581313: step 3860, loss = 1.46, accu = 0.75, validation: 0.65 (386.9 examples/sec; 0.331 sec/batch)
2016-12-03 02:45:36.028358: step 3870, loss = 1.33, accu = 0.81, validation: 0.68 (379.4 examples/sec; 0.337 sec/batch)
2016-12-03 02:45:39.538707: step 3880, loss = 1.28, accu = 0.80, validation: 0.73 (368.2 examples/sec; 0.348 sec/batch)
2016-12-03 02:45:43.013875: step 3890, loss = 1.29, accu = 0.82, validation: 0.66 (382.7 examples/sec; 0.335 sec/batch)
2016-12-03 02:45:46.505671: step 3900, loss = 1.34, accu = 0.77, validation: 0.63 (371.4 examples/sec; 0.345 sec/batch)
2016-12-03 02:45:50.473251: step 3910, loss = 1.32, accu = 0.81, validation: 0.68 (368.7 examples/sec; 0.347 sec/batch)
2016-12-03 02:45:53.970819: step 3920, loss = 1.33, accu = 0.75, validation: 0.64 (389.4 examples/sec; 0.329 sec/batch)
2016-12-03 02:45:57.431361: step 3930, loss = 1.32, accu = 0.80, validation: 0.63 (388.7 examples/sec; 0.329 sec/batch)
2016-12-03 02:46:00.921200: step 3940, loss = 1.16, accu = 0.84, validation: 0.59 (371.6 examples/sec; 0.344 sec/batch)
2016-12-03 02:46:04.453852: step 3950, loss = 1.28, accu = 0.77, validation: 0.69 (385.9 examples/sec; 0.332 sec/batch)
2016-12-03 02:46:07.990518: step 3960, loss = 1.13, accu = 0.88, validation: 0.58 (376.4 examples/sec; 0.340 sec/batch)
2016-12-03 02:46:11.504083: step 3970, loss = 1.24, accu = 0.81, validation: 0.63 (367.3 examples/sec; 0.348 sec/batch)
2016-12-03 02:46:15.060130: step 3980, loss = 1.32, accu = 0.78, validation: 0.70 (302.8 examples/sec; 0.423 sec/batch)
2016-12-03 02:46:18.498036: step 3990, loss = 1.16, accu = 0.81, validation: 0.68 (362.9 examples/sec; 0.353 sec/batch)
2016-12-03 02:46:22.035470: step 4000, loss = 1.25, accu = 0.77, validation: 0.69 (392.1 examples/sec; 0.326 sec/batch)
2016-12-03 02:46:26.277409: step 4010, loss = 1.24, accu = 0.80, validation: 0.67 (396.0 examples/sec; 0.323 sec/batch)
2016-12-03 02:46:29.796868: step 4020, loss = 1.28, accu = 0.82, validation: 0.70 (375.0 examples/sec; 0.341 sec/batch)
2016-12-03 02:46:33.418894: step 4030, loss = 1.36, accu = 0.78, validation: 0.66 (340.2 examples/sec; 0.376 sec/batch)
2016-12-03 02:46:36.910092: step 4040, loss = 1.22, accu = 0.84, validation: 0.62 (374.6 examples/sec; 0.342 sec/batch)
2016-12-03 02:46:40.486064: step 4050, loss = 1.21, accu = 0.81, validation: 0.65 (356.0 examples/sec; 0.360 sec/batch)
2016-12-03 02:46:43.896025: step 4060, loss = 1.24, accu = 0.77, validation: 0.67 (365.9 examples/sec; 0.350 sec/batch)
2016-12-03 02:46:47.423262: step 4070, loss = 1.17, accu = 0.83, validation: 0.62 (377.9 examples/sec; 0.339 sec/batch)
2016-12-03 02:46:50.930784: step 4080, loss = 1.16, accu = 0.84, validation: 0.65 (380.8 examples/sec; 0.336 sec/batch)
2016-12-03 02:46:54.587679: step 4090, loss = 1.09, accu = 0.86, validation: 0.65 (305.1 examples/sec; 0.419 sec/batch)
2016-12-03 02:46:58.099078: step 4100, loss = 1.28, accu = 0.80, validation: 0.59 (382.2 examples/sec; 0.335 sec/batch)
2016-12-03 02:47:01.916102: step 4110, loss = 1.07, accu = 0.87, validation: 0.70 (355.7 examples/sec; 0.360 sec/batch)
2016-12-03 02:47:05.492968: step 4120, loss = 1.18, accu = 0.85, validation: 0.67 (321.8 examples/sec; 0.398 sec/batch)
2016-12-03 02:47:09.000145: step 4130, loss = 1.22, accu = 0.83, validation: 0.74 (362.4 examples/sec; 0.353 sec/batch)
2016-12-03 02:47:12.496042: step 4140, loss = 1.17, accu = 0.80, validation: 0.63 (388.3 examples/sec; 0.330 sec/batch)
2016-12-03 02:47:16.002497: step 4150, loss = 1.17, accu = 0.81, validation: 0.60 (371.7 examples/sec; 0.344 sec/batch)
2016-12-03 02:47:19.549184: step 4160, loss = 1.11, accu = 0.85, validation: 0.68 (365.6 examples/sec; 0.350 sec/batch)
2016-12-03 02:47:23.098776: step 4170, loss = 1.25, accu = 0.80, validation: 0.63 (355.0 examples/sec; 0.361 sec/batch)
2016-12-03 02:47:26.679902: step 4180, loss = 1.15, accu = 0.84, validation: 0.56 (340.7 examples/sec; 0.376 sec/batch)
2016-12-03 02:47:30.054254: step 4190, loss = 1.16, accu = 0.81, validation: 0.71 (393.0 examples/sec; 0.326 sec/batch)
2016-12-03 02:47:33.805933: step 4200, loss = 1.10, accu = 0.83, validation: 0.59 (381.1 examples/sec; 0.336 sec/batch)
2016-12-03 02:47:37.596769: step 4210, loss = 1.19, accu = 0.82, validation: 0.66 (364.2 examples/sec; 0.351 sec/batch)
2016-12-03 02:47:41.111242: step 4220, loss = 1.07, accu = 0.86, validation: 0.62 (380.1 examples/sec; 0.337 sec/batch)
2016-12-03 02:47:44.698403: step 4230, loss = 1.09, accu = 0.84, validation: 0.60 (371.0 examples/sec; 0.345 sec/batch)
2016-12-03 02:47:48.224200: step 4240, loss = 1.21, accu = 0.80, validation: 0.62 (387.5 examples/sec; 0.330 sec/batch)
2016-12-03 02:47:51.707858: step 4250, loss = 1.09, accu = 0.84, validation: 0.62 (368.0 examples/sec; 0.348 sec/batch)
2016-12-03 02:47:55.237364: step 4260, loss = 1.10, accu = 0.85, validation: 0.62 (378.4 examples/sec; 0.338 sec/batch)
2016-12-03 02:47:58.792181: step 4270, loss = 1.05, accu = 0.88, validation: 0.66 (381.7 examples/sec; 0.335 sec/batch)
2016-12-03 02:48:02.373665: step 4280, loss = 1.04, accu = 0.88, validation: 0.62 (283.5 examples/sec; 0.452 sec/batch)
2016-12-03 02:48:05.925225: step 4290, loss = 1.19, accu = 0.80, validation: 0.61 (357.1 examples/sec; 0.358 sec/batch)
2016-12-03 02:48:09.356112: step 4300, loss = 1.10, accu = 0.84, validation: 0.67 (381.1 examples/sec; 0.336 sec/batch)
2016-12-03 02:48:13.078303: step 4310, loss = 1.14, accu = 0.81, validation: 0.63 (364.4 examples/sec; 0.351 sec/batch)
2016-12-03 02:48:16.649881: step 4320, loss = 1.13, accu = 0.82, validation: 0.67 (353.5 examples/sec; 0.362 sec/batch)
2016-12-03 02:48:20.015251: step 4330, loss = 1.25, accu = 0.79, validation: 0.69 (376.9 examples/sec; 0.340 sec/batch)
2016-12-03 02:48:23.439042: step 4340, loss = 1.16, accu = 0.83, validation: 0.68 (393.4 examples/sec; 0.325 sec/batch)
2016-12-03 02:48:26.977594: step 4350, loss = 0.99, accu = 0.90, validation: 0.62 (378.2 examples/sec; 0.338 sec/batch)
2016-12-03 02:48:30.520161: step 4360, loss = 0.90, accu = 0.93, validation: 0.63 (380.8 examples/sec; 0.336 sec/batch)
2016-12-03 02:48:33.991221: step 4370, loss = 1.01, accu = 0.85, validation: 0.61 (376.0 examples/sec; 0.340 sec/batch)
2016-12-03 02:48:37.508684: step 4380, loss = 1.06, accu = 0.84, validation: 0.64 (376.4 examples/sec; 0.340 sec/batch)
2016-12-03 02:48:41.052719: step 4390, loss = 1.18, accu = 0.78, validation: 0.65 (393.0 examples/sec; 0.326 sec/batch)
2016-12-03 02:48:44.613293: step 4400, loss = 1.07, accu = 0.81, validation: 0.61 (388.0 examples/sec; 0.330 sec/batch)
2016-12-03 02:48:48.333580: step 4410, loss = 1.22, accu = 0.77, validation: 0.64 (381.9 examples/sec; 0.335 sec/batch)
2016-12-03 02:48:51.914073: step 4420, loss = 1.09, accu = 0.83, validation: 0.58 (382.6 examples/sec; 0.335 sec/batch)
2016-12-03 02:48:55.404278: step 4430, loss = 1.19, accu = 0.77, validation: 0.63 (390.1 examples/sec; 0.328 sec/batch)
2016-12-03 02:48:58.894638: step 4440, loss = 1.04, accu = 0.89, validation: 0.67 (385.9 examples/sec; 0.332 sec/batch)
2016-12-03 02:49:02.509740: step 4450, loss = 1.05, accu = 0.83, validation: 0.63 (368.7 examples/sec; 0.347 sec/batch)
2016-12-03 02:49:05.820950: step 4460, loss = 1.06, accu = 0.81, validation: 0.67 (390.5 examples/sec; 0.328 sec/batch)
2016-12-03 02:49:09.373026: step 4470, loss = 1.00, accu = 0.88, validation: 0.66 (381.2 examples/sec; 0.336 sec/batch)
2016-12-03 02:49:12.848250: step 4480, loss = 1.08, accu = 0.79, validation: 0.69 (378.1 examples/sec; 0.339 sec/batch)
2016-12-03 02:49:16.363539: step 4490, loss = 1.19, accu = 0.80, validation: 0.65 (387.5 examples/sec; 0.330 sec/batch)
2016-12-03 02:49:19.755102: step 4500, loss = 1.03, accu = 0.86, validation: 0.59 (380.5 examples/sec; 0.336 sec/batch)
2016-12-03 02:49:23.370794: step 4510, loss = 1.04, accu = 0.83, validation: 0.62 (370.1 examples/sec; 0.346 sec/batch)
2016-12-03 02:49:26.981071: step 4520, loss = 1.12, accu = 0.85, validation: 0.65 (386.4 examples/sec; 0.331 sec/batch)
2016-12-03 02:49:30.464576: step 4530, loss = 1.04, accu = 0.83, validation: 0.60 (396.5 examples/sec; 0.323 sec/batch)
2016-12-03 02:49:33.963053: step 4540, loss = 0.92, accu = 0.88, validation: 0.66 (382.3 examples/sec; 0.335 sec/batch)
2016-12-03 02:49:37.437408: step 4550, loss = 0.98, accu = 0.82, validation: 0.64 (407.4 examples/sec; 0.314 sec/batch)
2016-12-03 02:49:40.962498: step 4560, loss = 0.97, accu = 0.88, validation: 0.68 (377.9 examples/sec; 0.339 sec/batch)
2016-12-03 02:49:44.476590: step 4570, loss = 1.05, accu = 0.80, validation: 0.72 (382.3 examples/sec; 0.335 sec/batch)
2016-12-03 02:49:47.982438: step 4580, loss = 0.99, accu = 0.88, validation: 0.65 (373.2 examples/sec; 0.343 sec/batch)
2016-12-03 02:49:51.416412: step 4590, loss = 1.04, accu = 0.84, validation: 0.70 (374.3 examples/sec; 0.342 sec/batch)
2016-12-03 02:49:54.913960: step 4600, loss = 0.96, accu = 0.88, validation: 0.65 (379.4 examples/sec; 0.337 sec/batch)
2016-12-03 02:49:58.829443: step 4610, loss = 1.01, accu = 0.82, validation: 0.65 (388.5 examples/sec; 0.329 sec/batch)
2016-12-03 02:50:02.345422: step 4620, loss = 1.03, accu = 0.85, validation: 0.64 (390.0 examples/sec; 0.328 sec/batch)
2016-12-03 02:50:05.914939: step 4630, loss = 0.95, accu = 0.88, validation: 0.66 (396.9 examples/sec; 0.322 sec/batch)
2016-12-03 02:50:09.433421: step 4640, loss = 0.99, accu = 0.84, validation: 0.62 (392.1 examples/sec; 0.326 sec/batch)
2016-12-03 02:50:13.001781: step 4650, loss = 0.94, accu = 0.89, validation: 0.69 (385.3 examples/sec; 0.332 sec/batch)
2016-12-03 02:50:16.505309: step 4660, loss = 0.95, accu = 0.85, validation: 0.65 (286.1 examples/sec; 0.447 sec/batch)
2016-12-03 02:50:20.086391: step 4670, loss = 0.99, accu = 0.88, validation: 0.70 (372.5 examples/sec; 0.344 sec/batch)
2016-12-03 02:50:23.603176: step 4680, loss = 0.91, accu = 0.88, validation: 0.71 (382.4 examples/sec; 0.335 sec/batch)
2016-12-03 02:50:27.062204: step 4690, loss = 0.96, accu = 0.88, validation: 0.71 (389.6 examples/sec; 0.329 sec/batch)
2016-12-03 02:50:30.551538: step 4700, loss = 0.90, accu = 0.90, validation: 0.65 (356.2 examples/sec; 0.359 sec/batch)
2016-12-03 02:50:34.316467: step 4710, loss = 0.94, accu = 0.86, validation: 0.59 (373.5 examples/sec; 0.343 sec/batch)
2016-12-03 02:50:37.985765: step 4720, loss = 1.00, accu = 0.88, validation: 0.62 (370.6 examples/sec; 0.345 sec/batch)
2016-12-03 02:50:41.460550: step 4730, loss = 0.88, accu = 0.90, validation: 0.67 (391.5 examples/sec; 0.327 sec/batch)
2016-12-03 02:50:44.980167: step 4740, loss = 0.94, accu = 0.88, validation: 0.62 (387.7 examples/sec; 0.330 sec/batch)
2016-12-03 02:50:48.534725: step 4750, loss = 1.04, accu = 0.86, validation: 0.63 (360.8 examples/sec; 0.355 sec/batch)
2016-12-03 02:50:52.077189: step 4760, loss = 0.88, accu = 0.92, validation: 0.72 (361.9 examples/sec; 0.354 sec/batch)
2016-12-03 02:50:55.579266: step 4770, loss = 0.93, accu = 0.89, validation: 0.60 (382.3 examples/sec; 0.335 sec/batch)
2016-12-03 02:50:59.130671: step 4780, loss = 1.00, accu = 0.84, validation: 0.73 (303.7 examples/sec; 0.421 sec/batch)
2016-12-03 02:51:02.560908: step 4790, loss = 0.88, accu = 0.91, validation: 0.70 (348.8 examples/sec; 0.367 sec/batch)
2016-12-03 02:51:06.079952: step 4800, loss = 0.86, accu = 0.90, validation: 0.70 (382.7 examples/sec; 0.334 sec/batch)
2016-12-03 02:51:10.081417: step 4810, loss = 0.97, accu = 0.87, validation: 0.71 (368.5 examples/sec; 0.347 sec/batch)
2016-12-03 02:51:13.534423: step 4820, loss = 0.92, accu = 0.85, validation: 0.68 (390.6 examples/sec; 0.328 sec/batch)
2016-12-03 02:51:16.987350: step 4830, loss = 0.92, accu = 0.89, validation: 0.62 (375.4 examples/sec; 0.341 sec/batch)
2016-12-03 02:51:20.604208: step 4840, loss = 0.87, accu = 0.91, validation: 0.64 (305.9 examples/sec; 0.418 sec/batch)
2016-12-03 02:51:24.113982: step 4850, loss = 0.93, accu = 0.91, validation: 0.70 (356.4 examples/sec; 0.359 sec/batch)
2016-12-03 02:51:27.466245: step 4860, loss = 0.81, accu = 0.95, validation: 0.61 (404.0 examples/sec; 0.317 sec/batch)
2016-12-03 02:51:31.173690: step 4870, loss = 0.87, accu = 0.94, validation: 0.62 (338.6 examples/sec; 0.378 sec/batch)
2016-12-03 02:51:34.524960: step 4880, loss = 0.86, accu = 0.90, validation: 0.66 (374.3 examples/sec; 0.342 sec/batch)
2016-12-03 02:51:37.994416: step 4890, loss = 0.95, accu = 0.88, validation: 0.62 (386.6 examples/sec; 0.331 sec/batch)
2016-12-03 02:51:41.495464: step 4900, loss = 0.92, accu = 0.86, validation: 0.68 (375.0 examples/sec; 0.341 sec/batch)
2016-12-03 02:51:45.349196: step 4910, loss = 0.85, accu = 0.91, validation: 0.66 (368.1 examples/sec; 0.348 sec/batch)
2016-12-03 02:51:48.891961: step 4920, loss = 0.89, accu = 0.91, validation: 0.66 (308.5 examples/sec; 0.415 sec/batch)
2016-12-03 02:51:52.404023: step 4930, loss = 0.84, accu = 0.92, validation: 0.64 (340.8 examples/sec; 0.376 sec/batch)
2016-12-03 02:51:55.894726: step 4940, loss = 0.77, accu = 0.96, validation: 0.66 (336.0 examples/sec; 0.381 sec/batch)
2016-12-03 02:51:59.279711: step 4950, loss = 0.79, accu = 0.95, validation: 0.64 (374.5 examples/sec; 0.342 sec/batch)
2016-12-03 02:52:02.871057: step 4960, loss = 0.83, accu = 0.94, validation: 0.70 (323.7 examples/sec; 0.395 sec/batch)
2016-12-03 02:52:06.414257: step 4970, loss = 0.88, accu = 0.89, validation: 0.68 (384.7 examples/sec; 0.333 sec/batch)
2016-12-03 02:52:09.918662: step 4980, loss = 0.85, accu = 0.91, validation: 0.65 (320.6 examples/sec; 0.399 sec/batch)
2016-12-03 02:52:13.297967: step 4990, loss = 0.81, accu = 0.93, validation: 0.62 (379.4 examples/sec; 0.337 sec/batch)
2016-12-03 02:52:16.757025: step 5000, loss = 0.90, accu = 0.86, validation: 0.64 (389.2 examples/sec; 0.329 sec/batch)
2016-12-03 02:52:21.133326: step 5010, loss = 0.83, accu = 0.91, validation: 0.62 (335.6 examples/sec; 0.381 sec/batch)
2016-12-03 02:52:24.630967: step 5020, loss = 0.85, accu = 0.92, validation: 0.64 (374.3 examples/sec; 0.342 sec/batch)
2016-12-03 02:52:28.160335: step 5030, loss = 0.86, accu = 0.91, validation: 0.63 (378.4 examples/sec; 0.338 sec/batch)
2016-12-03 02:52:31.771091: step 5040, loss = 0.82, accu = 0.92, validation: 0.63 (278.8 examples/sec; 0.459 sec/batch)
2016-12-03 02:52:35.299840: step 5050, loss = 0.80, accu = 0.95, validation: 0.70 (375.7 examples/sec; 0.341 sec/batch)
2016-12-03 02:52:38.842131: step 5060, loss = 0.72, accu = 0.96, validation: 0.70 (383.2 examples/sec; 0.334 sec/batch)
2016-12-03 02:52:42.451298: step 5070, loss = 0.89, accu = 0.88, validation: 0.68 (376.8 examples/sec; 0.340 sec/batch)
2016-12-03 02:52:46.032657: step 5080, loss = 0.91, accu = 0.92, validation: 0.66 (383.4 examples/sec; 0.334 sec/batch)
2016-12-03 02:52:49.633830: step 5090, loss = 0.83, accu = 0.94, validation: 0.62 (375.7 examples/sec; 0.341 sec/batch)
2016-12-03 02:52:53.300125: step 5100, loss = 0.76, accu = 0.95, validation: 0.62 (278.2 examples/sec; 0.460 sec/batch)
2016-12-03 02:52:57.028826: step 5110, loss = 0.78, accu = 0.94, validation: 0.67 (360.6 examples/sec; 0.355 sec/batch)
2016-12-03 02:53:00.747081: step 5120, loss = 0.85, accu = 0.91, validation: 0.64 (375.8 examples/sec; 0.341 sec/batch)
2016-12-03 02:53:04.312796: step 5130, loss = 0.76, accu = 0.96, validation: 0.69 (380.7 examples/sec; 0.336 sec/batch)
2016-12-03 02:53:07.986879: step 5140, loss = 0.80, accu = 0.94, validation: 0.70 (367.2 examples/sec; 0.349 sec/batch)
2016-12-03 02:53:11.587460: step 5150, loss = 0.81, accu = 0.94, validation: 0.68 (380.9 examples/sec; 0.336 sec/batch)
2016-12-03 02:53:15.200192: step 5160, loss = 0.82, accu = 0.91, validation: 0.71 (372.9 examples/sec; 0.343 sec/batch)
2016-12-03 02:53:18.836049: step 5170, loss = 0.85, accu = 0.91, validation: 0.61 (361.1 examples/sec; 0.354 sec/batch)
2016-12-03 02:53:22.536398: step 5180, loss = 0.75, accu = 0.94, validation: 0.62 (285.1 examples/sec; 0.449 sec/batch)
2016-12-03 02:53:26.129279: step 5190, loss = 0.82, accu = 0.91, validation: 0.66 (326.4 examples/sec; 0.392 sec/batch)
2016-12-03 02:53:29.795171: step 5200, loss = 0.81, accu = 0.93, validation: 0.65 (283.4 examples/sec; 0.452 sec/batch)
2016-12-03 02:53:33.687198: step 5210, loss = 0.81, accu = 0.93, validation: 0.61 (369.7 examples/sec; 0.346 sec/batch)
2016-12-03 02:53:37.366702: step 5220, loss = 0.85, accu = 0.90, validation: 0.72 (372.2 examples/sec; 0.344 sec/batch)
2016-12-03 02:53:40.917928: step 5230, loss = 0.78, accu = 0.93, validation: 0.63 (384.2 examples/sec; 0.333 sec/batch)
2016-12-03 02:53:44.508226: step 5240, loss = 0.80, accu = 0.95, validation: 0.70 (388.4 examples/sec; 0.330 sec/batch)
2016-12-03 02:53:48.222193: step 5250, loss = 0.78, accu = 0.95, validation: 0.67 (279.0 examples/sec; 0.459 sec/batch)
2016-12-03 02:53:51.805207: step 5260, loss = 0.76, accu = 0.96, validation: 0.69 (385.6 examples/sec; 0.332 sec/batch)
2016-12-03 02:53:55.453495: step 5270, loss = 0.84, accu = 0.92, validation: 0.63 (386.5 examples/sec; 0.331 sec/batch)
2016-12-03 02:53:59.161829: step 5280, loss = 0.90, accu = 0.89, validation: 0.62 (339.2 examples/sec; 0.377 sec/batch)
2016-12-03 02:54:02.713676: step 5290, loss = 0.87, accu = 0.91, validation: 0.65 (377.4 examples/sec; 0.339 sec/batch)
2016-12-03 02:54:06.386718: step 5300, loss = 0.79, accu = 0.91, validation: 0.62 (338.5 examples/sec; 0.378 sec/batch)
2016-12-03 02:54:10.129275: step 5310, loss = 0.77, accu = 0.95, validation: 0.62 (379.9 examples/sec; 0.337 sec/batch)
2016-12-03 02:54:13.627340: step 5320, loss = 0.75, accu = 0.95, validation: 0.60 (375.5 examples/sec; 0.341 sec/batch)
2016-12-03 02:54:17.330178: step 5330, loss = 0.74, accu = 0.96, validation: 0.70 (273.3 examples/sec; 0.468 sec/batch)
2016-12-03 02:54:20.807952: step 5340, loss = 0.82, accu = 0.94, validation: 0.69 (347.8 examples/sec; 0.368 sec/batch)
2016-12-03 02:54:24.462324: step 5350, loss = 0.79, accu = 0.94, validation: 0.73 (339.1 examples/sec; 0.378 sec/batch)
2016-12-03 02:54:28.078212: step 5360, loss = 0.81, accu = 0.95, validation: 0.70 (385.9 examples/sec; 0.332 sec/batch)
2016-12-03 02:54:31.456260: step 5370, loss = 0.77, accu = 0.95, validation: 0.68 (390.3 examples/sec; 0.328 sec/batch)
2016-12-03 02:54:35.071478: step 5380, loss = 0.77, accu = 0.93, validation: 0.66 (375.3 examples/sec; 0.341 sec/batch)
2016-12-03 02:54:38.715157: step 5390, loss = 0.82, accu = 0.91, validation: 0.63 (281.9 examples/sec; 0.454 sec/batch)
2016-12-03 02:54:42.306647: step 5400, loss = 0.79, accu = 0.93, validation: 0.68 (373.9 examples/sec; 0.342 sec/batch)
2016-12-03 02:54:46.318908: step 5410, loss = 0.80, accu = 0.91, validation: 0.70 (354.0 examples/sec; 0.362 sec/batch)
2016-12-03 02:54:49.858067: step 5420, loss = 0.78, accu = 0.93, validation: 0.70 (387.8 examples/sec; 0.330 sec/batch)
2016-12-03 02:54:53.444783: step 5430, loss = 0.84, accu = 0.91, validation: 0.63 (376.0 examples/sec; 0.340 sec/batch)
2016-12-03 02:54:57.150790: step 5440, loss = 0.74, accu = 0.95, validation: 0.65 (379.9 examples/sec; 0.337 sec/batch)
2016-12-03 02:55:00.727584: step 5450, loss = 0.77, accu = 0.92, validation: 0.66 (366.4 examples/sec; 0.349 sec/batch)
2016-12-03 02:55:04.264281: step 5460, loss = 0.78, accu = 0.94, validation: 0.64 (386.6 examples/sec; 0.331 sec/batch)
2016-12-03 02:55:07.916557: step 5470, loss = 0.80, accu = 0.95, validation: 0.69 (386.5 examples/sec; 0.331 sec/batch)
2016-12-03 02:55:11.470983: step 5480, loss = 0.86, accu = 0.89, validation: 0.62 (378.7 examples/sec; 0.338 sec/batch)
2016-12-03 02:55:15.067046: step 5490, loss = 0.77, accu = 0.92, validation: 0.60 (393.5 examples/sec; 0.325 sec/batch)
2016-12-03 02:55:18.616847: step 5500, loss = 0.84, accu = 0.91, validation: 0.62 (373.4 examples/sec; 0.343 sec/batch)
2016-12-03 02:55:22.556534: step 5510, loss = 0.70, accu = 0.95, validation: 0.72 (360.5 examples/sec; 0.355 sec/batch)
2016-12-03 02:55:26.260043: step 5520, loss = 0.81, accu = 0.93, validation: 0.65 (270.2 examples/sec; 0.474 sec/batch)
2016-12-03 02:55:29.793752: step 5530, loss = 0.76, accu = 0.95, validation: 0.70 (379.8 examples/sec; 0.337 sec/batch)
2016-12-03 02:55:33.317762: step 5540, loss = 0.79, accu = 0.93, validation: 0.66 (381.4 examples/sec; 0.336 sec/batch)
2016-12-03 02:55:37.101631: step 5550, loss = 0.77, accu = 0.93, validation: 0.63 (319.7 examples/sec; 0.400 sec/batch)
2016-12-03 02:55:40.660614: step 5560, loss = 0.76, accu = 0.95, validation: 0.65 (323.3 examples/sec; 0.396 sec/batch)
2016-12-03 02:55:44.225762: step 5570, loss = 0.81, accu = 0.92, validation: 0.66 (390.9 examples/sec; 0.327 sec/batch)
2016-12-03 02:55:47.797067: step 5580, loss = 0.71, accu = 0.97, validation: 0.60 (388.8 examples/sec; 0.329 sec/batch)
2016-12-03 02:55:51.348228: step 5590, loss = 0.83, accu = 0.90, validation: 0.62 (387.1 examples/sec; 0.331 sec/batch)
2016-12-03 02:55:54.989596: step 5600, loss = 0.83, accu = 0.92, validation: 0.70 (384.5 examples/sec; 0.333 sec/batch)
2016-12-03 02:55:58.902131: step 5610, loss = 0.76, accu = 0.95, validation: 0.68 (375.5 examples/sec; 0.341 sec/batch)
2016-12-03 02:56:02.497619: step 5620, loss = 0.87, accu = 0.90, validation: 0.68 (337.8 examples/sec; 0.379 sec/batch)
2016-12-03 02:56:06.131570: step 5630, loss = 0.75, accu = 0.95, validation: 0.59 (342.1 examples/sec; 0.374 sec/batch)
2016-12-03 02:56:09.611145: step 5640, loss = 0.84, accu = 0.90, validation: 0.59 (386.8 examples/sec; 0.331 sec/batch)
2016-12-03 02:56:13.278697: step 5650, loss = 0.79, accu = 0.93, validation: 0.66 (380.3 examples/sec; 0.337 sec/batch)
2016-12-03 02:56:16.972338: step 5660, loss = 0.82, accu = 0.93, validation: 0.66 (331.5 examples/sec; 0.386 sec/batch)
2016-12-03 02:56:20.470801: step 5670, loss = 0.77, accu = 0.94, validation: 0.62 (395.0 examples/sec; 0.324 sec/batch)
2016-12-03 02:56:24.168361: step 5680, loss = 0.76, accu = 0.95, validation: 0.69 (386.1 examples/sec; 0.331 sec/batch)
2016-12-03 02:56:27.702933: step 5690, loss = 0.78, accu = 0.91, validation: 0.63 (396.6 examples/sec; 0.323 sec/batch)
2016-12-03 02:56:31.212147: step 5700, loss = 0.69, accu = 0.98, validation: 0.70 (384.2 examples/sec; 0.333 sec/batch)
2016-12-03 02:56:35.118779: step 5710, loss = 0.75, accu = 0.95, validation: 0.73 (348.5 examples/sec; 0.367 sec/batch)
2016-12-03 02:56:38.713543: step 5720, loss = 0.72, accu = 0.94, validation: 0.73 (394.7 examples/sec; 0.324 sec/batch)
2016-12-03 02:56:42.261971: step 5730, loss = 0.72, accu = 0.95, validation: 0.73 (375.2 examples/sec; 0.341 sec/batch)
2016-12-03 02:56:45.889112: step 5740, loss = 0.72, accu = 0.97, validation: 0.61 (268.5 examples/sec; 0.477 sec/batch)
2016-12-03 02:56:49.403875: step 5750, loss = 0.79, accu = 0.92, validation: 0.66 (379.0 examples/sec; 0.338 sec/batch)
2016-12-03 02:56:52.921847: step 5760, loss = 0.72, accu = 0.95, validation: 0.63 (391.4 examples/sec; 0.327 sec/batch)
2016-12-03 02:56:56.593807: step 5770, loss = 0.80, accu = 0.90, validation: 0.72 (377.0 examples/sec; 0.340 sec/batch)
2016-12-03 02:57:00.248533: step 5780, loss = 0.74, accu = 0.95, validation: 0.62 (342.8 examples/sec; 0.373 sec/batch)
2016-12-03 02:57:03.757697: step 5790, loss = 0.79, accu = 0.92, validation: 0.71 (388.6 examples/sec; 0.329 sec/batch)
2016-12-03 02:57:07.309902: step 5800, loss = 0.69, accu = 0.96, validation: 0.66 (378.3 examples/sec; 0.338 sec/batch)
2016-12-03 02:57:11.122128: step 5810, loss = 0.77, accu = 0.93, validation: 0.68 (296.4 examples/sec; 0.432 sec/batch)
2016-12-03 02:57:14.705273: step 5820, loss = 0.79, accu = 0.91, validation: 0.70 (373.6 examples/sec; 0.343 sec/batch)
2016-12-03 02:57:18.224690: step 5830, loss = 0.76, accu = 0.93, validation: 0.70 (383.4 examples/sec; 0.334 sec/batch)
2016-12-03 02:57:21.935786: step 5840, loss = 0.74, accu = 0.94, validation: 0.69 (364.8 examples/sec; 0.351 sec/batch)
2016-12-03 02:57:25.469439: step 5850, loss = 0.78, accu = 0.91, validation: 0.57 (388.9 examples/sec; 0.329 sec/batch)
2016-12-03 02:57:29.119967: step 5860, loss = 0.70, accu = 0.94, validation: 0.69 (284.0 examples/sec; 0.451 sec/batch)
2016-12-03 02:57:32.781686: step 5870, loss = 0.69, accu = 0.96, validation: 0.66 (321.5 examples/sec; 0.398 sec/batch)
2016-12-03 02:57:36.346460: step 5880, loss = 0.71, accu = 0.95, validation: 0.70 (400.8 examples/sec; 0.319 sec/batch)
2016-12-03 02:57:39.934435: step 5890, loss = 0.78, accu = 0.91, validation: 0.59 (392.4 examples/sec; 0.326 sec/batch)
2016-12-03 02:57:43.597791: step 5900, loss = 0.78, accu = 0.93, validation: 0.69 (380.3 examples/sec; 0.337 sec/batch)
2016-12-03 02:57:47.386789: step 5910, loss = 0.71, accu = 0.95, validation: 0.67 (372.6 examples/sec; 0.343 sec/batch)
2016-12-03 02:57:51.059792: step 5920, loss = 0.76, accu = 0.93, validation: 0.70 (360.9 examples/sec; 0.355 sec/batch)
2016-12-03 02:57:54.547180: step 5930, loss = 0.72, accu = 0.94, validation: 0.66 (400.0 examples/sec; 0.320 sec/batch)
2016-12-03 02:57:58.219213: step 5940, loss = 0.71, accu = 0.96, validation: 0.63 (377.6 examples/sec; 0.339 sec/batch)
2016-12-03 02:58:01.735802: step 5950, loss = 0.76, accu = 0.93, validation: 0.62 (376.6 examples/sec; 0.340 sec/batch)
2016-12-03 02:58:05.232043: step 5960, loss = 0.75, accu = 0.95, validation: 0.65 (386.6 examples/sec; 0.331 sec/batch)
2016-12-03 02:58:08.951829: step 5970, loss = 0.80, accu = 0.92, validation: 0.62 (318.0 examples/sec; 0.403 sec/batch)
2016-12-03 02:58:12.453456: step 5980, loss = 0.77, accu = 0.95, validation: 0.64 (373.3 examples/sec; 0.343 sec/batch)
2016-12-03 02:58:16.046926: step 5990, loss = 0.70, accu = 0.96, validation: 0.65 (353.6 examples/sec; 0.362 sec/batch)
2016-12-03 02:58:19.704458: step 6000, loss = 0.72, accu = 0.97, validation: 0.63 (280.4 examples/sec; 0.456 sec/batch)
2016-12-03 02:58:23.986350: step 6010, loss = 0.77, accu = 0.91, validation: 0.65 (377.0 examples/sec; 0.340 sec/batch)
2016-12-03 02:58:27.482803: step 6020, loss = 0.73, accu = 0.93, validation: 0.65 (376.2 examples/sec; 0.340 sec/batch)
2016-12-03 02:58:31.102965: step 6030, loss = 0.73, accu = 0.92, validation: 0.69 (382.7 examples/sec; 0.335 sec/batch)
2016-12-03 02:58:34.923044: step 6040, loss = 0.73, accu = 0.95, validation: 0.64 (373.7 examples/sec; 0.343 sec/batch)
2016-12-03 02:58:38.527307: step 6050, loss = 0.72, accu = 0.91, validation: 0.61 (383.4 examples/sec; 0.334 sec/batch)
2016-12-03 02:58:42.302568: step 6060, loss = 0.79, accu = 0.90, validation: 0.70 (318.2 examples/sec; 0.402 sec/batch)
2016-12-03 02:58:45.904497: step 6070, loss = 0.70, accu = 0.96, validation: 0.63 (370.8 examples/sec; 0.345 sec/batch)
2016-12-03 02:58:49.513659: step 6080, loss = 0.76, accu = 0.92, validation: 0.71 (337.7 examples/sec; 0.379 sec/batch)
2016-12-03 02:58:53.130527: step 6090, loss = 0.66, accu = 0.98, validation: 0.63 (391.8 examples/sec; 0.327 sec/batch)
2016-12-03 02:58:56.877454: step 6100, loss = 0.75, accu = 0.91, validation: 0.62 (359.3 examples/sec; 0.356 sec/batch)
2016-12-03 02:59:00.565477: step 6110, loss = 0.66, accu = 0.98, validation: 0.66 (392.6 examples/sec; 0.326 sec/batch)
2016-12-03 02:59:04.318184: step 6120, loss = 0.73, accu = 0.95, validation: 0.66 (375.9 examples/sec; 0.341 sec/batch)
2016-12-03 02:59:08.022592: step 6130, loss = 0.72, accu = 0.93, validation: 0.62 (279.1 examples/sec; 0.459 sec/batch)
2016-12-03 02:59:11.580680: step 6140, loss = 0.70, accu = 0.95, validation: 0.72 (379.6 examples/sec; 0.337 sec/batch)
2016-12-03 02:59:15.268817: step 6150, loss = 0.67, accu = 0.98, validation: 0.66 (382.0 examples/sec; 0.335 sec/batch)
2016-12-03 02:59:18.824463: step 6160, loss = 0.75, accu = 0.95, validation: 0.67 (382.6 examples/sec; 0.335 sec/batch)
2016-12-03 02:59:22.494785: step 6170, loss = 0.79, accu = 0.92, validation: 0.70 (320.6 examples/sec; 0.399 sec/batch)
2016-12-03 02:59:26.081315: step 6180, loss = 0.70, accu = 0.96, validation: 0.73 (381.5 examples/sec; 0.336 sec/batch)
2016-12-03 02:59:29.762944: step 6190, loss = 0.67, accu = 0.97, validation: 0.66 (268.2 examples/sec; 0.477 sec/batch)
2016-12-03 02:59:33.343737: step 6200, loss = 0.68, accu = 0.96, validation: 0.66 (386.5 examples/sec; 0.331 sec/batch)
2016-12-03 02:59:37.277785: step 6210, loss = 0.72, accu = 0.94, validation: 0.60 (359.4 examples/sec; 0.356 sec/batch)
2016-12-03 02:59:41.034112: step 6220, loss = 0.72, accu = 0.95, validation: 0.66 (387.7 examples/sec; 0.330 sec/batch)
2016-12-03 02:59:44.548769: step 6230, loss = 0.72, accu = 0.93, validation: 0.64 (388.2 examples/sec; 0.330 sec/batch)
2016-12-03 02:59:48.197416: step 6240, loss = 0.74, accu = 0.93, validation: 0.65 (394.0 examples/sec; 0.325 sec/batch)
2016-12-03 02:59:51.912854: step 6250, loss = 0.67, accu = 0.97, validation: 0.73 (377.7 examples/sec; 0.339 sec/batch)
2016-12-03 02:59:55.505459: step 6260, loss = 0.69, accu = 0.95, validation: 0.58 (369.9 examples/sec; 0.346 sec/batch)
2016-12-03 02:59:59.223188: step 6270, loss = 0.77, accu = 0.93, validation: 0.69 (378.8 examples/sec; 0.338 sec/batch)
2016-12-03 03:00:02.830390: step 6280, loss = 0.70, accu = 0.95, validation: 0.70 (379.0 examples/sec; 0.338 sec/batch)
2016-12-03 03:00:06.531121: step 6290, loss = 0.76, accu = 0.91, validation: 0.70 (363.9 examples/sec; 0.352 sec/batch)
2016-12-03 03:00:09.963961: step 6300, loss = 0.69, accu = 0.95, validation: 0.68 (388.4 examples/sec; 0.330 sec/batch)
2016-12-03 03:00:13.791525: step 6310, loss = 0.71, accu = 0.95, validation: 0.62 (372.0 examples/sec; 0.344 sec/batch)
2016-12-03 03:00:17.343346: step 6320, loss = 0.66, accu = 0.98, validation: 0.62 (385.6 examples/sec; 0.332 sec/batch)
2016-12-03 03:00:21.053636: step 6330, loss = 0.69, accu = 0.96, validation: 0.66 (394.3 examples/sec; 0.325 sec/batch)
2016-12-03 03:00:24.715891: step 6340, loss = 0.77, accu = 0.94, validation: 0.64 (339.7 examples/sec; 0.377 sec/batch)
2016-12-03 03:00:28.431854: step 6350, loss = 0.71, accu = 0.95, validation: 0.61 (357.6 examples/sec; 0.358 sec/batch)
2016-12-03 03:00:31.981236: step 6360, loss = 0.67, accu = 0.96, validation: 0.68 (380.4 examples/sec; 0.336 sec/batch)
2016-12-03 03:00:35.490713: step 6370, loss = 0.66, accu = 0.97, validation: 0.66 (381.5 examples/sec; 0.335 sec/batch)
2016-12-03 03:00:39.153467: step 6380, loss = 0.66, accu = 0.95, validation: 0.67 (376.1 examples/sec; 0.340 sec/batch)
2016-12-03 03:00:42.836486: step 6390, loss = 0.73, accu = 0.95, validation: 0.63 (388.0 examples/sec; 0.330 sec/batch)
2016-12-03 03:00:46.428532: step 6400, loss = 0.66, accu = 0.96, validation: 0.65 (291.1 examples/sec; 0.440 sec/batch)
2016-12-03 03:00:50.313689: step 6410, loss = 0.71, accu = 0.93, validation: 0.66 (387.2 examples/sec; 0.331 sec/batch)
2016-12-03 03:00:54.022629: step 6420, loss = 0.68, accu = 0.96, validation: 0.62 (375.1 examples/sec; 0.341 sec/batch)
2016-12-03 03:00:57.480320: step 6430, loss = 0.66, accu = 0.98, validation: 0.67 (392.8 examples/sec; 0.326 sec/batch)
2016-12-03 03:01:00.982790: step 6440, loss = 0.71, accu = 0.93, validation: 0.65 (376.6 examples/sec; 0.340 sec/batch)
2016-12-03 03:01:04.681935: step 6450, loss = 0.70, accu = 0.96, validation: 0.64 (382.4 examples/sec; 0.335 sec/batch)
2016-12-03 03:01:08.347082: step 6460, loss = 0.71, accu = 0.93, validation: 0.68 (388.1 examples/sec; 0.330 sec/batch)
2016-12-03 03:01:11.976232: step 6470, loss = 0.66, accu = 0.97, validation: 0.66 (340.1 examples/sec; 0.376 sec/batch)
2016-12-03 03:01:15.442778: step 6480, loss = 0.64, accu = 0.97, validation: 0.62 (391.0 examples/sec; 0.327 sec/batch)
2016-12-03 03:01:19.017742: step 6490, loss = 0.68, accu = 0.96, validation: 0.66 (341.8 examples/sec; 0.375 sec/batch)
2016-12-03 03:01:22.794326: step 6500, loss = 0.72, accu = 0.95, validation: 0.73 (273.7 examples/sec; 0.468 sec/batch)
2016-12-03 03:01:26.593263: step 6510, loss = 0.64, accu = 0.98, validation: 0.66 (376.2 examples/sec; 0.340 sec/batch)
2016-12-03 03:01:30.257573: step 6520, loss = 0.68, accu = 0.95, validation: 0.65 (340.5 examples/sec; 0.376 sec/batch)
2016-12-03 03:01:33.768318: step 6530, loss = 0.71, accu = 0.94, validation: 0.61 (372.1 examples/sec; 0.344 sec/batch)
2016-12-03 03:01:37.381696: step 6540, loss = 0.66, accu = 0.96, validation: 0.67 (398.0 examples/sec; 0.322 sec/batch)
2016-12-03 03:01:40.922885: step 6550, loss = 0.67, accu = 0.95, validation: 0.65 (376.0 examples/sec; 0.340 sec/batch)
2016-12-03 03:01:44.538793: step 6560, loss = 0.64, accu = 0.97, validation: 0.66 (385.5 examples/sec; 0.332 sec/batch)
2016-12-03 03:01:48.201717: step 6570, loss = 0.66, accu = 0.96, validation: 0.65 (288.6 examples/sec; 0.444 sec/batch)
2016-12-03 03:01:51.653462: step 6580, loss = 0.63, accu = 0.97, validation: 0.63 (389.7 examples/sec; 0.328 sec/batch)
2016-12-03 03:01:55.425674: step 6590, loss = 0.69, accu = 0.95, validation: 0.61 (370.7 examples/sec; 0.345 sec/batch)
2016-12-03 03:01:59.088701: step 6600, loss = 0.68, accu = 0.95, validation: 0.63 (381.8 examples/sec; 0.335 sec/batch)
2016-12-03 03:02:03.047173: step 6610, loss = 0.73, accu = 0.95, validation: 0.62 (389.7 examples/sec; 0.328 sec/batch)
2016-12-03 03:02:06.617934: step 6620, loss = 0.69, accu = 0.96, validation: 0.67 (386.0 examples/sec; 0.332 sec/batch)
2016-12-03 03:02:10.147961: step 6630, loss = 0.68, accu = 0.95, validation: 0.65 (381.3 examples/sec; 0.336 sec/batch)
2016-12-03 03:02:13.936172: step 6640, loss = 0.64, accu = 0.96, validation: 0.68 (380.8 examples/sec; 0.336 sec/batch)
2016-12-03 03:02:17.506256: step 6650, loss = 0.61, accu = 0.98, validation: 0.66 (371.6 examples/sec; 0.344 sec/batch)
2016-12-03 03:02:21.206394: step 6660, loss = 0.66, accu = 0.96, validation: 0.66 (381.2 examples/sec; 0.336 sec/batch)
2016-12-03 03:02:24.724464: step 6670, loss = 0.71, accu = 0.95, validation: 0.66 (377.4 examples/sec; 0.339 sec/batch)
2016-12-03 03:02:28.282484: step 6680, loss = 0.65, accu = 0.97, validation: 0.70 (383.2 examples/sec; 0.334 sec/batch)
2016-12-03 03:02:31.799351: step 6690, loss = 0.61, accu = 0.97, validation: 0.64 (392.6 examples/sec; 0.326 sec/batch)
2016-12-03 03:02:35.368757: step 6700, loss = 0.67, accu = 0.96, validation: 0.62 (380.8 examples/sec; 0.336 sec/batch)
2016-12-03 03:02:39.350209: step 6710, loss = 0.64, accu = 0.98, validation: 0.70 (349.8 examples/sec; 0.366 sec/batch)
2016-12-03 03:02:43.043508: step 6720, loss = 0.66, accu = 0.95, validation: 0.61 (282.4 examples/sec; 0.453 sec/batch)
2016-12-03 03:02:46.634607: step 6730, loss = 0.70, accu = 0.94, validation: 0.71 (381.8 examples/sec; 0.335 sec/batch)
2016-12-03 03:02:50.331096: step 6740, loss = 0.66, accu = 0.94, validation: 0.73 (364.7 examples/sec; 0.351 sec/batch)
2016-12-03 03:02:53.989325: step 6750, loss = 0.73, accu = 0.92, validation: 0.67 (341.4 examples/sec; 0.375 sec/batch)
2016-12-03 03:02:57.649755: step 6760, loss = 0.67, accu = 0.94, validation: 0.70 (276.4 examples/sec; 0.463 sec/batch)
2016-12-03 03:03:01.241323: step 6770, loss = 0.63, accu = 0.97, validation: 0.62 (375.0 examples/sec; 0.341 sec/batch)
2016-12-03 03:03:04.798874: step 6780, loss = 0.58, accu = 1.00, validation: 0.60 (399.6 examples/sec; 0.320 sec/batch)
2016-12-03 03:03:08.344157: step 6790, loss = 0.64, accu = 0.98, validation: 0.73 (364.5 examples/sec; 0.351 sec/batch)
2016-12-03 03:03:12.124080: step 6800, loss = 0.66, accu = 0.95, validation: 0.68 (332.9 examples/sec; 0.385 sec/batch)
2016-12-03 03:03:15.995418: step 6810, loss = 0.66, accu = 0.96, validation: 0.63 (296.3 examples/sec; 0.432 sec/batch)
2016-12-03 03:03:19.540467: step 6820, loss = 0.73, accu = 0.92, validation: 0.73 (381.4 examples/sec; 0.336 sec/batch)
2016-12-03 03:03:23.247545: step 6830, loss = 0.60, accu = 0.98, validation: 0.65 (341.4 examples/sec; 0.375 sec/batch)
2016-12-03 03:03:26.805477: step 6840, loss = 0.66, accu = 0.95, validation: 0.67 (387.6 examples/sec; 0.330 sec/batch)
2016-12-03 03:03:30.389398: step 6850, loss = 0.67, accu = 0.96, validation: 0.69 (377.2 examples/sec; 0.339 sec/batch)
2016-12-03 03:03:34.019949: step 6860, loss = 0.66, accu = 0.95, validation: 0.68 (400.0 examples/sec; 0.320 sec/batch)
2016-12-03 03:03:37.571174: step 6870, loss = 0.64, accu = 0.96, validation: 0.62 (379.0 examples/sec; 0.338 sec/batch)
2016-12-03 03:03:41.367254: step 6880, loss = 0.73, accu = 0.93, validation: 0.68 (388.3 examples/sec; 0.330 sec/batch)
2016-12-03 03:03:45.052935: step 6890, loss = 0.64, accu = 0.97, validation: 0.66 (285.4 examples/sec; 0.449 sec/batch)
2016-12-03 03:03:48.628607: step 6900, loss = 0.63, accu = 0.98, validation: 0.67 (379.3 examples/sec; 0.337 sec/batch)
2016-12-03 03:03:52.653730: step 6910, loss = 0.65, accu = 0.98, validation: 0.66 (382.6 examples/sec; 0.335 sec/batch)
2016-12-03 03:03:56.347798: step 6920, loss = 0.64, accu = 0.96, validation: 0.59 (333.4 examples/sec; 0.384 sec/batch)
2016-12-03 03:03:59.987272: step 6930, loss = 0.61, accu = 0.97, validation: 0.66 (379.2 examples/sec; 0.338 sec/batch)
2016-12-03 03:04:03.636340: step 6940, loss = 0.64, accu = 0.97, validation: 0.66 (298.4 examples/sec; 0.429 sec/batch)
2016-12-03 03:04:07.138513: step 6950, loss = 0.63, accu = 0.98, validation: 0.60 (390.9 examples/sec; 0.327 sec/batch)
2016-12-03 03:04:10.636039: step 6960, loss = 0.63, accu = 0.98, validation: 0.65 (386.8 examples/sec; 0.331 sec/batch)
2016-12-03 03:04:14.322727: step 6970, loss = 0.69, accu = 0.93, validation: 0.65 (283.5 examples/sec; 0.451 sec/batch)
2016-12-03 03:04:17.934021: step 6980, loss = 0.63, accu = 0.98, validation: 0.65 (381.5 examples/sec; 0.335 sec/batch)
2016-12-03 03:04:21.620327: step 6990, loss = 0.63, accu = 0.97, validation: 0.65 (357.1 examples/sec; 0.358 sec/batch)
2016-12-03 03:04:25.228659: step 7000, loss = 0.62, accu = 0.98, validation: 0.68 (384.6 examples/sec; 0.333 sec/batch)
2016-12-03 03:04:29.760392: step 7010, loss = 0.67, accu = 0.95, validation: 0.63 (358.3 examples/sec; 0.357 sec/batch)
2016-12-03 03:04:33.357550: step 7020, loss = 0.62, accu = 0.96, validation: 0.66 (286.4 examples/sec; 0.447 sec/batch)
2016-12-03 03:04:36.959497: step 7030, loss = 0.63, accu = 0.96, validation: 0.67 (381.9 examples/sec; 0.335 sec/batch)
2016-12-03 03:04:40.745775: step 7040, loss = 0.66, accu = 0.95, validation: 0.67 (322.5 examples/sec; 0.397 sec/batch)
2016-12-03 03:04:44.333013: step 7050, loss = 0.61, accu = 0.97, validation: 0.65 (385.1 examples/sec; 0.332 sec/batch)
2016-12-03 03:04:48.054952: step 7060, loss = 0.67, accu = 0.96, validation: 0.66 (332.4 examples/sec; 0.385 sec/batch)
2016-12-03 03:04:51.657869: step 7070, loss = 0.59, accu = 0.99, validation: 0.67 (272.1 examples/sec; 0.470 sec/batch)
2016-12-03 03:04:55.396305: step 7080, loss = 0.67, accu = 0.96, validation: 0.62 (303.2 examples/sec; 0.422 sec/batch)
2016-12-03 03:04:58.915864: step 7090, loss = 0.66, accu = 0.95, validation: 0.66 (391.8 examples/sec; 0.327 sec/batch)
2016-12-03 03:05:02.415215: step 7100, loss = 0.61, accu = 0.96, validation: 0.68 (384.8 examples/sec; 0.333 sec/batch)
2016-12-03 03:05:06.330020: step 7110, loss = 0.61, accu = 0.98, validation: 0.70 (383.9 examples/sec; 0.333 sec/batch)
2016-12-03 03:05:09.919001: step 7120, loss = 0.61, accu = 0.97, validation: 0.65 (319.5 examples/sec; 0.401 sec/batch)
2016-12-03 03:05:13.526813: step 7130, loss = 0.67, accu = 0.95, validation: 0.62 (344.1 examples/sec; 0.372 sec/batch)
2016-12-03 03:05:17.206785: step 7140, loss = 0.60, accu = 0.98, validation: 0.63 (376.6 examples/sec; 0.340 sec/batch)
2016-12-03 03:05:20.702348: step 7150, loss = 0.67, accu = 0.95, validation: 0.66 (378.6 examples/sec; 0.338 sec/batch)
2016-12-03 03:05:24.377054: step 7160, loss = 0.65, accu = 0.97, validation: 0.63 (383.5 examples/sec; 0.334 sec/batch)
2016-12-03 03:05:28.051802: step 7170, loss = 0.63, accu = 0.95, validation: 0.65 (361.0 examples/sec; 0.355 sec/batch)
2016-12-03 03:05:31.687850: step 7180, loss = 0.63, accu = 0.96, validation: 0.62 (389.0 examples/sec; 0.329 sec/batch)
2016-12-03 03:05:35.309699: step 7190, loss = 0.63, accu = 0.97, validation: 0.64 (350.1 examples/sec; 0.366 sec/batch)
2016-12-03 03:05:38.895237: step 7200, loss = 0.67, accu = 0.93, validation: 0.77 (387.6 examples/sec; 0.330 sec/batch)
2016-12-03 03:05:42.935104: step 7210, loss = 0.66, accu = 0.94, validation: 0.72 (285.6 examples/sec; 0.448 sec/batch)
2016-12-03 03:05:46.626943: step 7220, loss = 0.68, accu = 0.94, validation: 0.70 (350.6 examples/sec; 0.365 sec/batch)
2016-12-03 03:05:50.223880: step 7230, loss = 0.63, accu = 0.98, validation: 0.68 (381.7 examples/sec; 0.335 sec/batch)
2016-12-03 03:05:53.803334: step 7240, loss = 0.61, accu = 0.96, validation: 0.59 (365.7 examples/sec; 0.350 sec/batch)
2016-12-03 03:05:57.485527: step 7250, loss = 0.62, accu = 0.96, validation: 0.67 (379.5 examples/sec; 0.337 sec/batch)
2016-12-03 03:06:01.118986: step 7260, loss = 0.62, accu = 0.98, validation: 0.66 (373.4 examples/sec; 0.343 sec/batch)
2016-12-03 03:06:04.669621: step 7270, loss = 0.66, accu = 0.95, validation: 0.66 (377.0 examples/sec; 0.339 sec/batch)
2016-12-03 03:06:08.282239: step 7280, loss = 0.63, accu = 0.96, validation: 0.78 (377.1 examples/sec; 0.339 sec/batch)
2016-12-03 03:06:11.942936: step 7290, loss = 0.68, accu = 0.94, validation: 0.59 (291.9 examples/sec; 0.438 sec/batch)
2016-12-03 03:06:15.546604: step 7300, loss = 0.62, accu = 0.95, validation: 0.64 (377.3 examples/sec; 0.339 sec/batch)
2016-12-03 03:06:19.273468: step 7310, loss = 0.66, accu = 0.95, validation: 0.73 (382.6 examples/sec; 0.335 sec/batch)
2016-12-03 03:06:22.905104: step 7320, loss = 0.66, accu = 0.95, validation: 0.72 (365.7 examples/sec; 0.350 sec/batch)
2016-12-03 03:06:26.478181: step 7330, loss = 0.64, accu = 0.95, validation: 0.70 (295.2 examples/sec; 0.434 sec/batch)
2016-12-03 03:06:29.990492: step 7340, loss = 0.64, accu = 0.95, validation: 0.64 (391.3 examples/sec; 0.327 sec/batch)
2016-12-03 03:06:33.488546: step 7350, loss = 0.61, accu = 0.95, validation: 0.62 (401.3 examples/sec; 0.319 sec/batch)
2016-12-03 03:06:37.192214: step 7360, loss = 0.67, accu = 0.96, validation: 0.70 (393.2 examples/sec; 0.326 sec/batch)
2016-12-03 03:06:40.790140: step 7370, loss = 0.60, accu = 0.98, validation: 0.61 (343.5 examples/sec; 0.373 sec/batch)
2016-12-03 03:06:44.315438: step 7380, loss = 0.66, accu = 0.95, validation: 0.59 (384.9 examples/sec; 0.333 sec/batch)
2016-12-03 03:06:47.774671: step 7390, loss = 0.57, accu = 0.98, validation: 0.69 (383.3 examples/sec; 0.334 sec/batch)
2016-12-03 03:06:51.328110: step 7400, loss = 0.61, accu = 0.96, validation: 0.67 (365.3 examples/sec; 0.350 sec/batch)
2016-12-03 03:06:55.050697: step 7410, loss = 0.60, accu = 0.98, validation: 0.67 (371.2 examples/sec; 0.345 sec/batch)
2016-12-03 03:06:58.658450: step 7420, loss = 0.62, accu = 0.97, validation: 0.66 (385.2 examples/sec; 0.332 sec/batch)
2016-12-03 03:07:02.195825: step 7430, loss = 0.69, accu = 0.91, validation: 0.67 (396.9 examples/sec; 0.322 sec/batch)
2016-12-03 03:07:05.738108: step 7440, loss = 0.62, accu = 0.98, validation: 0.67 (378.7 examples/sec; 0.338 sec/batch)
2016-12-03 03:07:09.296626: step 7450, loss = 0.69, accu = 0.92, validation: 0.65 (385.7 examples/sec; 0.332 sec/batch)
2016-12-03 03:07:13.016437: step 7460, loss = 0.65, accu = 0.96, validation: 0.63 (373.8 examples/sec; 0.342 sec/batch)
2016-12-03 03:07:16.471916: step 7470, loss = 0.63, accu = 0.94, validation: 0.66 (388.1 examples/sec; 0.330 sec/batch)
2016-12-03 03:07:20.020682: step 7480, loss = 0.61, accu = 0.98, validation: 0.69 (388.9 examples/sec; 0.329 sec/batch)
2016-12-03 03:07:23.648036: step 7490, loss = 0.69, accu = 0.94, validation: 0.66 (402.6 examples/sec; 0.318 sec/batch)
2016-12-03 03:07:27.140002: step 7500, loss = 0.60, accu = 0.97, validation: 0.63 (386.0 examples/sec; 0.332 sec/batch)
2016-12-03 03:07:31.040054: step 7510, loss = 0.60, accu = 0.98, validation: 0.65 (378.3 examples/sec; 0.338 sec/batch)
2016-12-03 03:07:34.504458: step 7520, loss = 0.62, accu = 0.98, validation: 0.62 (384.4 examples/sec; 0.333 sec/batch)
2016-12-03 03:07:38.061375: step 7530, loss = 0.60, accu = 0.98, validation: 0.62 (387.0 examples/sec; 0.331 sec/batch)
2016-12-03 03:07:41.696260: step 7540, loss = 0.65, accu = 0.95, validation: 0.61 (285.3 examples/sec; 0.449 sec/batch)
2016-12-03 03:07:45.258486: step 7550, loss = 0.59, accu = 0.98, validation: 0.67 (376.8 examples/sec; 0.340 sec/batch)
2016-12-03 03:07:48.904741: step 7560, loss = 0.59, accu = 0.97, validation: 0.66 (385.9 examples/sec; 0.332 sec/batch)
2016-12-03 03:07:52.387399: step 7570, loss = 0.60, accu = 0.98, validation: 0.73 (376.1 examples/sec; 0.340 sec/batch)
2016-12-03 03:07:55.984350: step 7580, loss = 0.60, accu = 0.97, validation: 0.64 (360.9 examples/sec; 0.355 sec/batch)
2016-12-03 03:07:59.488688: step 7590, loss = 0.57, accu = 0.99, validation: 0.67 (281.6 examples/sec; 0.454 sec/batch)
2016-12-03 03:08:03.128982: step 7600, loss = 0.62, accu = 0.96, validation: 0.62 (394.2 examples/sec; 0.325 sec/batch)
2016-12-03 03:08:07.102282: step 7610, loss = 0.59, accu = 0.98, validation: 0.67 (385.2 examples/sec; 0.332 sec/batch)
2016-12-03 03:08:10.509395: step 7620, loss = 0.59, accu = 0.97, validation: 0.62 (380.7 examples/sec; 0.336 sec/batch)
2016-12-03 03:08:14.146365: step 7630, loss = 0.56, accu = 0.98, validation: 0.67 (392.3 examples/sec; 0.326 sec/batch)
2016-12-03 03:08:17.869860: step 7640, loss = 0.60, accu = 0.98, validation: 0.61 (355.2 examples/sec; 0.360 sec/batch)
2016-12-03 03:08:21.393228: step 7650, loss = 0.63, accu = 0.97, validation: 0.63 (270.7 examples/sec; 0.473 sec/batch)
2016-12-03 03:08:24.884831: step 7660, loss = 0.62, accu = 0.96, validation: 0.69 (397.4 examples/sec; 0.322 sec/batch)
2016-12-03 03:08:28.405793: step 7670, loss = 0.61, accu = 0.97, validation: 0.69 (368.3 examples/sec; 0.348 sec/batch)
2016-12-03 03:08:31.977522: step 7680, loss = 0.61, accu = 0.96, validation: 0.71 (394.8 examples/sec; 0.324 sec/batch)
2016-12-03 03:08:35.632495: step 7690, loss = 0.62, accu = 0.97, validation: 0.68 (322.9 examples/sec; 0.396 sec/batch)
2016-12-03 03:08:39.177943: step 7700, loss = 0.57, accu = 0.98, validation: 0.64 (331.9 examples/sec; 0.386 sec/batch)
2016-12-03 03:08:42.992520: step 7710, loss = 0.55, accu = 0.99, validation: 0.64 (376.4 examples/sec; 0.340 sec/batch)
2016-12-03 03:08:46.469724: step 7720, loss = 0.58, accu = 0.97, validation: 0.66 (385.1 examples/sec; 0.332 sec/batch)
2016-12-03 03:08:50.149801: step 7730, loss = 0.63, accu = 0.96, validation: 0.58 (343.2 examples/sec; 0.373 sec/batch)
2016-12-03 03:08:53.678045: step 7740, loss = 0.61, accu = 0.98, validation: 0.76 (377.9 examples/sec; 0.339 sec/batch)
2016-12-03 03:08:57.220734: step 7750, loss = 0.56, accu = 0.99, validation: 0.65 (403.4 examples/sec; 0.317 sec/batch)
2016-12-03 03:09:00.759595: step 7760, loss = 0.61, accu = 0.96, validation: 0.69 (396.0 examples/sec; 0.323 sec/batch)
2016-12-03 03:09:04.255827: step 7770, loss = 0.60, accu = 0.98, validation: 0.73 (330.2 examples/sec; 0.388 sec/batch)
2016-12-03 03:09:07.898318: step 7780, loss = 0.69, accu = 0.95, validation: 0.70 (395.0 examples/sec; 0.324 sec/batch)
2016-12-03 03:09:11.442018: step 7790, loss = 0.58, accu = 0.98, validation: 0.66 (336.1 examples/sec; 0.381 sec/batch)
2016-12-03 03:09:14.946528: step 7800, loss = 0.57, accu = 0.98, validation: 0.65 (390.6 examples/sec; 0.328 sec/batch)
2016-12-03 03:09:18.720704: step 7810, loss = 0.68, accu = 0.95, validation: 0.67 (371.8 examples/sec; 0.344 sec/batch)
2016-12-03 03:09:22.281687: step 7820, loss = 0.58, accu = 0.99, validation: 0.70 (370.9 examples/sec; 0.345 sec/batch)
2016-12-03 03:09:25.885860: step 7830, loss = 0.60, accu = 0.98, validation: 0.65 (362.0 examples/sec; 0.354 sec/batch)
2016-12-03 03:09:29.411827: step 7840, loss = 0.63, accu = 0.96, validation: 0.62 (392.8 examples/sec; 0.326 sec/batch)
2016-12-03 03:09:33.066015: step 7850, loss = 0.61, accu = 0.95, validation: 0.73 (357.0 examples/sec; 0.359 sec/batch)
2016-12-03 03:09:36.588461: step 7860, loss = 0.57, accu = 0.99, validation: 0.66 (375.4 examples/sec; 0.341 sec/batch)
2016-12-03 03:09:40.234457: step 7870, loss = 0.60, accu = 0.98, validation: 0.70 (310.3 examples/sec; 0.412 sec/batch)
2016-12-03 03:09:43.768193: step 7880, loss = 0.57, accu = 0.98, validation: 0.72 (344.9 examples/sec; 0.371 sec/batch)
2016-12-03 03:09:47.469178: step 7890, loss = 0.57, accu = 0.98, validation: 0.68 (377.7 examples/sec; 0.339 sec/batch)
2016-12-03 03:09:50.992894: step 7900, loss = 0.61, accu = 0.97, validation: 0.68 (379.0 examples/sec; 0.338 sec/batch)
2016-12-03 03:09:54.894094: step 7910, loss = 0.57, accu = 0.98, validation: 0.61 (390.6 examples/sec; 0.328 sec/batch)
2016-12-03 03:09:58.429082: step 7920, loss = 0.59, accu = 0.97, validation: 0.64 (384.5 examples/sec; 0.333 sec/batch)
2016-12-03 03:10:02.094624: step 7930, loss = 0.60, accu = 0.95, validation: 0.64 (375.7 examples/sec; 0.341 sec/batch)
2016-12-03 03:10:05.624599: step 7940, loss = 0.62, accu = 0.97, validation: 0.69 (296.3 examples/sec; 0.432 sec/batch)
2016-12-03 03:10:09.062164: step 7950, loss = 0.61, accu = 0.96, validation: 0.62 (383.5 examples/sec; 0.334 sec/batch)
2016-12-03 03:10:12.729200: step 7960, loss = 0.58, accu = 0.97, validation: 0.69 (380.0 examples/sec; 0.337 sec/batch)
2016-12-03 03:10:16.385420: step 7970, loss = 0.57, accu = 0.98, validation: 0.65 (375.5 examples/sec; 0.341 sec/batch)
2016-12-03 03:10:19.925858: step 7980, loss = 0.56, accu = 0.98, validation: 0.63 (388.4 examples/sec; 0.330 sec/batch)
2016-12-03 03:10:23.493182: step 7990, loss = 0.55, accu = 0.99, validation: 0.66 (375.1 examples/sec; 0.341 sec/batch)
2016-12-03 03:10:27.029468: step 8000, loss = 0.54, accu = 0.99, validation: 0.63 (400.1 examples/sec; 0.320 sec/batch)
2016-12-03 03:10:31.324449: step 8010, loss = 0.63, accu = 0.95, validation: 0.61 (319.9 examples/sec; 0.400 sec/batch)
2016-12-03 03:10:34.836511: step 8020, loss = 0.60, accu = 0.95, validation: 0.62 (393.4 examples/sec; 0.325 sec/batch)
2016-12-03 03:10:38.601471: step 8030, loss = 0.58, accu = 0.98, validation: 0.68 (370.6 examples/sec; 0.345 sec/batch)
2016-12-03 03:10:42.097238: step 8040, loss = 0.63, accu = 0.96, validation: 0.66 (355.0 examples/sec; 0.361 sec/batch)
2016-12-03 03:10:45.642827: step 8050, loss = 0.56, accu = 0.97, validation: 0.62 (386.0 examples/sec; 0.332 sec/batch)
2016-12-03 03:10:49.283397: step 8060, loss = 0.58, accu = 0.98, validation: 0.62 (386.7 examples/sec; 0.331 sec/batch)
2016-12-03 03:10:52.785856: step 8070, loss = 0.64, accu = 0.96, validation: 0.65 (380.5 examples/sec; 0.336 sec/batch)
2016-12-03 03:10:56.441204: step 8080, loss = 0.56, accu = 0.97, validation: 0.66 (284.0 examples/sec; 0.451 sec/batch)
2016-12-03 03:11:00.005189: step 8090, loss = 0.55, accu = 0.98, validation: 0.67 (400.4 examples/sec; 0.320 sec/batch)
2016-12-03 03:11:03.531418: step 8100, loss = 0.56, accu = 0.99, validation: 0.63 (362.3 examples/sec; 0.353 sec/batch)
2016-12-03 03:11:07.410588: step 8110, loss = 0.59, accu = 0.95, validation: 0.62 (366.3 examples/sec; 0.349 sec/batch)
2016-12-03 03:11:11.107225: step 8120, loss = 0.61, accu = 0.97, validation: 0.68 (406.2 examples/sec; 0.315 sec/batch)
2016-12-03 03:11:14.657298: step 8130, loss = 0.59, accu = 0.96, validation: 0.72 (374.2 examples/sec; 0.342 sec/batch)
2016-12-03 03:11:18.280286: step 8140, loss = 0.59, accu = 0.96, validation: 0.70 (371.3 examples/sec; 0.345 sec/batch)
2016-12-03 03:11:21.976736: step 8150, loss = 0.57, accu = 0.97, validation: 0.65 (376.0 examples/sec; 0.340 sec/batch)
2016-12-03 03:11:25.572083: step 8160, loss = 0.58, accu = 0.95, validation: 0.65 (369.9 examples/sec; 0.346 sec/batch)
2016-12-03 03:11:29.153390: step 8170, loss = 0.60, accu = 0.97, validation: 0.68 (390.2 examples/sec; 0.328 sec/batch)
2016-12-03 03:11:32.766289: step 8180, loss = 0.58, accu = 0.98, validation: 0.64 (293.0 examples/sec; 0.437 sec/batch)
2016-12-03 03:11:36.341982: step 8190, loss = 0.57, accu = 0.96, validation: 0.62 (380.7 examples/sec; 0.336 sec/batch)
2016-12-03 03:11:39.996508: step 8200, loss = 0.54, accu = 1.00, validation: 0.65 (377.7 examples/sec; 0.339 sec/batch)
2016-12-03 03:11:43.924748: step 8210, loss = 0.57, accu = 0.98, validation: 0.66 (379.9 examples/sec; 0.337 sec/batch)
2016-12-03 03:11:47.493823: step 8220, loss = 0.55, accu = 0.98, validation: 0.66 (335.2 examples/sec; 0.382 sec/batch)
2016-12-03 03:11:50.992132: step 8230, loss = 0.60, accu = 0.95, validation: 0.73 (385.8 examples/sec; 0.332 sec/batch)
2016-12-03 03:11:54.576952: step 8240, loss = 0.62, accu = 0.98, validation: 0.70 (372.9 examples/sec; 0.343 sec/batch)
2016-12-03 03:11:58.144876: step 8250, loss = 0.61, accu = 0.95, validation: 0.67 (351.8 examples/sec; 0.364 sec/batch)
2016-12-03 03:12:01.708580: step 8260, loss = 0.60, accu = 0.96, validation: 0.65 (391.7 examples/sec; 0.327 sec/batch)
2016-12-03 03:12:05.361924: step 8270, loss = 0.58, accu = 0.97, validation: 0.62 (364.6 examples/sec; 0.351 sec/batch)
2016-12-03 03:12:08.895704: step 8280, loss = 0.59, accu = 0.96, validation: 0.67 (377.6 examples/sec; 0.339 sec/batch)
2016-12-03 03:12:12.488233: step 8290, loss = 0.57, accu = 0.97, validation: 0.67 (395.2 examples/sec; 0.324 sec/batch)
2016-12-03 03:12:15.997092: step 8300, loss = 0.55, accu = 0.98, validation: 0.63 (385.8 examples/sec; 0.332 sec/batch)
2016-12-03 03:12:19.872657: step 8310, loss = 0.59, accu = 0.97, validation: 0.72 (382.2 examples/sec; 0.335 sec/batch)
2016-12-03 03:12:23.413829: step 8320, loss = 0.56, accu = 0.98, validation: 0.64 (385.7 examples/sec; 0.332 sec/batch)
2016-12-03 03:12:27.122618: step 8330, loss = 0.51, accu = 1.00, validation: 0.71 (274.6 examples/sec; 0.466 sec/batch)
2016-12-03 03:12:30.688999: step 8340, loss = 0.56, accu = 0.97, validation: 0.68 (381.9 examples/sec; 0.335 sec/batch)
2016-12-03 03:12:34.240639: step 8350, loss = 0.58, accu = 0.98, validation: 0.70 (385.8 examples/sec; 0.332 sec/batch)
2016-12-03 03:12:37.918728: step 8360, loss = 0.54, accu = 0.98, validation: 0.66 (384.8 examples/sec; 0.333 sec/batch)
2016-12-03 03:12:41.593167: step 8370, loss = 0.54, accu = 0.99, validation: 0.64 (270.8 examples/sec; 0.473 sec/batch)
2016-12-03 03:12:44.956766: step 8380, loss = 0.56, accu = 0.97, validation: 0.61 (406.6 examples/sec; 0.315 sec/batch)
2016-12-03 03:12:48.396924: step 8390, loss = 0.54, accu = 0.99, validation: 0.72 (374.6 examples/sec; 0.342 sec/batch)
2016-12-03 03:12:52.024659: step 8400, loss = 0.55, accu = 0.98, validation: 0.64 (355.3 examples/sec; 0.360 sec/batch)
2016-12-03 03:12:55.800337: step 8410, loss = 0.56, accu = 0.98, validation: 0.54 (397.5 examples/sec; 0.322 sec/batch)
2016-12-03 03:12:59.502944: step 8420, loss = 0.56, accu = 0.97, validation: 0.73 (272.2 examples/sec; 0.470 sec/batch)
2016-12-03 03:13:03.064614: step 8430, loss = 0.55, accu = 0.98, validation: 0.65 (376.2 examples/sec; 0.340 sec/batch)
2016-12-03 03:13:06.672933: step 8440, loss = 0.52, accu = 0.99, validation: 0.66 (386.4 examples/sec; 0.331 sec/batch)
2016-12-03 03:13:10.235163: step 8450, loss = 0.54, accu = 1.00, validation: 0.66 (368.2 examples/sec; 0.348 sec/batch)
2016-12-03 03:13:13.838495: step 8460, loss = 0.55, accu = 0.98, validation: 0.63 (359.8 examples/sec; 0.356 sec/batch)
2016-12-03 03:13:17.355314: step 8470, loss = 0.55, accu = 0.97, validation: 0.62 (386.7 examples/sec; 0.331 sec/batch)
2016-12-03 03:13:20.903459: step 8480, loss = 0.57, accu = 0.98, validation: 0.66 (371.2 examples/sec; 0.345 sec/batch)
2016-12-03 03:13:24.612440: step 8490, loss = 0.58, accu = 0.97, validation: 0.66 (283.8 examples/sec; 0.451 sec/batch)
2016-12-03 03:13:28.280405: step 8500, loss = 0.62, accu = 0.94, validation: 0.65 (389.8 examples/sec; 0.328 sec/batch)
2016-12-03 03:13:32.033178: step 8510, loss = 0.58, accu = 0.97, validation: 0.70 (390.2 examples/sec; 0.328 sec/batch)
2016-12-03 03:13:35.572893: step 8520, loss = 0.54, accu = 0.98, validation: 0.63 (387.5 examples/sec; 0.330 sec/batch)
2016-12-03 03:13:39.193481: step 8530, loss = 0.55, accu = 0.99, validation: 0.62 (392.2 examples/sec; 0.326 sec/batch)
2016-12-03 03:13:42.791114: step 8540, loss = 0.57, accu = 0.97, validation: 0.68 (373.6 examples/sec; 0.343 sec/batch)
2016-12-03 03:13:46.357450: step 8550, loss = 0.55, accu = 0.97, validation: 0.66 (372.8 examples/sec; 0.343 sec/batch)
2016-12-03 03:13:50.028156: step 8560, loss = 0.54, accu = 0.98, validation: 0.69 (346.2 examples/sec; 0.370 sec/batch)
2016-12-03 03:13:53.462769: step 8570, loss = 0.55, accu = 0.98, validation: 0.66 (386.5 examples/sec; 0.331 sec/batch)
2016-12-03 03:13:57.003259: step 8580, loss = 0.53, accu = 0.98, validation: 0.62 (376.1 examples/sec; 0.340 sec/batch)
2016-12-03 03:14:00.530148: step 8590, loss = 0.56, accu = 0.98, validation: 0.69 (377.7 examples/sec; 0.339 sec/batch)
2016-12-03 03:14:04.015041: step 8600, loss = 0.53, accu = 0.99, validation: 0.70 (398.1 examples/sec; 0.322 sec/batch)
2016-12-03 03:14:07.878868: step 8610, loss = 0.57, accu = 0.98, validation: 0.67 (362.0 examples/sec; 0.354 sec/batch)
2016-12-03 03:14:11.509587: step 8620, loss = 0.59, accu = 0.96, validation: 0.61 (291.2 examples/sec; 0.440 sec/batch)
2016-12-03 03:14:15.045905: step 8630, loss = 0.61, accu = 0.95, validation: 0.65 (370.9 examples/sec; 0.345 sec/batch)
2016-12-03 03:14:18.522799: step 8640, loss = 0.58, accu = 0.97, validation: 0.66 (391.1 examples/sec; 0.327 sec/batch)
2016-12-03 03:14:22.058837: step 8650, loss = 0.56, accu = 0.98, validation: 0.62 (405.0 examples/sec; 0.316 sec/batch)
2016-12-03 03:14:25.786949: step 8660, loss = 0.53, accu = 0.99, validation: 0.66 (363.6 examples/sec; 0.352 sec/batch)
2016-12-03 03:14:29.261024: step 8670, loss = 0.55, accu = 0.96, validation: 0.62 (383.4 examples/sec; 0.334 sec/batch)
2016-12-03 03:14:32.878159: step 8680, loss = 0.52, accu = 0.99, validation: 0.66 (309.1 examples/sec; 0.414 sec/batch)
2016-12-03 03:14:36.433020: step 8690, loss = 0.52, accu = 0.98, validation: 0.65 (368.0 examples/sec; 0.348 sec/batch)
2016-12-03 03:14:40.070930: step 8700, loss = 0.51, accu = 0.98, validation: 0.68 (374.0 examples/sec; 0.342 sec/batch)
2016-12-03 03:14:43.864353: step 8710, loss = 0.54, accu = 0.99, validation: 0.69 (386.6 examples/sec; 0.331 sec/batch)
2016-12-03 03:14:47.426826: step 8720, loss = 0.53, accu = 0.98, validation: 0.67 (368.3 examples/sec; 0.348 sec/batch)
2016-12-03 03:14:51.015284: step 8730, loss = 0.55, accu = 0.98, validation: 0.59 (312.9 examples/sec; 0.409 sec/batch)
2016-12-03 03:14:54.589900: step 8740, loss = 0.56, accu = 0.98, validation: 0.65 (385.7 examples/sec; 0.332 sec/batch)
2016-12-03 03:14:58.088039: step 8750, loss = 0.53, accu = 0.98, validation: 0.64 (377.0 examples/sec; 0.340 sec/batch)
2016-12-03 03:15:01.686435: step 8760, loss = 0.56, accu = 0.95, validation: 0.62 (358.6 examples/sec; 0.357 sec/batch)
2016-12-03 03:15:05.356643: step 8770, loss = 0.55, accu = 0.97, validation: 0.73 (379.4 examples/sec; 0.337 sec/batch)
2016-12-03 03:15:08.870736: step 8780, loss = 0.54, accu = 0.97, validation: 0.61 (374.1 examples/sec; 0.342 sec/batch)
2016-12-03 03:15:12.312526: step 8790, loss = 0.53, accu = 0.98, validation: 0.69 (314.7 examples/sec; 0.407 sec/batch)
2016-12-03 03:15:15.857873: step 8800, loss = 0.58, accu = 0.97, validation: 0.73 (392.3 examples/sec; 0.326 sec/batch)
2016-12-03 03:15:19.669940: step 8810, loss = 0.54, accu = 0.98, validation: 0.67 (374.5 examples/sec; 0.342 sec/batch)
2016-12-03 03:15:23.113612: step 8820, loss = 0.54, accu = 0.98, validation: 0.66 (388.3 examples/sec; 0.330 sec/batch)
2016-12-03 03:15:26.593997: step 8830, loss = 0.52, accu = 0.98, validation: 0.62 (378.5 examples/sec; 0.338 sec/batch)
2016-12-03 03:15:30.197111: step 8840, loss = 0.51, accu = 0.99, validation: 0.63 (372.3 examples/sec; 0.344 sec/batch)
2016-12-03 03:15:33.720147: step 8850, loss = 0.52, accu = 0.99, validation: 0.66 (380.1 examples/sec; 0.337 sec/batch)
2016-12-03 03:15:37.340453: step 8860, loss = 0.57, accu = 0.96, validation: 0.63 (386.8 examples/sec; 0.331 sec/batch)
2016-12-03 03:15:40.892007: step 8870, loss = 0.54, accu = 0.96, validation: 0.58 (385.6 examples/sec; 0.332 sec/batch)
2016-12-03 03:15:44.511282: step 8880, loss = 0.51, accu = 0.98, validation: 0.70 (349.9 examples/sec; 0.366 sec/batch)
2016-12-03 03:15:48.050520: step 8890, loss = 0.53, accu = 0.98, validation: 0.68 (396.3 examples/sec; 0.323 sec/batch)
2016-12-03 03:15:51.549580: step 8900, loss = 0.53, accu = 0.99, validation: 0.70 (384.9 examples/sec; 0.333 sec/batch)
2016-12-03 03:15:55.306313: step 8910, loss = 0.54, accu = 0.98, validation: 0.66 (379.8 examples/sec; 0.337 sec/batch)
2016-12-03 03:15:58.942372: step 8920, loss = 0.54, accu = 0.98, validation: 0.66 (291.3 examples/sec; 0.439 sec/batch)
2016-12-03 03:16:02.522559: step 8930, loss = 0.57, accu = 0.95, validation: 0.66 (380.2 examples/sec; 0.337 sec/batch)
2016-12-03 03:16:06.155247: step 8940, loss = 0.56, accu = 0.98, validation: 0.66 (273.1 examples/sec; 0.469 sec/batch)
2016-12-03 03:16:09.771225: step 8950, loss = 0.56, accu = 0.98, validation: 0.62 (388.4 examples/sec; 0.330 sec/batch)
2016-12-03 03:16:13.290483: step 8960, loss = 0.52, accu = 0.98, validation: 0.64 (372.3 examples/sec; 0.344 sec/batch)
2016-12-03 03:16:16.853631: step 8970, loss = 0.59, accu = 0.92, validation: 0.66 (388.2 examples/sec; 0.330 sec/batch)
2016-12-03 03:16:20.541602: step 8980, loss = 0.54, accu = 0.95, validation: 0.62 (366.4 examples/sec; 0.349 sec/batch)
2016-12-03 03:16:24.037251: step 8990, loss = 0.52, accu = 0.98, validation: 0.72 (318.0 examples/sec; 0.402 sec/batch)
2016-12-03 03:16:27.666503: step 9000, loss = 0.50, accu = 0.99, validation: 0.62 (304.1 examples/sec; 0.421 sec/batch)
2016-12-03 03:16:31.848964: step 9010, loss = 0.53, accu = 0.97, validation: 0.61 (376.6 examples/sec; 0.340 sec/batch)
2016-12-03 03:16:35.404416: step 9020, loss = 0.56, accu = 0.96, validation: 0.66 (374.3 examples/sec; 0.342 sec/batch)
2016-12-03 03:16:39.051497: step 9030, loss = 0.58, accu = 0.97, validation: 0.62 (314.6 examples/sec; 0.407 sec/batch)
2016-12-03 03:16:42.628646: step 9040, loss = 0.55, accu = 0.98, validation: 0.67 (375.3 examples/sec; 0.341 sec/batch)
2016-12-03 03:16:46.205909: step 9050, loss = 0.51, accu = 0.99, validation: 0.66 (369.4 examples/sec; 0.346 sec/batch)
2016-12-03 03:16:49.793692: step 9060, loss = 0.55, accu = 0.98, validation: 0.68 (391.3 examples/sec; 0.327 sec/batch)
2016-12-03 03:16:53.493724: step 9070, loss = 0.53, accu = 0.98, validation: 0.70 (273.3 examples/sec; 0.468 sec/batch)
2016-12-03 03:16:57.044576: step 9080, loss = 0.51, accu = 0.99, validation: 0.60 (277.1 examples/sec; 0.462 sec/batch)
2016-12-03 03:17:00.642740: step 9090, loss = 0.52, accu = 0.98, validation: 0.61 (366.5 examples/sec; 0.349 sec/batch)
2016-12-03 03:17:04.224915: step 9100, loss = 0.50, accu = 0.99, validation: 0.65 (360.3 examples/sec; 0.355 sec/batch)
2016-12-03 03:17:08.170831: step 9110, loss = 0.52, accu = 0.98, validation: 0.62 (287.4 examples/sec; 0.445 sec/batch)
2016-12-03 03:17:11.775513: step 9120, loss = 0.52, accu = 0.98, validation: 0.66 (391.9 examples/sec; 0.327 sec/batch)
2016-12-03 03:17:15.353408: step 9130, loss = 0.52, accu = 0.98, validation: 0.66 (375.7 examples/sec; 0.341 sec/batch)
2016-12-03 03:17:18.950506: step 9140, loss = 0.53, accu = 0.98, validation: 0.67 (376.2 examples/sec; 0.340 sec/batch)
2016-12-03 03:17:22.680262: step 9150, loss = 0.49, accu = 1.00, validation: 0.74 (357.2 examples/sec; 0.358 sec/batch)
2016-12-03 03:17:26.285212: step 9160, loss = 0.52, accu = 0.96, validation: 0.65 (344.0 examples/sec; 0.372 sec/batch)
2016-12-03 03:17:29.963873: step 9170, loss = 0.49, accu = 1.00, validation: 0.66 (376.4 examples/sec; 0.340 sec/batch)
2016-12-03 03:17:33.536310: step 9180, loss = 0.52, accu = 0.98, validation: 0.62 (373.3 examples/sec; 0.343 sec/batch)
2016-12-03 03:17:37.242680: step 9190, loss = 0.52, accu = 0.99, validation: 0.64 (331.4 examples/sec; 0.386 sec/batch)
2016-12-03 03:17:40.848964: step 9200, loss = 0.54, accu = 0.98, validation: 0.65 (372.7 examples/sec; 0.343 sec/batch)
2016-12-03 03:17:44.628728: step 9210, loss = 0.51, accu = 0.98, validation: 0.66 (372.9 examples/sec; 0.343 sec/batch)
2016-12-03 03:17:48.277736: step 9220, loss = 0.54, accu = 0.98, validation: 0.61 (380.5 examples/sec; 0.336 sec/batch)
2016-12-03 03:17:51.837492: step 9230, loss = 0.53, accu = 0.97, validation: 0.64 (384.6 examples/sec; 0.333 sec/batch)
2016-12-03 03:17:55.505094: step 9240, loss = 0.51, accu = 0.99, validation: 0.59 (364.1 examples/sec; 0.352 sec/batch)
2016-12-03 03:17:59.070077: step 9250, loss = 0.51, accu = 0.98, validation: 0.66 (380.5 examples/sec; 0.336 sec/batch)
2016-12-03 03:18:02.801675: step 9260, loss = 0.52, accu = 0.98, validation: 0.73 (309.7 examples/sec; 0.413 sec/batch)
2016-12-03 03:18:06.423836: step 9270, loss = 0.49, accu = 0.99, validation: 0.75 (365.6 examples/sec; 0.350 sec/batch)
2016-12-03 03:18:09.966065: step 9280, loss = 0.53, accu = 0.98, validation: 0.68 (381.3 examples/sec; 0.336 sec/batch)
2016-12-03 03:18:13.550775: step 9290, loss = 0.53, accu = 0.98, validation: 0.65 (377.0 examples/sec; 0.340 sec/batch)
2016-12-03 03:18:17.124665: step 9300, loss = 0.51, accu = 0.98, validation: 0.62 (390.4 examples/sec; 0.328 sec/batch)
2016-12-03 03:18:20.970172: step 9310, loss = 0.58, accu = 0.98, validation: 0.70 (296.7 examples/sec; 0.431 sec/batch)
2016-12-03 03:18:24.545729: step 9320, loss = 0.55, accu = 0.95, validation: 0.69 (384.6 examples/sec; 0.333 sec/batch)
2016-12-03 03:18:28.180027: step 9330, loss = 0.50, accu = 0.98, validation: 0.65 (298.9 examples/sec; 0.428 sec/batch)
2016-12-03 03:18:31.793781: step 9340, loss = 0.54, accu = 0.99, validation: 0.71 (368.9 examples/sec; 0.347 sec/batch)
2016-12-03 03:18:35.362506: step 9350, loss = 0.49, accu = 1.00, validation: 0.64 (367.9 examples/sec; 0.348 sec/batch)
2016-12-03 03:18:38.854296: step 9360, loss = 0.51, accu = 0.98, validation: 0.73 (353.9 examples/sec; 0.362 sec/batch)
2016-12-03 03:18:42.503234: step 9370, loss = 0.55, accu = 0.97, validation: 0.70 (338.0 examples/sec; 0.379 sec/batch)
2016-12-03 03:18:46.004055: step 9380, loss = 0.51, accu = 0.98, validation: 0.67 (390.0 examples/sec; 0.328 sec/batch)
2016-12-03 03:18:49.665137: step 9390, loss = 0.54, accu = 0.96, validation: 0.68 (366.5 examples/sec; 0.349 sec/batch)
2016-12-03 03:18:53.146142: step 9400, loss = 0.51, accu = 0.98, validation: 0.59 (395.8 examples/sec; 0.323 sec/batch)
2016-12-03 03:18:56.981522: step 9410, loss = 0.57, accu = 0.96, validation: 0.70 (355.9 examples/sec; 0.360 sec/batch)
2016-12-03 03:19:00.538783: step 9420, loss = 0.52, accu = 0.99, validation: 0.73 (335.7 examples/sec; 0.381 sec/batch)
2016-12-03 03:19:04.140828: step 9430, loss = 0.49, accu = 0.99, validation: 0.65 (309.9 examples/sec; 0.413 sec/batch)
2016-12-03 03:19:07.615104: step 9440, loss = 0.49, accu = 0.98, validation: 0.59 (391.3 examples/sec; 0.327 sec/batch)
2016-12-03 03:19:11.233211: step 9450, loss = 0.50, accu = 0.98, validation: 0.72 (304.9 examples/sec; 0.420 sec/batch)
2016-12-03 03:19:14.787170: step 9460, loss = 0.51, accu = 0.98, validation: 0.66 (389.7 examples/sec; 0.328 sec/batch)
2016-12-03 03:19:18.438389: step 9470, loss = 0.50, accu = 0.98, validation: 0.67 (277.3 examples/sec; 0.462 sec/batch)
2016-12-03 03:19:22.006226: step 9480, loss = 0.53, accu = 0.98, validation: 0.69 (388.9 examples/sec; 0.329 sec/batch)
2016-12-03 03:19:25.507705: step 9490, loss = 0.53, accu = 0.98, validation: 0.60 (388.1 examples/sec; 0.330 sec/batch)
2016-12-03 03:19:29.180755: step 9500, loss = 0.53, accu = 0.98, validation: 0.62 (388.6 examples/sec; 0.329 sec/batch)
2016-12-03 03:19:33.011854: step 9510, loss = 0.55, accu = 0.96, validation: 0.66 (377.5 examples/sec; 0.339 sec/batch)
2016-12-03 03:19:36.679056: step 9520, loss = 0.54, accu = 0.97, validation: 0.62 (329.5 examples/sec; 0.389 sec/batch)
2016-12-03 03:19:40.148862: step 9530, loss = 0.51, accu = 0.98, validation: 0.67 (386.2 examples/sec; 0.331 sec/batch)
2016-12-03 03:19:43.798685: step 9540, loss = 0.53, accu = 0.98, validation: 0.64 (390.3 examples/sec; 0.328 sec/batch)
2016-12-03 03:19:47.365848: step 9550, loss = 0.55, accu = 0.98, validation: 0.64 (388.2 examples/sec; 0.330 sec/batch)
2016-12-03 03:19:50.892557: step 9560, loss = 0.54, accu = 0.97, validation: 0.63 (381.8 examples/sec; 0.335 sec/batch)
2016-12-03 03:19:54.416274: step 9570, loss = 0.54, accu = 0.96, validation: 0.68 (387.5 examples/sec; 0.330 sec/batch)
2016-12-03 03:19:58.123262: step 9580, loss = 0.51, accu = 0.99, validation: 0.64 (381.7 examples/sec; 0.335 sec/batch)
2016-12-03 03:20:01.816056: step 9590, loss = 0.49, accu = 0.99, validation: 0.66 (387.4 examples/sec; 0.330 sec/batch)
2016-12-03 03:20:05.299486: step 9600, loss = 0.50, accu = 0.98, validation: 0.66 (386.5 examples/sec; 0.331 sec/batch)
2016-12-03 03:20:09.193822: step 9610, loss = 0.50, accu = 0.99, validation: 0.63 (345.4 examples/sec; 0.371 sec/batch)
2016-12-03 03:20:12.876951: step 9620, loss = 0.48, accu = 1.00, validation: 0.66 (387.1 examples/sec; 0.331 sec/batch)
2016-12-03 03:20:16.362432: step 9630, loss = 0.54, accu = 0.95, validation: 0.72 (381.5 examples/sec; 0.336 sec/batch)
2016-12-03 03:20:20.018876: step 9640, loss = 0.52, accu = 0.98, validation: 0.68 (286.2 examples/sec; 0.447 sec/batch)
2016-12-03 03:20:23.439353: step 9650, loss = 0.55, accu = 0.96, validation: 0.60 (375.7 examples/sec; 0.341 sec/batch)
2016-12-03 03:20:26.998378: step 9660, loss = 0.50, accu = 0.99, validation: 0.67 (390.4 examples/sec; 0.328 sec/batch)
2016-12-03 03:20:30.657403: step 9670, loss = 0.50, accu = 1.00, validation: 0.62 (294.0 examples/sec; 0.435 sec/batch)
2016-12-03 03:20:34.265718: step 9680, loss = 0.51, accu = 0.98, validation: 0.60 (371.9 examples/sec; 0.344 sec/batch)
2016-12-03 03:20:37.991016: step 9690, loss = 0.52, accu = 0.98, validation: 0.65 (282.1 examples/sec; 0.454 sec/batch)
2016-12-03 03:20:41.520929: step 9700, loss = 0.52, accu = 0.98, validation: 0.59 (389.6 examples/sec; 0.329 sec/batch)
2016-12-03 03:20:45.367129: step 9710, loss = 0.52, accu = 0.98, validation: 0.62 (350.9 examples/sec; 0.365 sec/batch)
2016-12-03 03:20:48.846440: step 9720, loss = 0.53, accu = 0.98, validation: 0.69 (387.6 examples/sec; 0.330 sec/batch)
2016-12-03 03:20:52.360824: step 9730, loss = 0.54, accu = 0.96, validation: 0.68 (380.2 examples/sec; 0.337 sec/batch)
2016-12-03 03:20:55.982424: step 9740, loss = 0.50, accu = 0.99, validation: 0.70 (321.6 examples/sec; 0.398 sec/batch)
2016-12-03 03:20:59.536597: step 9750, loss = 0.53, accu = 0.98, validation: 0.66 (389.3 examples/sec; 0.329 sec/batch)
2016-12-03 03:21:03.067031: step 9760, loss = 0.53, accu = 0.98, validation: 0.68 (393.8 examples/sec; 0.325 sec/batch)
2016-12-03 03:21:06.573919: step 9770, loss = 0.53, accu = 0.96, validation: 0.68 (370.9 examples/sec; 0.345 sec/batch)
2016-12-03 03:21:10.105991: step 9780, loss = 0.56, accu = 0.95, validation: 0.66 (393.9 examples/sec; 0.325 sec/batch)
2016-12-03 03:21:13.790706: step 9790, loss = 0.51, accu = 0.98, validation: 0.59 (369.7 examples/sec; 0.346 sec/batch)
2016-12-03 03:21:17.271106: step 9800, loss = 0.51, accu = 0.98, validation: 0.76 (397.9 examples/sec; 0.322 sec/batch)
2016-12-03 03:21:21.040328: step 9810, loss = 0.49, accu = 1.00, validation: 0.62 (378.6 examples/sec; 0.338 sec/batch)
2016-12-03 03:21:24.751110: step 9820, loss = 0.56, accu = 0.97, validation: 0.70 (322.7 examples/sec; 0.397 sec/batch)
2016-12-03 03:21:28.231816: step 9830, loss = 0.53, accu = 0.98, validation: 0.69 (285.0 examples/sec; 0.449 sec/batch)
2016-12-03 03:21:31.653084: step 9840, loss = 0.51, accu = 0.98, validation: 0.64 (378.9 examples/sec; 0.338 sec/batch)
2016-12-03 03:21:35.325410: step 9850, loss = 0.52, accu = 0.97, validation: 0.63 (384.4 examples/sec; 0.333 sec/batch)
2016-12-03 03:21:38.981357: step 9860, loss = 0.52, accu = 0.98, validation: 0.63 (290.3 examples/sec; 0.441 sec/batch)
2016-12-03 03:21:42.657870: step 9870, loss = 0.52, accu = 0.98, validation: 0.65 (337.4 examples/sec; 0.379 sec/batch)
2016-12-03 03:21:46.178297: step 9880, loss = 0.48, accu = 0.99, validation: 0.69 (370.8 examples/sec; 0.345 sec/batch)
2016-12-03 03:21:49.748167: step 9890, loss = 0.54, accu = 0.96, validation: 0.65 (390.3 examples/sec; 0.328 sec/batch)
2016-12-03 03:21:53.177341: step 9900, loss = 0.53, accu = 0.97, validation: 0.60 (319.0 examples/sec; 0.401 sec/batch)
2016-12-03 03:21:57.182663: step 9910, loss = 0.53, accu = 0.97, validation: 0.66 (266.7 examples/sec; 0.480 sec/batch)
2016-12-03 03:22:00.717690: step 9920, loss = 0.49, accu = 0.98, validation: 0.69 (371.7 examples/sec; 0.344 sec/batch)
2016-12-03 03:22:04.280969: step 9930, loss = 0.50, accu = 0.98, validation: 0.73 (378.8 examples/sec; 0.338 sec/batch)
2016-12-03 03:22:08.020633: step 9940, loss = 0.48, accu = 1.00, validation: 0.70 (381.0 examples/sec; 0.336 sec/batch)
2016-12-03 03:22:11.606323: step 9950, loss = 0.53, accu = 0.99, validation: 0.69 (384.6 examples/sec; 0.333 sec/batch)
2016-12-03 03:22:15.280041: step 9960, loss = 0.49, accu = 0.99, validation: 0.67 (281.0 examples/sec; 0.455 sec/batch)
2016-12-03 03:22:18.792171: step 9970, loss = 0.53, accu = 0.98, validation: 0.66 (396.6 examples/sec; 0.323 sec/batch)
2016-12-03 03:22:22.374824: step 9980, loss = 0.49, accu = 0.99, validation: 0.67 (382.5 examples/sec; 0.335 sec/batch)
2016-12-03 03:22:25.887998: step 9990, loss = 0.52, accu = 0.98, validation: 0.67 (399.1 examples/sec; 0.321 sec/batch)
2016-12-03 03:22:29.434285: step 10000, loss = 0.51, accu = 0.98, validation: 0.62 (347.0 examples/sec; 0.369 sec/batch)
2016-12-03 03:22:33.865560: step 10010, loss = 0.50, accu = 1.00, validation: 0.64 (393.9 examples/sec; 0.325 sec/batch)
2016-12-03 03:22:37.328834: step 10020, loss = 0.51, accu = 0.99, validation: 0.64 (275.1 examples/sec; 0.465 sec/batch)
2016-12-03 03:22:40.971804: step 10030, loss = 0.51, accu = 0.98, validation: 0.69 (374.7 examples/sec; 0.342 sec/batch)
2016-12-03 03:22:44.548431: step 10040, loss = 0.53, accu = 0.98, validation: 0.66 (325.9 examples/sec; 0.393 sec/batch)
2016-12-03 03:22:48.084906: step 10050, loss = 0.49, accu = 0.99, validation: 0.65 (386.1 examples/sec; 0.331 sec/batch)
2016-12-03 03:22:51.598602: step 10060, loss = 0.49, accu = 0.99, validation: 0.62 (333.4 examples/sec; 0.384 sec/batch)
2016-12-03 03:22:55.275252: step 10070, loss = 0.52, accu = 0.98, validation: 0.62 (289.7 examples/sec; 0.442 sec/batch)
2016-12-03 03:22:58.877682: step 10080, loss = 0.50, accu = 0.99, validation: 0.66 (370.2 examples/sec; 0.346 sec/batch)
2016-12-03 03:23:02.335019: step 10090, loss = 0.55, accu = 0.96, validation: 0.68 (386.4 examples/sec; 0.331 sec/batch)
2016-12-03 03:23:05.933735: step 10100, loss = 0.53, accu = 0.98, validation: 0.66 (358.7 examples/sec; 0.357 sec/batch)
2016-12-03 03:23:09.883888: step 10110, loss = 0.54, accu = 0.98, validation: 0.67 (284.5 examples/sec; 0.450 sec/batch)
2016-12-03 03:23:14.712014: step 10120, loss = 0.54, accu = 0.97, validation: 0.62 (238.4 examples/sec; 0.537 sec/batch)
2016-12-03 03:23:21.042347: step 10130, loss = 0.51, accu = 0.98, validation: 0.69 (235.4 examples/sec; 0.544 sec/batch)
2016-12-03 03:23:24.787011: step 10140, loss = 0.55, accu = 0.97, validation: 0.62 (383.8 examples/sec; 0.334 sec/batch)
2016-12-03 03:23:28.462134: step 10150, loss = 0.52, accu = 0.98, validation: 0.63 (394.6 examples/sec; 0.324 sec/batch)
2016-12-03 03:23:32.117099: step 10160, loss = 0.50, accu = 0.99, validation: 0.65 (281.2 examples/sec; 0.455 sec/batch)
2016-12-03 03:23:35.810129: step 10170, loss = 0.52, accu = 0.98, validation: 0.66 (260.2 examples/sec; 0.492 sec/batch)
2016-12-03 03:23:39.414815: step 10180, loss = 0.49, accu = 0.99, validation: 0.69 (388.4 examples/sec; 0.330 sec/batch)
2016-12-03 03:23:42.997972: step 10190, loss = 0.56, accu = 0.97, validation: 0.69 (383.4 examples/sec; 0.334 sec/batch)
2016-12-03 03:23:46.552554: step 10200, loss = 0.50, accu = 0.99, validation: 0.69 (353.6 examples/sec; 0.362 sec/batch)
2016-12-03 03:23:50.385782: step 10210, loss = 0.53, accu = 0.98, validation: 0.64 (345.0 examples/sec; 0.371 sec/batch)
2016-12-03 03:23:53.956122: step 10220, loss = 0.51, accu = 0.97, validation: 0.63 (325.6 examples/sec; 0.393 sec/batch)
2016-12-03 03:23:57.507589: step 10230, loss = 0.51, accu = 0.99, validation: 0.66 (374.6 examples/sec; 0.342 sec/batch)
2016-12-03 03:24:01.016098: step 10240, loss = 0.52, accu = 0.98, validation: 0.61 (386.5 examples/sec; 0.331 sec/batch)
2016-12-03 03:24:04.555898: step 10250, loss = 0.50, accu = 1.00, validation: 0.66 (362.8 examples/sec; 0.353 sec/batch)
2016-12-03 03:24:08.176771: step 10260, loss = 0.52, accu = 0.98, validation: 0.68 (291.3 examples/sec; 0.439 sec/batch)
2016-12-03 03:24:11.738646: step 10270, loss = 0.48, accu = 1.00, validation: 0.60 (367.6 examples/sec; 0.348 sec/batch)
2016-12-03 03:24:15.358506: step 10280, loss = 0.57, accu = 0.94, validation: 0.70 (391.2 examples/sec; 0.327 sec/batch)
2016-12-03 03:24:18.863078: step 10290, loss = 0.51, accu = 0.98, validation: 0.73 (391.6 examples/sec; 0.327 sec/batch)
2016-12-03 03:24:22.382591: step 10300, loss = 0.51, accu = 0.99, validation: 0.70 (387.9 examples/sec; 0.330 sec/batch)
2016-12-03 03:24:26.413739: step 10310, loss = 0.55, accu = 0.97, validation: 0.67 (372.0 examples/sec; 0.344 sec/batch)
2016-12-03 03:24:30.146391: step 10320, loss = 0.49, accu = 0.99, validation: 0.67 (364.1 examples/sec; 0.352 sec/batch)
2016-12-03 03:24:33.723937: step 10330, loss = 0.52, accu = 0.99, validation: 0.64 (395.0 examples/sec; 0.324 sec/batch)
2016-12-03 03:24:37.329610: step 10340, loss = 0.50, accu = 0.99, validation: 0.70 (331.2 examples/sec; 0.387 sec/batch)
2016-12-03 03:24:40.787430: step 10350, loss = 0.50, accu = 1.00, validation: 0.62 (397.0 examples/sec; 0.322 sec/batch)
2016-12-03 03:24:44.420968: step 10360, loss = 0.50, accu = 0.98, validation: 0.66 (366.2 examples/sec; 0.350 sec/batch)
2016-12-03 03:24:47.888667: step 10370, loss = 0.51, accu = 0.98, validation: 0.69 (394.2 examples/sec; 0.325 sec/batch)
2016-12-03 03:24:51.543904: step 10380, loss = 0.51, accu = 0.99, validation: 0.64 (275.6 examples/sec; 0.464 sec/batch)
2016-12-03 03:24:55.075852: step 10390, loss = 0.52, accu = 0.98, validation: 0.72 (383.8 examples/sec; 0.334 sec/batch)
2016-12-03 03:24:58.556910: step 10400, loss = 0.52, accu = 0.98, validation: 0.64 (395.7 examples/sec; 0.323 sec/batch)
2016-12-03 03:25:02.510805: step 10410, loss = 0.52, accu = 0.97, validation: 0.67 (370.5 examples/sec; 0.345 sec/batch)
2016-12-03 03:25:05.968220: step 10420, loss = 0.54, accu = 0.98, validation: 0.65 (386.1 examples/sec; 0.331 sec/batch)
2016-12-03 03:25:09.712902: step 10430, loss = 0.54, accu = 0.96, validation: 0.65 (376.3 examples/sec; 0.340 sec/batch)
2016-12-03 03:25:13.283037: step 10440, loss = 0.53, accu = 0.98, validation: 0.68 (377.8 examples/sec; 0.339 sec/batch)
2016-12-03 03:25:16.800062: step 10450, loss = 0.50, accu = 0.99, validation: 0.64 (372.2 examples/sec; 0.344 sec/batch)
2016-12-03 03:25:20.340231: step 10460, loss = 0.52, accu = 0.98, validation: 0.68 (391.6 examples/sec; 0.327 sec/batch)
2016-12-03 03:25:23.906483: step 10470, loss = 0.51, accu = 0.98, validation: 0.56 (386.1 examples/sec; 0.332 sec/batch)
2016-12-03 03:25:27.574137: step 10480, loss = 0.51, accu = 0.99, validation: 0.71 (302.3 examples/sec; 0.423 sec/batch)
2016-12-03 03:25:31.106849: step 10490, loss = 0.50, accu = 0.98, validation: 0.68 (383.1 examples/sec; 0.334 sec/batch)
2016-12-03 03:25:34.541275: step 10500, loss = 0.50, accu = 1.00, validation: 0.66 (369.8 examples/sec; 0.346 sec/batch)
2016-12-03 03:25:38.462074: step 10510, loss = 0.51, accu = 0.98, validation: 0.71 (380.3 examples/sec; 0.337 sec/batch)
2016-12-03 03:25:42.013044: step 10520, loss = 0.50, accu = 0.99, validation: 0.65 (391.7 examples/sec; 0.327 sec/batch)
2016-12-03 03:25:45.524687: step 10530, loss = 0.49, accu = 1.00, validation: 0.62 (387.8 examples/sec; 0.330 sec/batch)
2016-12-03 03:25:49.065470: step 10540, loss = 0.51, accu = 0.98, validation: 0.65 (377.4 examples/sec; 0.339 sec/batch)
2016-12-03 03:25:52.790408: step 10550, loss = 0.52, accu = 0.98, validation: 0.67 (336.7 examples/sec; 0.380 sec/batch)
2016-12-03 03:25:56.184439: step 10560, loss = 0.53, accu = 0.98, validation: 0.66 (377.8 examples/sec; 0.339 sec/batch)
2016-12-03 03:25:59.834922: step 10570, loss = 0.51, accu = 0.99, validation: 0.62 (392.6 examples/sec; 0.326 sec/batch)
2016-12-03 03:26:03.358634: step 10580, loss = 0.50, accu = 0.99, validation: 0.60 (382.0 examples/sec; 0.335 sec/batch)
2016-12-03 03:26:06.900614: step 10590, loss = 0.52, accu = 0.98, validation: 0.65 (380.8 examples/sec; 0.336 sec/batch)
2016-12-03 03:26:10.601723: step 10600, loss = 0.52, accu = 0.98, validation: 0.61 (284.0 examples/sec; 0.451 sec/batch)
2016-12-03 03:26:14.352968: step 10610, loss = 0.49, accu = 0.99, validation: 0.63 (384.7 examples/sec; 0.333 sec/batch)
2016-12-03 03:26:18.058998: step 10620, loss = 0.49, accu = 1.00, validation: 0.72 (282.7 examples/sec; 0.453 sec/batch)
2016-12-03 03:26:21.415911: step 10630, loss = 0.51, accu = 0.98, validation: 0.64 (377.9 examples/sec; 0.339 sec/batch)
2016-12-03 03:26:25.152149: step 10640, loss = 0.56, accu = 0.96, validation: 0.66 (386.4 examples/sec; 0.331 sec/batch)
2016-12-03 03:26:28.777012: step 10650, loss = 0.53, accu = 0.98, validation: 0.66 (366.1 examples/sec; 0.350 sec/batch)
2016-12-03 03:26:32.326740: step 10660, loss = 0.51, accu = 0.98, validation: 0.71 (269.0 examples/sec; 0.476 sec/batch)
2016-12-03 03:26:35.902085: step 10670, loss = 0.55, accu = 0.97, validation: 0.66 (396.2 examples/sec; 0.323 sec/batch)
2016-12-03 03:26:39.512028: step 10680, loss = 0.49, accu = 0.98, validation: 0.68 (285.4 examples/sec; 0.449 sec/batch)
2016-12-03 03:26:43.082925: step 10690, loss = 0.53, accu = 0.97, validation: 0.68 (367.5 examples/sec; 0.348 sec/batch)
2016-12-03 03:26:46.606326: step 10700, loss = 0.53, accu = 0.98, validation: 0.66 (323.5 examples/sec; 0.396 sec/batch)
2016-12-03 03:26:50.439952: step 10710, loss = 0.52, accu = 0.98, validation: 0.65 (382.2 examples/sec; 0.335 sec/batch)
2016-12-03 03:26:54.030408: step 10720, loss = 0.50, accu = 0.99, validation: 0.68 (369.8 examples/sec; 0.346 sec/batch)
2016-12-03 03:26:57.628782: step 10730, loss = 0.54, accu = 0.96, validation: 0.59 (388.5 examples/sec; 0.329 sec/batch)
2016-12-03 03:27:01.216681: step 10740, loss = 0.51, accu = 0.99, validation: 0.63 (275.8 examples/sec; 0.464 sec/batch)
2016-12-03 03:27:04.831945: step 10750, loss = 0.50, accu = 0.99, validation: 0.69 (388.7 examples/sec; 0.329 sec/batch)
2016-12-03 03:27:08.403815: step 10760, loss = 0.50, accu = 0.98, validation: 0.66 (388.1 examples/sec; 0.330 sec/batch)
2016-12-03 03:27:11.918535: step 10770, loss = 0.50, accu = 0.99, validation: 0.69 (386.6 examples/sec; 0.331 sec/batch)
2016-12-03 03:27:15.601637: step 10780, loss = 0.52, accu = 0.98, validation: 0.66 (353.8 examples/sec; 0.362 sec/batch)
2016-12-03 03:27:19.140342: step 10790, loss = 0.48, accu = 1.00, validation: 0.57 (380.8 examples/sec; 0.336 sec/batch)
2016-12-03 03:27:22.757151: step 10800, loss = 0.52, accu = 0.98, validation: 0.69 (283.2 examples/sec; 0.452 sec/batch)
2016-12-03 03:27:26.557073: step 10810, loss = 0.55, accu = 0.96, validation: 0.61 (387.3 examples/sec; 0.331 sec/batch)
2016-12-03 03:27:30.103166: step 10820, loss = 0.58, accu = 0.95, validation: 0.62 (376.9 examples/sec; 0.340 sec/batch)
2016-12-03 03:27:33.722575: step 10830, loss = 0.54, accu = 0.97, validation: 0.73 (392.1 examples/sec; 0.326 sec/batch)
2016-12-03 03:27:37.274063: step 10840, loss = 0.54, accu = 0.97, validation: 0.64 (384.4 examples/sec; 0.333 sec/batch)
2016-12-03 03:27:40.896910: step 10850, loss = 0.53, accu = 0.96, validation: 0.66 (378.9 examples/sec; 0.338 sec/batch)
2016-12-03 03:27:44.627150: step 10860, loss = 0.50, accu = 0.99, validation: 0.70 (278.5 examples/sec; 0.460 sec/batch)
2016-12-03 03:27:48.038978: step 10870, loss = 0.55, accu = 0.97, validation: 0.69 (391.2 examples/sec; 0.327 sec/batch)
2016-12-03 03:27:51.689504: step 10880, loss = 0.52, accu = 0.98, validation: 0.66 (373.1 examples/sec; 0.343 sec/batch)
2016-12-03 03:27:55.220063: step 10890, loss = 0.50, accu = 1.00, validation: 0.66 (387.9 examples/sec; 0.330 sec/batch)
2016-12-03 03:27:58.914649: step 10900, loss = 0.49, accu = 0.99, validation: 0.61 (382.1 examples/sec; 0.335 sec/batch)
2016-12-03 03:28:02.670242: step 10910, loss = 0.51, accu = 0.97, validation: 0.70 (348.6 examples/sec; 0.367 sec/batch)
2016-12-03 03:28:06.303311: step 10920, loss = 0.53, accu = 0.98, validation: 0.65 (341.2 examples/sec; 0.375 sec/batch)
2016-12-03 03:28:09.829046: step 10930, loss = 0.53, accu = 0.95, validation: 0.56 (385.4 examples/sec; 0.332 sec/batch)
2016-12-03 03:28:13.506396: step 10940, loss = 0.49, accu = 0.99, validation: 0.73 (339.8 examples/sec; 0.377 sec/batch)
2016-12-03 03:28:17.038840: step 10950, loss = 0.49, accu = 1.00, validation: 0.69 (377.4 examples/sec; 0.339 sec/batch)
2016-12-03 03:28:20.603296: step 10960, loss = 0.50, accu = 0.98, validation: 0.71 (330.1 examples/sec; 0.388 sec/batch)
2016-12-03 03:28:24.325729: step 10970, loss = 0.52, accu = 0.98, validation: 0.68 (334.4 examples/sec; 0.383 sec/batch)
2016-12-03 03:28:27.825916: step 10980, loss = 0.49, accu = 1.00, validation: 0.66 (364.2 examples/sec; 0.351 sec/batch)
2016-12-03 03:28:31.413159: step 10990, loss = 0.48, accu = 1.00, validation: 0.66 (375.5 examples/sec; 0.341 sec/batch)
2016-12-03 03:28:35.085780: step 11000, loss = 0.50, accu = 0.98, validation: 0.66 (380.8 examples/sec; 0.336 sec/batch)
2016-12-03 03:28:39.386734: step 11010, loss = 0.53, accu = 0.96, validation: 0.66 (383.5 examples/sec; 0.334 sec/batch)
2016-12-03 03:28:42.856307: step 11020, loss = 0.48, accu = 1.00, validation: 0.70 (378.8 examples/sec; 0.338 sec/batch)
2016-12-03 03:28:46.566047: step 11030, loss = 0.48, accu = 1.00, validation: 0.68 (363.9 examples/sec; 0.352 sec/batch)
2016-12-03 03:28:50.090558: step 11040, loss = 0.52, accu = 0.98, validation: 0.61 (374.3 examples/sec; 0.342 sec/batch)
2016-12-03 03:28:53.659190: step 11050, loss = 0.51, accu = 0.98, validation: 0.65 (359.9 examples/sec; 0.356 sec/batch)
2016-12-03 03:28:57.234837: step 11060, loss = 0.49, accu = 0.99, validation: 0.66 (363.3 examples/sec; 0.352 sec/batch)
2016-12-03 03:29:00.770436: step 11070, loss = 0.50, accu = 0.98, validation: 0.67 (385.8 examples/sec; 0.332 sec/batch)
2016-12-03 03:29:04.488724: step 11080, loss = 0.50, accu = 0.99, validation: 0.68 (375.9 examples/sec; 0.341 sec/batch)
2016-12-03 03:29:08.036650: step 11090, loss = 0.50, accu = 0.99, validation: 0.67 (369.9 examples/sec; 0.346 sec/batch)
2016-12-03 03:29:11.562102: step 11100, loss = 0.52, accu = 0.97, validation: 0.64 (361.6 examples/sec; 0.354 sec/batch)
2016-12-03 03:29:15.476899: step 11110, loss = 0.50, accu = 0.98, validation: 0.63 (351.5 examples/sec; 0.364 sec/batch)
2016-12-03 03:29:19.248935: step 11120, loss = 0.49, accu = 0.99, validation: 0.69 (272.1 examples/sec; 0.470 sec/batch)
2016-12-03 03:29:22.760146: step 11130, loss = 0.50, accu = 0.99, validation: 0.68 (295.0 examples/sec; 0.434 sec/batch)
2016-12-03 03:29:26.443999: step 11140, loss = 0.54, accu = 0.98, validation: 0.70 (278.7 examples/sec; 0.459 sec/batch)
2016-12-03 03:29:30.073882: step 11150, loss = 0.54, accu = 0.98, validation: 0.62 (385.2 examples/sec; 0.332 sec/batch)
2016-12-03 03:29:33.658081: step 11160, loss = 0.49, accu = 1.00, validation: 0.67 (387.6 examples/sec; 0.330 sec/batch)
2016-12-03 03:29:37.318264: step 11170, loss = 0.48, accu = 0.99, validation: 0.63 (367.9 examples/sec; 0.348 sec/batch)
2016-12-03 03:29:40.805698: step 11180, loss = 0.52, accu = 0.97, validation: 0.66 (373.3 examples/sec; 0.343 sec/batch)
2016-12-03 03:29:44.495145: step 11190, loss = 0.52, accu = 0.98, validation: 0.62 (375.0 examples/sec; 0.341 sec/batch)
2016-12-03 03:29:48.093747: step 11200, loss = 0.50, accu = 0.99, validation: 0.66 (364.9 examples/sec; 0.351 sec/batch)
2016-12-03 03:29:51.933614: step 11210, loss = 0.51, accu = 0.98, validation: 0.70 (382.8 examples/sec; 0.334 sec/batch)
2016-12-03 03:29:55.667772: step 11220, loss = 0.54, accu = 0.98, validation: 0.71 (341.4 examples/sec; 0.375 sec/batch)
2016-12-03 03:29:59.270364: step 11230, loss = 0.57, accu = 0.98, validation: 0.67 (393.2 examples/sec; 0.326 sec/batch)
2016-12-03 03:30:02.863022: step 11240, loss = 0.52, accu = 0.98, validation: 0.62 (352.5 examples/sec; 0.363 sec/batch)
2016-12-03 03:30:06.552506: step 11250, loss = 0.48, accu = 1.00, validation: 0.63 (268.3 examples/sec; 0.477 sec/batch)
2016-12-03 03:30:10.119057: step 11260, loss = 0.54, accu = 0.97, validation: 0.62 (357.5 examples/sec; 0.358 sec/batch)
2016-12-03 03:30:13.727605: step 11270, loss = 0.49, accu = 0.98, validation: 0.66 (364.1 examples/sec; 0.352 sec/batch)
2016-12-03 03:30:17.389864: step 11280, loss = 0.50, accu = 0.98, validation: 0.63 (392.8 examples/sec; 0.326 sec/batch)
2016-12-03 03:30:20.926806: step 11290, loss = 0.51, accu = 0.98, validation: 0.74 (387.1 examples/sec; 0.331 sec/batch)
2016-12-03 03:30:24.623099: step 11300, loss = 0.51, accu = 0.98, validation: 0.59 (336.6 examples/sec; 0.380 sec/batch)
2016-12-03 03:30:28.389628: step 11310, loss = 0.48, accu = 0.99, validation: 0.67 (373.6 examples/sec; 0.343 sec/batch)
2016-12-03 03:30:31.901724: step 11320, loss = 0.48, accu = 1.00, validation: 0.73 (382.4 examples/sec; 0.335 sec/batch)
2016-12-03 03:30:35.563291: step 11330, loss = 0.50, accu = 1.00, validation: 0.69 (369.0 examples/sec; 0.347 sec/batch)
2016-12-03 03:30:39.014649: step 11340, loss = 0.53, accu = 0.97, validation: 0.68 (390.0 examples/sec; 0.328 sec/batch)
2016-12-03 03:30:42.680682: step 11350, loss = 0.50, accu = 0.98, validation: 0.67 (271.9 examples/sec; 0.471 sec/batch)
2016-12-03 03:30:46.090555: step 11360, loss = 0.51, accu = 0.99, validation: 0.66 (383.8 examples/sec; 0.334 sec/batch)
2016-12-03 03:30:49.716638: step 11370, loss = 0.50, accu = 0.98, validation: 0.75 (387.5 examples/sec; 0.330 sec/batch)
2016-12-03 03:30:53.244302: step 11380, loss = 0.51, accu = 0.98, validation: 0.70 (379.3 examples/sec; 0.337 sec/batch)
2016-12-03 03:30:56.897838: step 11390, loss = 0.53, accu = 0.97, validation: 0.66 (395.8 examples/sec; 0.323 sec/batch)
2016-12-03 03:31:00.372103: step 11400, loss = 0.55, accu = 0.96, validation: 0.72 (376.3 examples/sec; 0.340 sec/batch)
2016-12-03 03:31:04.167335: step 11410, loss = 0.52, accu = 0.98, validation: 0.63 (382.9 examples/sec; 0.334 sec/batch)
2016-12-03 03:31:07.703564: step 11420, loss = 0.50, accu = 0.98, validation: 0.73 (373.9 examples/sec; 0.342 sec/batch)
2016-12-03 03:31:11.273674: step 11430, loss = 0.54, accu = 0.97, validation: 0.70 (359.3 examples/sec; 0.356 sec/batch)
2016-12-03 03:31:14.868410: step 11440, loss = 0.48, accu = 1.00, validation: 0.73 (391.3 examples/sec; 0.327 sec/batch)
2016-12-03 03:31:18.446902: step 11450, loss = 0.49, accu = 0.99, validation: 0.66 (292.3 examples/sec; 0.438 sec/batch)
2016-12-03 03:31:21.993439: step 11460, loss = 0.51, accu = 0.98, validation: 0.63 (394.6 examples/sec; 0.324 sec/batch)
2016-12-03 03:31:25.672742: step 11470, loss = 0.49, accu = 0.99, validation: 0.66 (296.3 examples/sec; 0.432 sec/batch)
2016-12-03 03:31:29.113450: step 11480, loss = 0.49, accu = 0.99, validation: 0.65 (394.5 examples/sec; 0.324 sec/batch)
2016-12-03 03:31:32.829041: step 11490, loss = 0.49, accu = 0.99, validation: 0.65 (380.9 examples/sec; 0.336 sec/batch)
2016-12-03 03:31:36.404461: step 11500, loss = 0.50, accu = 0.98, validation: 0.66 (363.7 examples/sec; 0.352 sec/batch)
2016-12-03 03:31:40.325576: step 11510, loss = 0.49, accu = 0.99, validation: 0.74 (377.3 examples/sec; 0.339 sec/batch)
2016-12-03 03:31:43.842079: step 11520, loss = 0.52, accu = 0.98, validation: 0.67 (346.6 examples/sec; 0.369 sec/batch)
2016-12-03 03:31:47.456855: step 11530, loss = 0.49, accu = 1.00, validation: 0.67 (371.4 examples/sec; 0.345 sec/batch)
2016-12-03 03:31:50.930080: step 11540, loss = 0.50, accu = 0.99, validation: 0.66 (383.3 examples/sec; 0.334 sec/batch)
2016-12-03 03:31:54.494941: step 11550, loss = 0.50, accu = 0.99, validation: 0.69 (388.5 examples/sec; 0.329 sec/batch)
2016-12-03 03:31:58.006968: step 11560, loss = 0.50, accu = 0.99, validation: 0.64 (398.3 examples/sec; 0.321 sec/batch)
2016-12-03 03:32:01.785503: step 11570, loss = 0.50, accu = 0.99, validation: 0.70 (372.7 examples/sec; 0.343 sec/batch)
2016-12-03 03:32:05.263173: step 11580, loss = 0.51, accu = 0.97, validation: 0.68 (381.1 examples/sec; 0.336 sec/batch)
2016-12-03 03:32:08.887063: step 11590, loss = 0.51, accu = 0.98, validation: 0.73 (385.0 examples/sec; 0.332 sec/batch)
2016-12-03 03:32:12.372407: step 11600, loss = 0.51, accu = 0.98, validation: 0.66 (395.0 examples/sec; 0.324 sec/batch)
2016-12-03 03:32:16.345636: step 11610, loss = 0.50, accu = 1.00, validation: 0.65 (367.3 examples/sec; 0.348 sec/batch)
2016-12-03 03:32:19.911777: step 11620, loss = 0.51, accu = 0.98, validation: 0.62 (379.6 examples/sec; 0.337 sec/batch)
2016-12-03 03:32:23.592884: step 11630, loss = 0.53, accu = 0.96, validation: 0.64 (322.7 examples/sec; 0.397 sec/batch)
2016-12-03 03:32:27.089597: step 11640, loss = 0.48, accu = 0.99, validation: 0.70 (376.2 examples/sec; 0.340 sec/batch)
2016-12-03 03:32:30.720246: step 11650, loss = 0.51, accu = 0.98, validation: 0.66 (321.0 examples/sec; 0.399 sec/batch)
2016-12-03 03:32:34.238500: step 11660, loss = 0.49, accu = 1.00, validation: 0.64 (393.7 examples/sec; 0.325 sec/batch)
2016-12-03 03:32:37.772967: step 11670, loss = 0.51, accu = 0.99, validation: 0.70 (381.8 examples/sec; 0.335 sec/batch)
2016-12-03 03:32:41.516958: step 11680, loss = 0.49, accu = 0.99, validation: 0.69 (287.6 examples/sec; 0.445 sec/batch)
2016-12-03 03:32:45.097377: step 11690, loss = 0.51, accu = 0.98, validation: 0.72 (278.1 examples/sec; 0.460 sec/batch)
2016-12-03 03:32:48.678018: step 11700, loss = 0.54, accu = 0.98, validation: 0.62 (377.7 examples/sec; 0.339 sec/batch)
2016-12-03 03:32:52.437306: step 11710, loss = 0.51, accu = 0.98, validation: 0.66 (379.6 examples/sec; 0.337 sec/batch)
2016-12-03 03:32:56.061512: step 11720, loss = 0.52, accu = 0.98, validation: 0.67 (363.3 examples/sec; 0.352 sec/batch)
2016-12-03 03:32:59.729250: step 11730, loss = 0.51, accu = 0.98, validation: 0.68 (387.2 examples/sec; 0.331 sec/batch)
2016-12-03 03:33:03.299167: step 11740, loss = 0.49, accu = 0.98, validation: 0.61 (362.2 examples/sec; 0.353 sec/batch)
2016-12-03 03:33:06.915447: step 11750, loss = 0.52, accu = 0.98, validation: 0.66 (369.4 examples/sec; 0.346 sec/batch)
2016-12-03 03:33:10.521315: step 11760, loss = 0.51, accu = 0.98, validation: 0.55 (378.5 examples/sec; 0.338 sec/batch)
2016-12-03 03:33:13.975841: step 11770, loss = 0.50, accu = 0.99, validation: 0.62 (395.1 examples/sec; 0.324 sec/batch)
2016-12-03 03:33:17.600110: step 11780, loss = 0.50, accu = 0.98, validation: 0.71 (381.8 examples/sec; 0.335 sec/batch)
2016-12-03 03:33:21.116557: step 11790, loss = 0.49, accu = 0.99, validation: 0.70 (383.9 examples/sec; 0.333 sec/batch)
2016-12-03 03:33:24.620408: step 11800, loss = 0.48, accu = 0.99, validation: 0.69 (393.5 examples/sec; 0.325 sec/batch)
2016-12-03 03:33:28.604037: step 11810, loss = 0.49, accu = 0.98, validation: 0.62 (256.4 examples/sec; 0.499 sec/batch)
2016-12-03 03:33:32.144415: step 11820, loss = 0.49, accu = 1.00, validation: 0.60 (388.8 examples/sec; 0.329 sec/batch)
2016-12-03 03:33:35.723227: step 11830, loss = 0.47, accu = 1.00, validation: 0.70 (383.3 examples/sec; 0.334 sec/batch)
2016-12-03 03:33:39.432852: step 11840, loss = 0.51, accu = 0.98, validation: 0.70 (328.3 examples/sec; 0.390 sec/batch)
2016-12-03 03:33:42.988925: step 11850, loss = 0.52, accu = 0.97, validation: 0.62 (332.2 examples/sec; 0.385 sec/batch)
2016-12-03 03:33:46.563794: step 11860, loss = 0.51, accu = 0.98, validation: 0.77 (383.3 examples/sec; 0.334 sec/batch)
2016-12-03 03:33:50.089751: step 11870, loss = 0.48, accu = 0.99, validation: 0.62 (378.8 examples/sec; 0.338 sec/batch)
2016-12-03 03:33:53.652282: step 11880, loss = 0.48, accu = 1.00, validation: 0.70 (393.0 examples/sec; 0.326 sec/batch)
2016-12-03 03:33:57.194125: step 11890, loss = 0.52, accu = 0.99, validation: 0.71 (381.8 examples/sec; 0.335 sec/batch)
2016-12-03 03:34:00.885109: step 11900, loss = 0.48, accu = 0.99, validation: 0.66 (378.0 examples/sec; 0.339 sec/batch)
2016-12-03 03:34:04.649293: step 11910, loss = 0.49, accu = 0.98, validation: 0.64 (372.7 examples/sec; 0.343 sec/batch)
2016-12-03 03:34:08.340109: step 11920, loss = 0.51, accu = 0.99, validation: 0.59 (331.3 examples/sec; 0.386 sec/batch)
2016-12-03 03:34:11.920947: step 11930, loss = 0.52, accu = 0.98, validation: 0.64 (352.0 examples/sec; 0.364 sec/batch)
2016-12-03 03:34:15.440773: step 11940, loss = 0.54, accu = 0.96, validation: 0.64 (388.3 examples/sec; 0.330 sec/batch)
2016-12-03 03:34:19.176005: step 11950, loss = 0.51, accu = 0.99, validation: 0.68 (321.7 examples/sec; 0.398 sec/batch)
2016-12-03 03:34:22.698421: step 11960, loss = 0.48, accu = 1.00, validation: 0.56 (384.5 examples/sec; 0.333 sec/batch)
2016-12-03 03:34:26.338486: step 11970, loss = 0.52, accu = 0.97, validation: 0.73 (356.7 examples/sec; 0.359 sec/batch)
2016-12-03 03:34:29.860196: step 11980, loss = 0.53, accu = 0.97, validation: 0.68 (387.1 examples/sec; 0.331 sec/batch)
2016-12-03 03:34:33.352304: step 11990, loss = 0.51, accu = 0.98, validation: 0.68 (382.6 examples/sec; 0.335 sec/batch)
2016-12-03 03:34:36.858244: step 12000, loss = 0.55, accu = 0.95, validation: 0.69 (380.1 examples/sec; 0.337 sec/batch)
2016-12-03 03:34:41.131554: step 12010, loss = 0.56, accu = 0.97, validation: 0.62 (367.5 examples/sec; 0.348 sec/batch)
2016-12-03 03:34:44.732128: step 12020, loss = 0.50, accu = 0.98, validation: 0.68 (396.9 examples/sec; 0.322 sec/batch)
2016-12-03 03:34:48.339084: step 12030, loss = 0.49, accu = 0.99, validation: 0.68 (382.1 examples/sec; 0.335 sec/batch)
2016-12-03 03:34:51.946136: step 12040, loss = 0.54, accu = 0.96, validation: 0.73 (388.9 examples/sec; 0.329 sec/batch)
2016-12-03 03:34:55.525464: step 12050, loss = 0.49, accu = 0.99, validation: 0.65 (377.3 examples/sec; 0.339 sec/batch)
2016-12-03 03:34:59.261596: step 12060, loss = 0.47, accu = 1.00, validation: 0.68 (299.2 examples/sec; 0.428 sec/batch)
2016-12-03 03:35:02.866467: step 12070, loss = 0.50, accu = 0.98, validation: 0.59 (373.9 examples/sec; 0.342 sec/batch)
2016-12-03 03:35:06.534332: step 12080, loss = 0.50, accu = 0.97, validation: 0.66 (357.1 examples/sec; 0.358 sec/batch)
2016-12-03 03:35:10.261733: step 12090, loss = 0.48, accu = 0.99, validation: 0.63 (325.6 examples/sec; 0.393 sec/batch)
2016-12-03 03:35:13.861383: step 12100, loss = 0.53, accu = 0.98, validation: 0.62 (380.0 examples/sec; 0.337 sec/batch)
2016-12-03 03:35:17.646272: step 12110, loss = 0.47, accu = 1.00, validation: 0.68 (380.8 examples/sec; 0.336 sec/batch)
2016-12-03 03:35:21.308120: step 12120, loss = 0.49, accu = 0.99, validation: 0.66 (267.9 examples/sec; 0.478 sec/batch)
2016-12-03 03:35:24.918399: step 12130, loss = 0.50, accu = 0.98, validation: 0.68 (379.9 examples/sec; 0.337 sec/batch)
2016-12-03 03:35:28.476959: step 12140, loss = 0.50, accu = 0.99, validation: 0.63 (279.1 examples/sec; 0.459 sec/batch)
2016-12-03 03:35:32.050854: step 12150, loss = 0.50, accu = 0.98, validation: 0.73 (363.4 examples/sec; 0.352 sec/batch)
2016-12-03 03:35:35.726374: step 12160, loss = 0.51, accu = 0.98, validation: 0.65 (382.8 examples/sec; 0.334 sec/batch)
2016-12-03 03:35:39.340248: step 12170, loss = 0.49, accu = 1.00, validation: 0.63 (382.9 examples/sec; 0.334 sec/batch)
2016-12-03 03:35:43.056453: step 12180, loss = 0.49, accu = 0.99, validation: 0.66 (279.4 examples/sec; 0.458 sec/batch)
2016-12-03 03:35:46.627736: step 12190, loss = 0.49, accu = 0.99, validation: 0.65 (282.4 examples/sec; 0.453 sec/batch)
2016-12-03 03:35:50.252919: step 12200, loss = 0.52, accu = 0.97, validation: 0.63 (361.0 examples/sec; 0.355 sec/batch)
2016-12-03 03:35:54.045276: step 12210, loss = 0.50, accu = 0.99, validation: 0.65 (358.9 examples/sec; 0.357 sec/batch)
2016-12-03 03:35:57.655990: step 12220, loss = 0.53, accu = 0.97, validation: 0.61 (387.8 examples/sec; 0.330 sec/batch)
2016-12-03 03:36:01.216812: step 12230, loss = 0.49, accu = 0.99, validation: 0.62 (372.0 examples/sec; 0.344 sec/batch)
2016-12-03 03:36:04.966881: step 12240, loss = 0.48, accu = 0.99, validation: 0.71 (343.9 examples/sec; 0.372 sec/batch)
2016-12-03 03:36:08.555952: step 12250, loss = 0.51, accu = 0.98, validation: 0.72 (372.2 examples/sec; 0.344 sec/batch)
2016-12-03 03:36:12.119584: step 12260, loss = 0.51, accu = 0.98, validation: 0.65 (378.7 examples/sec; 0.338 sec/batch)
2016-12-03 03:36:15.675074: step 12270, loss = 0.49, accu = 0.99, validation: 0.62 (388.2 examples/sec; 0.330 sec/batch)
2016-12-03 03:36:19.332361: step 12280, loss = 0.49, accu = 0.99, validation: 0.63 (346.9 examples/sec; 0.369 sec/batch)
2016-12-03 03:36:22.891211: step 12290, loss = 0.50, accu = 0.98, validation: 0.63 (398.0 examples/sec; 0.322 sec/batch)
2016-12-03 03:36:26.482281: step 12300, loss = 0.51, accu = 0.98, validation: 0.66 (348.6 examples/sec; 0.367 sec/batch)
2016-12-03 03:36:30.392075: step 12310, loss = 0.50, accu = 0.98, validation: 0.63 (380.9 examples/sec; 0.336 sec/batch)
2016-12-03 03:36:33.958313: step 12320, loss = 0.47, accu = 1.00, validation: 0.70 (381.1 examples/sec; 0.336 sec/batch)
2016-12-03 03:36:37.511031: step 12330, loss = 0.52, accu = 0.98, validation: 0.63 (282.2 examples/sec; 0.454 sec/batch)
2016-12-03 03:36:41.025332: step 12340, loss = 0.49, accu = 0.99, validation: 0.63 (308.7 examples/sec; 0.415 sec/batch)
2016-12-03 03:36:44.580394: step 12350, loss = 0.50, accu = 0.99, validation: 0.75 (379.4 examples/sec; 0.337 sec/batch)
2016-12-03 03:36:48.316180: step 12360, loss = 0.50, accu = 0.99, validation: 0.72 (372.4 examples/sec; 0.344 sec/batch)
2016-12-03 03:36:51.802166: step 12370, loss = 0.53, accu = 0.98, validation: 0.67 (386.9 examples/sec; 0.331 sec/batch)
2016-12-03 03:36:55.466120: step 12380, loss = 0.51, accu = 0.98, validation: 0.60 (379.1 examples/sec; 0.338 sec/batch)
2016-12-03 03:36:59.150768: step 12390, loss = 0.51, accu = 0.98, validation: 0.66 (380.8 examples/sec; 0.336 sec/batch)
2016-12-03 03:37:02.669847: step 12400, loss = 0.49, accu = 0.98, validation: 0.67 (379.9 examples/sec; 0.337 sec/batch)
2016-12-03 03:37:06.719480: step 12410, loss = 0.52, accu = 0.97, validation: 0.67 (281.8 examples/sec; 0.454 sec/batch)
2016-12-03 03:37:10.296524: step 12420, loss = 0.55, accu = 0.98, validation: 0.60 (267.0 examples/sec; 0.479 sec/batch)
2016-12-03 03:37:13.823215: step 12430, loss = 0.49, accu = 0.99, validation: 0.75 (383.6 examples/sec; 0.334 sec/batch)
2016-12-03 03:37:17.409229: step 12440, loss = 0.47, accu = 1.00, validation: 0.70 (389.6 examples/sec; 0.329 sec/batch)
2016-12-03 03:37:21.001626: step 12450, loss = 0.52, accu = 0.98, validation: 0.76 (387.3 examples/sec; 0.330 sec/batch)
2016-12-03 03:37:24.507464: step 12460, loss = 0.49, accu = 0.98, validation: 0.71 (384.3 examples/sec; 0.333 sec/batch)
2016-12-03 03:37:28.100350: step 12470, loss = 0.50, accu = 0.98, validation: 0.68 (280.6 examples/sec; 0.456 sec/batch)
2016-12-03 03:37:31.533940: step 12480, loss = 0.50, accu = 0.99, validation: 0.64 (383.3 examples/sec; 0.334 sec/batch)
2016-12-03 03:37:35.316985: step 12490, loss = 0.50, accu = 0.98, validation: 0.65 (286.0 examples/sec; 0.448 sec/batch)
2016-12-03 03:37:38.874062: step 12500, loss = 0.50, accu = 0.98, validation: 0.66 (380.7 examples/sec; 0.336 sec/batch)
2016-12-03 03:37:42.639887: step 12510, loss = 0.48, accu = 0.99, validation: 0.69 (387.6 examples/sec; 0.330 sec/batch)
2016-12-03 03:37:46.276835: step 12520, loss = 0.54, accu = 0.98, validation: 0.62 (380.2 examples/sec; 0.337 sec/batch)
2016-12-03 03:37:49.819597: step 12530, loss = 0.50, accu = 0.98, validation: 0.69 (388.5 examples/sec; 0.329 sec/batch)
2016-12-03 03:37:53.404526: step 12540, loss = 0.50, accu = 0.98, validation: 0.67 (385.0 examples/sec; 0.332 sec/batch)
2016-12-03 03:37:56.936980: step 12550, loss = 0.51, accu = 0.98, validation: 0.71 (385.3 examples/sec; 0.332 sec/batch)
2016-12-03 03:38:00.458630: step 12560, loss = 0.52, accu = 0.98, validation: 0.64 (361.8 examples/sec; 0.354 sec/batch)
2016-12-03 03:38:04.115044: step 12570, loss = 0.51, accu = 0.99, validation: 0.69 (379.0 examples/sec; 0.338 sec/batch)
2016-12-03 03:38:07.857968: step 12580, loss = 0.50, accu = 0.99, validation: 0.71 (337.2 examples/sec; 0.380 sec/batch)
2016-12-03 03:38:11.391904: step 12590, loss = 0.53, accu = 0.96, validation: 0.65 (286.6 examples/sec; 0.447 sec/batch)
2016-12-03 03:38:14.874183: step 12600, loss = 0.50, accu = 0.98, validation: 0.66 (382.3 examples/sec; 0.335 sec/batch)
2016-12-03 03:38:18.774791: step 12610, loss = 0.49, accu = 0.98, validation: 0.70 (389.8 examples/sec; 0.328 sec/batch)
2016-12-03 03:38:22.362787: step 12620, loss = 0.51, accu = 0.98, validation: 0.74 (317.0 examples/sec; 0.404 sec/batch)
2016-12-03 03:38:25.921962: step 12630, loss = 0.47, accu = 0.98, validation: 0.62 (395.2 examples/sec; 0.324 sec/batch)
2016-12-03 03:38:29.518361: step 12640, loss = 0.50, accu = 0.99, validation: 0.61 (319.4 examples/sec; 0.401 sec/batch)
2016-12-03 03:38:33.036639: step 12650, loss = 0.51, accu = 0.98, validation: 0.62 (373.1 examples/sec; 0.343 sec/batch)
2016-12-03 03:38:36.568830: step 12660, loss = 0.49, accu = 0.98, validation: 0.60 (377.2 examples/sec; 0.339 sec/batch)
2016-12-03 03:38:40.222983: step 12670, loss = 0.49, accu = 1.00, validation: 0.67 (401.2 examples/sec; 0.319 sec/batch)
2016-12-03 03:38:43.783558: step 12680, loss = 0.54, accu = 0.96, validation: 0.62 (392.8 examples/sec; 0.326 sec/batch)
2016-12-03 03:38:47.462369: step 12690, loss = 0.49, accu = 0.99, validation: 0.65 (385.2 examples/sec; 0.332 sec/batch)
2016-12-03 03:38:50.914496: step 12700, loss = 0.49, accu = 1.00, validation: 0.64 (375.1 examples/sec; 0.341 sec/batch)
2016-12-03 03:38:54.909800: step 12710, loss = 0.50, accu = 0.96, validation: 0.68 (387.0 examples/sec; 0.331 sec/batch)
2016-12-03 03:38:58.474978: step 12720, loss = 0.55, accu = 0.98, validation: 0.67 (374.3 examples/sec; 0.342 sec/batch)
2016-12-03 03:39:02.205243: step 12730, loss = 0.49, accu = 1.00, validation: 0.62 (339.9 examples/sec; 0.377 sec/batch)
2016-12-03 03:39:05.570363: step 12740, loss = 0.48, accu = 0.98, validation: 0.62 (388.9 examples/sec; 0.329 sec/batch)
2016-12-03 03:39:09.251071: step 12750, loss = 0.52, accu = 0.97, validation: 0.66 (289.4 examples/sec; 0.442 sec/batch)
2016-12-03 03:39:12.824831: step 12760, loss = 0.50, accu = 0.98, validation: 0.70 (383.7 examples/sec; 0.334 sec/batch)
2016-12-03 03:39:16.309359: step 12770, loss = 0.51, accu = 0.98, validation: 0.64 (384.7 examples/sec; 0.333 sec/batch)
2016-12-03 03:39:20.048217: step 12780, loss = 0.49, accu = 0.99, validation: 0.69 (313.3 examples/sec; 0.409 sec/batch)
2016-12-03 03:39:23.574981: step 12790, loss = 0.51, accu = 0.99, validation: 0.63 (378.1 examples/sec; 0.339 sec/batch)
2016-12-03 03:39:27.031291: step 12800, loss = 0.48, accu = 1.00, validation: 0.65 (372.1 examples/sec; 0.344 sec/batch)
2016-12-03 03:39:30.890176: step 12810, loss = 0.49, accu = 0.98, validation: 0.74 (378.0 examples/sec; 0.339 sec/batch)
2016-12-03 03:39:34.446905: step 12820, loss = 0.47, accu = 0.99, validation: 0.70 (378.9 examples/sec; 0.338 sec/batch)
2016-12-03 03:39:37.954587: step 12830, loss = 0.53, accu = 0.97, validation: 0.69 (403.0 examples/sec; 0.318 sec/batch)
2016-12-03 03:39:41.554077: step 12840, loss = 0.56, accu = 0.95, validation: 0.65 (352.4 examples/sec; 0.363 sec/batch)
2016-12-03 03:39:45.044943: step 12850, loss = 0.48, accu = 0.99, validation: 0.64 (367.9 examples/sec; 0.348 sec/batch)
2016-12-03 03:39:48.569597: step 12860, loss = 0.51, accu = 0.98, validation: 0.67 (384.9 examples/sec; 0.333 sec/batch)
2016-12-03 03:39:52.186061: step 12870, loss = 0.52, accu = 0.96, validation: 0.69 (384.4 examples/sec; 0.333 sec/batch)
2016-12-03 03:39:55.829105: step 12880, loss = 0.50, accu = 1.00, validation: 0.67 (386.1 examples/sec; 0.332 sec/batch)
2016-12-03 03:39:59.514434: step 12890, loss = 0.54, accu = 0.95, validation: 0.75 (338.6 examples/sec; 0.378 sec/batch)
2016-12-03 03:40:03.023204: step 12900, loss = 0.50, accu = 0.99, validation: 0.62 (369.9 examples/sec; 0.346 sec/batch)
2016-12-03 03:40:07.014389: step 12910, loss = 0.48, accu = 1.00, validation: 0.68 (271.8 examples/sec; 0.471 sec/batch)
2016-12-03 03:40:10.444932: step 12920, loss = 0.48, accu = 1.00, validation: 0.74 (382.7 examples/sec; 0.334 sec/batch)
2016-12-03 03:40:14.093905: step 12930, loss = 0.47, accu = 1.00, validation: 0.69 (271.1 examples/sec; 0.472 sec/batch)
2016-12-03 03:40:17.634851: step 12940, loss = 0.51, accu = 0.98, validation: 0.65 (384.8 examples/sec; 0.333 sec/batch)
2016-12-03 03:40:21.134641: step 12950, loss = 0.48, accu = 1.00, validation: 0.62 (383.1 examples/sec; 0.334 sec/batch)
2016-12-03 03:40:24.709074: step 12960, loss = 0.51, accu = 0.98, validation: 0.64 (397.6 examples/sec; 0.322 sec/batch)
2016-12-03 03:40:28.229942: step 12970, loss = 0.47, accu = 0.99, validation: 0.70 (386.5 examples/sec; 0.331 sec/batch)
2016-12-03 03:40:31.782697: step 12980, loss = 0.50, accu = 0.98, validation: 0.62 (385.1 examples/sec; 0.332 sec/batch)
2016-12-03 03:40:35.510107: step 12990, loss = 0.50, accu = 0.98, validation: 0.56 (389.1 examples/sec; 0.329 sec/batch)
2016-12-03 03:40:39.091852: step 13000, loss = 0.48, accu = 0.98, validation: 0.76 (369.7 examples/sec; 0.346 sec/batch)
2016-12-03 03:40:43.338796: step 13010, loss = 0.51, accu = 0.99, validation: 0.70 (362.7 examples/sec; 0.353 sec/batch)
2016-12-03 03:40:46.859115: step 13020, loss = 0.48, accu = 1.00, validation: 0.73 (384.6 examples/sec; 0.333 sec/batch)
2016-12-03 03:40:50.441194: step 13030, loss = 0.48, accu = 0.99, validation: 0.70 (369.6 examples/sec; 0.346 sec/batch)
2016-12-03 03:40:54.157587: step 13040, loss = 0.49, accu = 0.98, validation: 0.67 (265.5 examples/sec; 0.482 sec/batch)
2016-12-03 03:40:57.736917: step 13050, loss = 0.48, accu = 1.00, validation: 0.59 (384.5 examples/sec; 0.333 sec/batch)
2016-12-03 03:41:01.244781: step 13060, loss = 0.51, accu = 0.98, validation: 0.65 (383.1 examples/sec; 0.334 sec/batch)
2016-12-03 03:41:04.987050: step 13070, loss = 0.49, accu = 0.98, validation: 0.67 (357.9 examples/sec; 0.358 sec/batch)
2016-12-03 03:41:08.517207: step 13080, loss = 0.50, accu = 0.98, validation: 0.70 (389.8 examples/sec; 0.328 sec/batch)
2016-12-03 03:41:12.207025: step 13090, loss = 0.48, accu = 0.98, validation: 0.71 (369.0 examples/sec; 0.347 sec/batch)
2016-12-03 03:41:15.786363: step 13100, loss = 0.49, accu = 0.99, validation: 0.60 (379.4 examples/sec; 0.337 sec/batch)
2016-12-03 03:41:19.677093: step 13110, loss = 0.49, accu = 0.98, validation: 0.70 (399.2 examples/sec; 0.321 sec/batch)
2016-12-03 03:41:23.228866: step 13120, loss = 0.54, accu = 0.98, validation: 0.64 (394.4 examples/sec; 0.325 sec/batch)
2016-12-03 03:41:26.892929: step 13130, loss = 0.54, accu = 0.95, validation: 0.63 (365.8 examples/sec; 0.350 sec/batch)
2016-12-03 03:41:30.463838: step 13140, loss = 0.47, accu = 1.00, validation: 0.68 (372.6 examples/sec; 0.343 sec/batch)
2016-12-03 03:41:34.271070: step 13150, loss = 0.51, accu = 0.97, validation: 0.66 (324.5 examples/sec; 0.394 sec/batch)
2016-12-03 03:41:37.690140: step 13160, loss = 0.50, accu = 0.98, validation: 0.64 (378.8 examples/sec; 0.338 sec/batch)
2016-12-03 03:41:41.371283: step 13170, loss = 0.52, accu = 0.97, validation: 0.66 (375.9 examples/sec; 0.340 sec/batch)
2016-12-03 03:41:45.082618: step 13180, loss = 0.52, accu = 0.97, validation: 0.77 (372.7 examples/sec; 0.343 sec/batch)
2016-12-03 03:41:48.637541: step 13190, loss = 0.52, accu = 0.97, validation: 0.63 (390.6 examples/sec; 0.328 sec/batch)
2016-12-03 03:41:52.184288: step 13200, loss = 0.49, accu = 0.98, validation: 0.63 (327.7 examples/sec; 0.391 sec/batch)
2016-12-03 03:41:55.999290: step 13210, loss = 0.51, accu = 0.98, validation: 0.66 (361.4 examples/sec; 0.354 sec/batch)
2016-12-03 03:41:59.705867: step 13220, loss = 0.49, accu = 0.99, validation: 0.61 (350.0 examples/sec; 0.366 sec/batch)
2016-12-03 03:42:03.290691: step 13230, loss = 0.54, accu = 0.97, validation: 0.66 (364.4 examples/sec; 0.351 sec/batch)
2016-12-03 03:42:06.880926: step 13240, loss = 0.49, accu = 0.99, validation: 0.68 (349.5 examples/sec; 0.366 sec/batch)
2016-12-03 03:42:10.557161: step 13250, loss = 0.48, accu = 0.99, validation: 0.59 (362.7 examples/sec; 0.353 sec/batch)
2016-12-03 03:42:14.134224: step 13260, loss = 0.49, accu = 0.98, validation: 0.61 (389.5 examples/sec; 0.329 sec/batch)
2016-12-03 03:42:17.723312: step 13270, loss = 0.50, accu = 0.98, validation: 0.73 (382.3 examples/sec; 0.335 sec/batch)
2016-12-03 03:42:21.447202: step 13280, loss = 0.53, accu = 0.98, validation: 0.70 (275.5 examples/sec; 0.465 sec/batch)
2016-12-03 03:42:25.026006: step 13290, loss = 0.50, accu = 0.98, validation: 0.68 (385.9 examples/sec; 0.332 sec/batch)
2016-12-03 03:42:28.722266: step 13300, loss = 0.49, accu = 0.99, validation: 0.65 (315.2 examples/sec; 0.406 sec/batch)
2016-12-03 03:42:32.564059: step 13310, loss = 0.53, accu = 0.96, validation: 0.64 (348.9 examples/sec; 0.367 sec/batch)
2016-12-03 03:42:36.043135: step 13320, loss = 0.49, accu = 0.98, validation: 0.69 (386.0 examples/sec; 0.332 sec/batch)
2016-12-03 03:42:39.683563: step 13330, loss = 0.50, accu = 0.98, validation: 0.70 (385.8 examples/sec; 0.332 sec/batch)
2016-12-03 03:42:43.470279: step 13340, loss = 0.50, accu = 0.98, validation: 0.59 (355.0 examples/sec; 0.361 sec/batch)
2016-12-03 03:42:46.927891: step 13350, loss = 0.51, accu = 0.98, validation: 0.69 (377.3 examples/sec; 0.339 sec/batch)
2016-12-03 03:42:50.445603: step 13360, loss = 0.50, accu = 0.98, validation: 0.64 (366.5 examples/sec; 0.349 sec/batch)
2016-12-03 03:42:54.105433: step 13370, loss = 0.51, accu = 0.97, validation: 0.66 (380.9 examples/sec; 0.336 sec/batch)
2016-12-03 03:42:57.692884: step 13380, loss = 0.53, accu = 0.96, validation: 0.71 (278.6 examples/sec; 0.459 sec/batch)
2016-12-03 03:43:01.235798: step 13390, loss = 0.51, accu = 0.98, validation: 0.72 (391.6 examples/sec; 0.327 sec/batch)
2016-12-03 03:43:04.740361: step 13400, loss = 0.50, accu = 0.98, validation: 0.65 (390.2 examples/sec; 0.328 sec/batch)
2016-12-03 03:43:08.533379: step 13410, loss = 0.49, accu = 1.00, validation: 0.65 (371.0 examples/sec; 0.345 sec/batch)
2016-12-03 03:43:12.225791: step 13420, loss = 0.51, accu = 0.98, validation: 0.63 (345.8 examples/sec; 0.370 sec/batch)
2016-12-03 03:43:15.861501: step 13430, loss = 0.53, accu = 0.98, validation: 0.70 (343.0 examples/sec; 0.373 sec/batch)
2016-12-03 03:43:19.391217: step 13440, loss = 0.49, accu = 0.99, validation: 0.69 (385.4 examples/sec; 0.332 sec/batch)
2016-12-03 03:43:22.893182: step 13450, loss = 0.49, accu = 0.98, validation: 0.62 (381.5 examples/sec; 0.336 sec/batch)
2016-12-03 03:43:26.482359: step 13460, loss = 0.48, accu = 0.99, validation: 0.71 (398.6 examples/sec; 0.321 sec/batch)
2016-12-03 03:43:30.113201: step 13470, loss = 0.48, accu = 0.99, validation: 0.61 (329.1 examples/sec; 0.389 sec/batch)
2016-12-03 03:43:33.585383: step 13480, loss = 0.49, accu = 0.99, validation: 0.72 (350.4 examples/sec; 0.365 sec/batch)
2016-12-03 03:43:37.084110: step 13490, loss = 0.50, accu = 0.98, validation: 0.70 (378.4 examples/sec; 0.338 sec/batch)
2016-12-03 03:43:40.840376: step 13500, loss = 0.51, accu = 0.99, validation: 0.65 (368.0 examples/sec; 0.348 sec/batch)
2016-12-03 03:43:44.660527: step 13510, loss = 0.50, accu = 0.98, validation: 0.62 (389.8 examples/sec; 0.328 sec/batch)
2016-12-03 03:43:48.324195: step 13520, loss = 0.50, accu = 0.98, validation: 0.66 (327.4 examples/sec; 0.391 sec/batch)
2016-12-03 03:43:51.822264: step 13530, loss = 0.53, accu = 0.96, validation: 0.62 (388.7 examples/sec; 0.329 sec/batch)
2016-12-03 03:43:55.327166: step 13540, loss = 0.47, accu = 1.00, validation: 0.68 (392.2 examples/sec; 0.326 sec/batch)
2016-12-03 03:43:58.963093: step 13550, loss = 0.53, accu = 0.97, validation: 0.63 (387.5 examples/sec; 0.330 sec/batch)
2016-12-03 03:44:02.516934: step 13560, loss = 0.49, accu = 0.98, validation: 0.63 (392.9 examples/sec; 0.326 sec/batch)
2016-12-03 03:44:06.029442: step 13570, loss = 0.49, accu = 0.99, validation: 0.70 (382.7 examples/sec; 0.334 sec/batch)
2016-12-03 03:44:09.536418: step 13580, loss = 0.50, accu = 0.98, validation: 0.65 (388.7 examples/sec; 0.329 sec/batch)
2016-12-03 03:44:13.069591: step 13590, loss = 0.48, accu = 0.98, validation: 0.66 (391.4 examples/sec; 0.327 sec/batch)
2016-12-03 03:44:16.615941: step 13600, loss = 0.52, accu = 0.98, validation: 0.70 (376.5 examples/sec; 0.340 sec/batch)
2016-12-03 03:44:20.553161: step 13610, loss = 0.48, accu = 0.99, validation: 0.59 (394.6 examples/sec; 0.324 sec/batch)
2016-12-03 03:44:24.122860: step 13620, loss = 0.51, accu = 0.98, validation: 0.63 (376.0 examples/sec; 0.340 sec/batch)
2016-12-03 03:44:27.712813: step 13630, loss = 0.50, accu = 0.98, validation: 0.62 (359.2 examples/sec; 0.356 sec/batch)
2016-12-03 03:44:31.206578: step 13640, loss = 0.48, accu = 0.99, validation: 0.71 (404.2 examples/sec; 0.317 sec/batch)
2016-12-03 03:44:34.898711: step 13650, loss = 0.50, accu = 0.98, validation: 0.67 (368.5 examples/sec; 0.347 sec/batch)
2016-12-03 03:44:38.428908: step 13660, loss = 0.49, accu = 0.99, validation: 0.65 (354.6 examples/sec; 0.361 sec/batch)
2016-12-03 03:44:42.061416: step 13670, loss = 0.50, accu = 0.98, validation: 0.63 (278.1 examples/sec; 0.460 sec/batch)
2016-12-03 03:44:45.494756: step 13680, loss = 0.49, accu = 0.98, validation: 0.59 (376.7 examples/sec; 0.340 sec/batch)
2016-12-03 03:44:49.039119: step 13690, loss = 0.47, accu = 1.00, validation: 0.54 (385.4 examples/sec; 0.332 sec/batch)
2016-12-03 03:44:52.712116: step 13700, loss = 0.48, accu = 1.00, validation: 0.63 (381.7 examples/sec; 0.335 sec/batch)
2016-12-03 03:44:56.582893: step 13710, loss = 0.50, accu = 0.98, validation: 0.62 (304.7 examples/sec; 0.420 sec/batch)
2016-12-03 03:45:00.107368: step 13720, loss = 0.49, accu = 0.98, validation: 0.65 (376.4 examples/sec; 0.340 sec/batch)
2016-12-03 03:45:03.696431: step 13730, loss = 0.51, accu = 0.98, validation: 0.65 (378.5 examples/sec; 0.338 sec/batch)
2016-12-03 03:45:07.256529: step 13740, loss = 0.49, accu = 0.99, validation: 0.68 (396.5 examples/sec; 0.323 sec/batch)
2016-12-03 03:45:10.928250: step 13750, loss = 0.53, accu = 0.98, validation: 0.67 (343.3 examples/sec; 0.373 sec/batch)
2016-12-03 03:45:14.434557: step 13760, loss = 0.50, accu = 0.98, validation: 0.63 (377.6 examples/sec; 0.339 sec/batch)
2016-12-03 03:45:18.003423: step 13770, loss = 0.53, accu = 0.95, validation: 0.62 (384.7 examples/sec; 0.333 sec/batch)
2016-12-03 03:45:21.676354: step 13780, loss = 0.48, accu = 0.98, validation: 0.66 (345.1 examples/sec; 0.371 sec/batch)
2016-12-03 03:45:25.186116: step 13790, loss = 0.51, accu = 0.97, validation: 0.66 (385.7 examples/sec; 0.332 sec/batch)
2016-12-03 03:45:28.914151: step 13800, loss = 0.49, accu = 1.00, validation: 0.65 (382.3 examples/sec; 0.335 sec/batch)
2016-12-03 03:45:32.842818: step 13810, loss = 0.50, accu = 0.97, validation: 0.67 (345.2 examples/sec; 0.371 sec/batch)
2016-12-03 03:45:36.309172: step 13820, loss = 0.48, accu = 0.99, validation: 0.60 (384.6 examples/sec; 0.333 sec/batch)
2016-12-03 03:45:39.718913: step 13830, loss = 0.47, accu = 1.00, validation: 0.67 (372.6 examples/sec; 0.344 sec/batch)
2016-12-03 03:45:43.379983: step 13840, loss = 0.50, accu = 0.98, validation: 0.73 (263.4 examples/sec; 0.486 sec/batch)
2016-12-03 03:45:46.893349: step 13850, loss = 0.50, accu = 0.99, validation: 0.70 (387.8 examples/sec; 0.330 sec/batch)
2016-12-03 03:45:50.444831: step 13860, loss = 0.49, accu = 0.99, validation: 0.62 (390.3 examples/sec; 0.328 sec/batch)
2016-12-03 03:45:54.026103: step 13870, loss = 0.51, accu = 0.98, validation: 0.70 (390.9 examples/sec; 0.327 sec/batch)
2016-12-03 03:45:57.554927: step 13880, loss = 0.49, accu = 0.98, validation: 0.61 (394.9 examples/sec; 0.324 sec/batch)
2016-12-03 03:46:01.129247: step 13890, loss = 0.50, accu = 0.96, validation: 0.66 (314.5 examples/sec; 0.407 sec/batch)
2016-12-03 03:46:04.543343: step 13900, loss = 0.48, accu = 0.98, validation: 0.64 (396.1 examples/sec; 0.323 sec/batch)
2016-12-03 03:46:08.431888: step 13910, loss = 0.48, accu = 0.98, validation: 0.62 (390.6 examples/sec; 0.328 sec/batch)
2016-12-03 03:46:12.136328: step 13920, loss = 0.49, accu = 0.98, validation: 0.72 (350.5 examples/sec; 0.365 sec/batch)
2016-12-03 03:46:15.712114: step 13930, loss = 0.51, accu = 0.98, validation: 0.62 (388.9 examples/sec; 0.329 sec/batch)
2016-12-03 03:46:19.445653: step 13940, loss = 0.50, accu = 0.99, validation: 0.70 (338.1 examples/sec; 0.379 sec/batch)
2016-12-03 03:46:22.922981: step 13950, loss = 0.49, accu = 0.98, validation: 0.72 (361.1 examples/sec; 0.354 sec/batch)
2016-12-03 03:46:26.435075: step 13960, loss = 0.48, accu = 0.99, validation: 0.66 (391.5 examples/sec; 0.327 sec/batch)
2016-12-03 03:46:30.148684: step 13970, loss = 0.50, accu = 0.99, validation: 0.63 (341.9 examples/sec; 0.374 sec/batch)
2016-12-03 03:46:33.509219: step 13980, loss = 0.53, accu = 0.96, validation: 0.59 (392.2 examples/sec; 0.326 sec/batch)
2016-12-03 03:46:37.205308: step 13990, loss = 0.51, accu = 0.98, validation: 0.71 (362.9 examples/sec; 0.353 sec/batch)

